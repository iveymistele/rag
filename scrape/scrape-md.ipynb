{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3753db49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from chromadb import PersistentClient\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "CHROMA_PATH = \"./chroma\"\n",
    "COLLECTION_NAME = \"data\"\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen3\"\n",
    ")\n",
    "\n",
    "persistent_client = PersistentClient(\n",
    "    path=CHROMA_PATH,\n",
    ")\n",
    "\n",
    "collection = persistent_client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "def add_documents_to_vector_store(documents):\n",
    "    vector_store.add_documents(\n",
    "        documents=documents,\n",
    "        ids=[doc.metadata['source_type'] + \"_\" + doc.metadata['source'] + \"_\" + str(doc.metadata['chunk_number']) for doc in documents],\n",
    "    )\n",
    "    print(f\"Added {len(documents)} documents to the vector store.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea74a3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping draft document: ./md_content/web_content/resources.md\n",
      "Skipping draft document: ./md_content/web_content/name-contest.md\n",
      "Skipping draft document: ./md_content/web_content/post/2020-dcos-maintenance.md\n",
      "Skipping draft document: ./md_content/web_content/post/2023-04-computational-scientist-position.md\n",
      "Skipping draft document: ./md_content/web_content/post/2019-september-maintenance-notes.md\n",
      "Skipping draft document: ./md_content/web_content/post/2019-september-scratch-notes.md\n",
      "Skipping draft document: ./md_content/web_content/post/2018-fall-workshops.md\n",
      "Skipping draft document: ./md_content/web_content/post/2018-spring-workshops.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/resources.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/use-cases.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/lab-computing.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/secure-computing.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/hipaa-compliance.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/x2go.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/cufflinks.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/samtools.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/sicer.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mariadb.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/postgresql.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mongodb.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mysql.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-linux-sw/image-processing/imagej.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/x2go.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/cufflinks.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/samtools.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/idl.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/sicer.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mariadb.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/postgresql.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/sql-server.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mongodb.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mysql.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/image-processing/axiovision.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/ivy/ivy-windows-sw/image-processing/imagej.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/storage/storage-options.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/storage/non-sensitive-data.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/accord/accord-support.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/omero/_index.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/anaconda.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/index.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/bowtie-docker.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/aws-cli.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/bioinformatics-pipelines.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/jq.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/google-cloud-sdk.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/aws-bioinformatics.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/awscli-powershell.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/boto3.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/rstudio-docker.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/s3.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/domino-data-lab.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/ebs-storage.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/bowtie.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/reference/docker.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/howtos/rivanna/gpu-training.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/howtos/general/redis.md\n",
      "Skipping draft document: ./md_content/web_content/userinfo/howtos/general/mysql.md\n",
      "Skipping draft document: ./md_content/web_content/service/consult.md\n",
      "Skipping draft document: ./md_content/web_content/service/grant-support.md\n",
      "Skipping draft document: ./md_content/web_content/service/collaboration.md\n",
      "Skipping draft document: ./md_content/web_content/service/map.md\n",
      "Skipping draft document: ./md_content/web_content/about/staff.md\n",
      "Skipping draft document: ./md_content/web_content/about/employment.md\n",
      "Skipping draft document: ./md_content/web_content/project/cloud-migrations.md\n",
      "Skipping draft document: ./md_content/web_content/project/basic-science.md\n",
      "Skipping draft document: ./md_content/web_content/project/clinical-research.md\n",
      "Skipping draft document: ./md_content/web_content/form/sns-test.md\n",
      "Skipping draft document: ./md_content/web_content/form/support-request-attachments.md\n",
      "Skipping draft document: ./md_content/web_content/form/support-request-orig.md\n",
      "Skipping draft document: ./md_content/web_content/form/skyline.md\n",
      "Skipping draft document: ./md_content/web_content/form/test-form.md\n",
      "Skipping draft document: ./md_content/web_content/form/support-request-vRedesign.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/storage-ptao.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/fdm.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/omero-ptao.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/database.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/containers-ptao.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/omero.md\n",
      "Skipping draft document: ./md_content/web_content/form/retired/allocation-purchase-ptao.md\n",
      "Skipping draft document: ./md_content/learning_content/resources.md\n",
      "Skipping draft document: ./md_content/learning_content/name-contest.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2020-dcos-maintenance.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2023-04-computational-scientist-position.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2019-september-maintenance-notes.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2019-september-scratch-notes.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2018-fall-workshops.md\n",
      "Skipping draft document: ./md_content/learning_content/post/2018-spring-workshops.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/resources.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/use-cases.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/lab-computing.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/secure-computing.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/hipaa-compliance.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/x2go.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/cufflinks.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/samtools.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/sicer.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mariadb.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/postgresql.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mongodb.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mysql.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-linux-sw/image-processing/imagej.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/x2go.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/cufflinks.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/samtools.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/idl.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/sicer.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mariadb.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/postgresql.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/sql-server.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mongodb.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mysql.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/image-processing/axiovision.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/ivy/ivy-windows-sw/image-processing/imagej.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/storage/storage-options.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/storage/non-sensitive-data.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/accord/accord-support.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/omero/_index.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/anaconda.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/index.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/bowtie-docker.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/aws-cli.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/bioinformatics-pipelines.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/jq.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/google-cloud-sdk.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/aws-bioinformatics.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/awscli-powershell.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/boto3.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/rstudio-docker.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/s3.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/domino-data-lab.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/ebs-storage.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/bowtie.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/reference/docker.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/howtos/rivanna/gpu-training.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/howtos/general/redis.md\n",
      "Skipping draft document: ./md_content/learning_content/userinfo/howtos/general/mysql.md\n",
      "Skipping draft document: ./md_content/learning_content/service/consult.md\n",
      "Skipping draft document: ./md_content/learning_content/service/grant-support.md\n",
      "Skipping draft document: ./md_content/learning_content/service/collaboration.md\n",
      "Skipping draft document: ./md_content/learning_content/service/map.md\n",
      "Skipping draft document: ./md_content/learning_content/about/staff.md\n",
      "Skipping draft document: ./md_content/learning_content/about/employment.md\n",
      "Skipping draft document: ./md_content/learning_content/project/cloud-migrations.md\n",
      "Skipping draft document: ./md_content/learning_content/project/basic-science.md\n",
      "Skipping draft document: ./md_content/learning_content/project/clinical-research.md\n",
      "Skipping draft document: ./md_content/learning_content/form/sns-test.md\n",
      "Skipping draft document: ./md_content/learning_content/form/support-request-attachments.md\n",
      "Skipping draft document: ./md_content/learning_content/form/support-request-orig.md\n",
      "Skipping draft document: ./md_content/learning_content/form/skyline.md\n",
      "Skipping draft document: ./md_content/learning_content/form/test-form.md\n",
      "Skipping draft document: ./md_content/learning_content/form/support-request-vRedesign.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/storage-ptao.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/fdm.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/omero-ptao.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/database.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/containers-ptao.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/omero.md\n",
      "Skipping draft document: ./md_content/learning_content/form/retired/allocation-purchase-ptao.md\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "def load_documents(path):\n",
    "    documents = []\n",
    "\n",
    "    for file in glob.glob(path, recursive=True):\n",
    "        # Load markdown files from the specified directory\n",
    "        loader = UnstructuredMarkdownLoader(\n",
    "            file_path=file,\n",
    "            mode='single',\n",
    "            source_type='markdown'\n",
    "        )\n",
    "    \n",
    "        markdown_docs = loader.load()\n",
    "\n",
    "        # check frontmatter. see if draft = true. if true, skip.\n",
    "        if markdown_docs[0].page_content.startswith('+++'):\n",
    "            frontmatter_end = markdown_docs[0].page_content.find('+++', 3)\n",
    "            if frontmatter_end != -1:\n",
    "                frontmatter = markdown_docs[0].page_content[3:frontmatter_end].strip()\n",
    "                if 'draft = true' in frontmatter:\n",
    "                    print(f\"Skipping draft document: {file}\")\n",
    "                    continue\n",
    "\n",
    "        documents.extend(markdown_docs)\n",
    "\n",
    "    # if page_content for any document is non-unique, remove duplicates\n",
    "    unique_documents = {doc.page_content: doc for doc in documents}\n",
    "    documents = list(unique_documents.values())\n",
    "\n",
    "    for doc in documents:\n",
    "        doc.metadata['source_type'] = 'markdown'\n",
    "        doc.metadata['source'] = doc.metadata.get('source', 'unknown')\n",
    "        doc.metadata['chunk_number'] = 1  # Assuming single chunk for markdown files\n",
    "    \n",
    "    return documents\n",
    "\n",
    "markdown_documents = load_documents('./md_content/**/*.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8024bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionDeleteEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 937 markdown documents.\n",
      "Marked document with id markdown_./md_content/web_content/resources.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/support.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/search.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/name-contest.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/thank-you.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/signup.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2026-hpc-maintenance-dates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-september-17-open-house.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-june-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-04-women-in-hpc.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-dcos-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2021-december-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-september15-matlab-seminar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-04-RCExhibition-Awards.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-december-maintenance-update-3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-october-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/scratch-policy.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-march-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-february-exhibition.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-rivanna-maintenance-dates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-march-rivanna-software.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-jan-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-may-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-Call-for-Posters.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-december-maintenance-update-4.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2021-remaining-maintenance-days-2021.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-women-in-hpc-20230404.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-workshop-survey.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2021-its-home-dirs.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-04-computational-scientist-position.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/what-is-research-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-oct-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-december-maintenance-announcement.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-hpc-maintenance-dates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/afton-dedication.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-may-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-february-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-december-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-knl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-september22-matlab-seminar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-women-in-hpc-20241105.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-june-r_updates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-fall-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-women-in-hpc-202208.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/lolaweb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-december-mainenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2021-october-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-july-scratch-purge.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-july-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-DAC-Awards.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-july-afton-release.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-03-matlab-seminar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-oct-anaconda-transition.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-08-accord-commmunity-meeting.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-women-in-hpc-20240903.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2021-june-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-women-in-hpc-202301.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-DAC-Fellowship.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-oct-ivy-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-may-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-december-maintenance-update-1.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-september-maintenance-notes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-jira-downtime.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-RC-event.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2024-aug-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-june-rivanna-accounting.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-september-scratch-notes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2018-fall-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-may-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-december-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-summer-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-september22-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-globus-scratch-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2019-sept17-notes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-july-scratch-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/alphafold.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-01-women-in-hpc.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2023-women-in-hpc-20230919.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/job-postings.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2025-april-ssz-h200-announcement.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/featured-projects.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2018-spring-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2020-december-maintenance-update-2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/post/2022-rivanna-maintenance-dates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/globus.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/resources.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/microservices.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/use-cases.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/pricing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/systems.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/computing-environments.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/lab-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/secure-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/transition_new_r_libraries.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hipaa-compliance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/user-guide.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/access-ci.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/data-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/r_updates.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/tools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/xsede.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/image-processing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/x2go.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/complete-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/cufflinks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/samtools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/bowtie2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/sw-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/hisat2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/bioinformatics/sicer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/productivity/libreoffice.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mariadb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/postgresql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/sw-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mongodb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/database/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/image-processing/imagej.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/programming/openjdk-8.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/programming/perl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/matlab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/r.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/anaconda.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/stata.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/sas.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/ctakes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/idl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/sw-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-linux-sw/data-analysis/rodeo.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/image-processing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/x2go.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/cufflinks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/samtools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/bowtie2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/idl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/sw-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/hisat2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/bioinformatics/sicer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/productivity/microsoft-office-professional-plus.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/productivity/sumatrapdf.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mariadb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/postgresql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/sql-server.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mongodb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/database/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/image-processing/axiovision.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/image-processing/imagej.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/programming/openjdk-8.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/programming/perl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/programming/strawberry-perl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/matlab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/r.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/anaconda.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/stata.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/sas.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/ctakes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/idl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/sw-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/rodeo.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/ivy/ivy-windows-sw/data-analysis/spss.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/linux/uva-anywhere-vpn-linux.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/research-project.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/sensitive-data.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/cloud.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/storage-options.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/research-standard.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/personal-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/non-sensitive-data.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/data-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/storage/data-sensitivity.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/k8s/deployments.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/jupyter.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/theia.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/userguide.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/rstudio.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/about.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/faq.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/security.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/environments.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/accord-support.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/accord/projects.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/omero/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/anaconda.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/bowtie-docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/aws-cli.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/bioinformatics-pipelines.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/jq.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/google-cloud-sdk.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/aws-bioinformatics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/awscli-powershell.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/boto3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/rstudio-docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/s3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/domino-data-lab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/ebs-storage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/bowtie.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/reference/docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/access.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/basepod.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/slurm.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/login.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/storage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/slurm-script-generator.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/ood/fileexplorer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/ood/jobcomposer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/ood/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/ood/desktop.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/cyberduck.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/fastx.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/mobaxterm.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/filezilla.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/cl-data-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/rivanna-ssh.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/logintools/graphical-sftp.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/matlab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/r.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/libraries.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/vasp.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/sagemath.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/mathematica.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/clara-parabricks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/miniforge.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/openfoam.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/singularity.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gnupg.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gurobi.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/samtools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/intel.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/fiji.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/ide.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/rstudio.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/workflow_managers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/math-statistics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/cellranger.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/amber.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/blender.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/sas.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/picard.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gatk.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/berkeleygw.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gaussian.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gromacs.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/abinit.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/machine-learning.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/pytorch.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/cellranger-atac.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/bowtie2.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/namd.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/perl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/physics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/python.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/texlive.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/apptainer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/blast.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/deeplabcut.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/containers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/cellprofiler.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/compilers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/ansys.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/yambo.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/debuggers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/code-server.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/modules.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/chemistry.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/lammps.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/gpu.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/tensorflow.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/quantumespresso.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/rapidsai.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/wdltool.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/bioconda.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/complete-list.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/bioinformatics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/bwa.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/nvhpc.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/cromwell.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/imageprocessing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/jupyterlab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/smrtlink.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/totalview.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/alphafold.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/julia.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/orca.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/snakemake.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/mpi.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/spark.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/paraview.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/hpc/software/engineering.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/faq/storage-faq.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/faq/rivanna-faq.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/faq/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/ivy/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/ivy/secure-globus-transfer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/storage/drive-mapping.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/storage/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/storage/aws-s3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/storage/globus-cli.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/docker-images-on-rivanna.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/clear-ood-session-files.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/image-processing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/gpu-training.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/compiler-howto.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/mpi-howto.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/load-module-in-jupyter.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/convert-jupyter-pdf.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/make.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/add-packages-to-container.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/mpi-tutorial.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/bioinfo-on-rivanna.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/custom-jupyter-kernels.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/launch-rserver.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/wdl-bioinformatics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/jupyter-to-python-script.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/rivanna/migrate-python.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/general/docker-basics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/general/redis.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/general/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/general/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/userinfo/howtos/general/sshkeys.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/consult.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/cloud.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/grant-support.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/status.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/high-performance-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/collaboration.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/map.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dtc.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/imaging.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/tiers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dac.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/bioinformatics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/acknowledgement.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dac/past_awardees.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dac/ai.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dac/awards.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dtc/contact.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/service/dtc/grants.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/staff.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/mission.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/employment.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/students.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/vo.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/tomar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/losen.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/periyasamy.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/khan.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/sun.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/lin.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/quist.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/andino.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/addakula.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/vu.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/bobar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/jpark.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/ptak.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/boakyedanquah.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/parece.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/tran.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/siller.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/baller.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/duy.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/chamakuri.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/sheikhzada.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/kureishi.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/linehan.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/hongyan.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/co.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/garrevenkata.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/alabi.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/siadaty.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/eubanks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/kim.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/wang.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/hall.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/strumpf.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/prakash.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/galitz.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/mistele.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/park.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/shankar.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/hussein.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/huband.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/triant.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/xu.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/holcomb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/about/people/orndorff.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/epihet.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/calcium-oscillations.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/age-mvc.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/johnson-steven.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/guagliardo.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/simpleCache.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/cloud-migrations.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/dest.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/smooth-muscle-cells.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/covid-saliva.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/functional-connectome.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/esfarjani-aladyn.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/bii-covid.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/basic-science.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/primed.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/radiology-tustison-stone.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/refgenie.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/ncaa.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/political-sentiment.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/nicu-bpd.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/nicu-vital-signs.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/lolaweb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/brodie-biology.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/ercp.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/bartweb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/sink-microbiome.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/ciliberto-economics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/sonomicrometry-signal.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/shukla-nikhil.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/cardiovascular-genomics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/periasamy-flim.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/transcription-factor.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/surgical-research.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/clinical-research.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/arctic.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/ed-triage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/zhigilei-materialsci.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/project/reidenbach-envirosci.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/education/courses.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/education/rivanna-instructional.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/education/workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/accord.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/dedicated-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/sns-test.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/support-request-attachments.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/combined-request-form.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/allocation-purchase.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/support-request-orig.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/allocation-instructional.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/skyline.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/support-request.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/containers.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/README.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/storage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/test-form.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/allocation-standard.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/support-request-vRedesign.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/storage-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/fdm.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/omero-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/database.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/containers-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/omero.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/web_content/form/retired/allocation-purchase-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/resources.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/name-contest.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2020-dcos-maintenance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2023-04-computational-scientist-position.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2019-september-maintenance-notes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2019-september-scratch-notes.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2018-fall-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/post/2018-spring-workshops.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/resources.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/use-cases.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/lab-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/secure-computing.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/hipaa-compliance.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/x2go.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/cufflinks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/samtools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/bioinformatics/sicer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mariadb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/postgresql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mongodb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/database/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-linux-sw/image-processing/imagej.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/x2go.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/cufflinks.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/samtools.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/idl.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/bioinformatics/sicer.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mariadb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/postgresql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/sql-server.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mongodb.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/database/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/image-processing/axiovision.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/ivy/ivy-windows-sw/image-processing/imagej.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/storage/storage-options.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/storage/non-sensitive-data.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/accord/accord-support.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/omero/_index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/anaconda.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/index.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/bowtie-docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/aws-cli.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/bioinformatics-pipelines.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/jq.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/google-cloud-sdk.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/aws-bioinformatics.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/awscli-powershell.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/boto3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/rstudio-docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/s3.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/domino-data-lab.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/ebs-storage.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/bowtie.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/reference/docker.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/howtos/rivanna/gpu-training.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/howtos/general/redis.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/userinfo/howtos/general/mysql.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/service/consult.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/service/grant-support.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/service/collaboration.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/service/map.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/about/staff.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/about/employment.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_ssh.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/project/cloud-migrations.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/project/basic-science.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/project/clinical-research.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/sns-test.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/support-request-attachments.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/support-request-orig.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/skyline.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/test-form.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/support-request-vRedesign.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/storage-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/fdm.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/omero-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/database.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/containers-ptao.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/omero.md_1 for removal from the vector store.\n",
      "Marked document with id markdown_./md_content/learning_content/form/retired/allocation-purchase-ptao.md_1 for removal from the vector store.\n",
      "Total documents to remove: 540\n",
      "937\n"
     ]
    }
   ],
   "source": [
    "# USE THIS BLOCK TO REMOVE DRAFTS AND DUPLICATES\n",
    "\n",
    "print(f\"Loaded {len(markdown_documents)} markdown documents.\")\n",
    "\n",
    "# remove documents not in markdown_documents from collection\n",
    "\n",
    "all_valid_documents = [doc.metadata['source_type'] + \"_\" + doc.metadata['source'] + \"_\" + str(doc.metadata['chunk_number']) for doc in markdown_documents]\n",
    "all_valid_documents_set = set(all_valid_documents)\n",
    "\n",
    "documents = vector_store.get(include=[\"documents\"])\n",
    "\n",
    "to_remove = []\n",
    "for doc, id in zip(documents[\"documents\"], documents[\"ids\"]):\n",
    "    if id not in all_valid_documents_set:\n",
    "        to_remove.append(id)\n",
    "        print(f\"Marked document with id {id} for removal from the vector store.\")\n",
    "\n",
    "print(f\"Total documents to remove: {len(to_remove)}\")\n",
    "print(len(markdown_documents))\n",
    "vector_store.delete(ids=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2996945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 1476\n",
      "[Batch 1207 of 1477]\n",
      "Found 1206 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/section2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: II - Files and Directories date: 2023-12-11T00:00:00-05:00 type: docs toc : true weight: 20 menu: hpc-from-terminal:\\n\\nFiles and Directories\\n\\nFiles store some sort of information: data, source code for scripts or programs, images, video, and so forth.\\n\\nThere are two basic types of files: * Text (documents, code) * Binary (images, executables)\\n\\nThe Unix shells ignore file extensions, but software might require certain extensions. This includes compilers (.cxx, .f90 and so forth), interpreters (.py, .R, etc.), image and video tools (.png, .jpg, .mp4). Since the format of the file extension depends on the expectations of software or on user preference, there is no rule limiting the number of characters, but most consist of one to three characters.\\n\\nDirectories are collections of files and other directories. Often they are called folders, but directory is generally the preferred (and historical) term in Unix.\\n\\nDirectories that are stored within another directory are subdirectories of the parent.\\n\\nBoth files and directories have metadata associated with them such as name, timestamps, and permissions.\\n\\nThe names of Unix files and directories should contain no spaces. ```bash $ls\\n\\n\\'10. directories.md\\' \\'15. streams.md\\' ``` The quotes indicate that a space is part of the file name. While most modern Unix tools can handle spaces, the shell does not always do so, and special precautions must be taken to avoid surprises. For that reason, underscores or hyphens are preferred instead of spaces.\\n\\nPaths\\n\\nIn most operating systems, all files and directories are located with a path. The path is the \"full name\" of every file & directory.\\n\\nIn a Unix-based operating system, the files are organized into a tree structure (the method to store and organize the files is called filesystem, e.g. ext3,ext4, NTFS, etc). The tree is \"upside down\" because the root directory is at the top, and directories branch off from there. The root directory is indicated with a forward slash /.\\n\\n{{< diagram >}} graph TD C[\"/\"] --> etc[\"etc\"] C[\"/\"] --> opt[\"opt\"] C[\"/\"] --> lib[\"lib\"] C --> usr[\"usr\"] C --> home[\"home\"] C --> var[\"var\"]\\n\\nhome --> mst3k[\"mst3k\"]\\nhome --> im4u[\"im4u\"]\\n\\nmst3k-->myfile[\"myfile\"]\\nmst3k-->mydir[\"mydir\"]\\n\\nmydir-->file1[\"file1\"]\\nmydir-->file2[\"file2\"]\\n\\nusr--> bin[\"bin\"]\\nusr--> share[\"share\"]\\nusr--> local[\"local\"]\\n\\nbin--> ls[\"ls\"]\\nbin--> pwd[\"pwd\"]\\nbin--> cd[\"cd\"]\\n\\n{{< /diagram >}}\\n\\nThe home directory is the usual name on Linux and similar Unix-based operating systems for the folder that holds user directories and files. On macOS it is called User. On both, the separator between branches of the tree is the forward slash.\\n\\n{{< hl >}} /home/mst3k/myfile {{< /hl >}} {{< hl >}} /Users/Misty Tea/Documents/Homework.pages {{< /hl >}}\\n\\nWindows files and folders also have paths. In Windows, drive letters or volumes are the top-level folders, and usually there is more than one. User files are in Users, similar to macOS.\\n\\n{{< hl >}} C:\\\\Users\\\\Misty Tea\\\\Documents\\\\Homework.docx {{< /hl >}}\\n\\nAbsolute and Relative Paths\\n\\nPaths may be absolute or relative.\\n\\nAn absolute path is path to a file or folder starting at the root. On Unix it will begin with /, to designate the root.\\n\\nAn absolute path is guaranteed to get you to the location you want.\\n\\nA relative path is the path to a file starting at the current location. We use the notation . (a single period) for the current working directory, and .. (two periods) for the parent of the current working directory.\\n\\nExamples\\n\\nAbsolute paths: no-highlight /home/mst3k/file.txt /home/mst3k/files/file.txt /home/mst3k/projects/project1 /home/mst3k/projects/project1/output.txt Note that /home/mst3k/file.txt and /home/mst3k/files/file.txt are different files unless you explicitly link them.\\n\\nRelative paths. Suppose we are in the /home/mst3k/files folder. no-highlight ./file.txt ../files/file.txt The relative path to file.txt in files from the project1 folder is no-highlight ../../files/file.txt\\n\\nTilde Notation\\n\\nIn Unix the tilde ~ stands for the user\\'s home directory, e.g. /home/mst3k. no-hightlight ls ~ ls ~/files\\n\\nFile Commands\\n\\nls\\n\\nls lists files in a directory. bash $ls With no argument, listing the entire contents of the current working directory is assumed.\\n\\nLike most Unix commands, it has many options. They may be combined.\\n\\n{{< table >}} | Option | Purpose | |-------|-----| |-l | long listing, includes file date, size, and permissions | |-a | displays all files including hidden (dotfiles) | |-h | show file sizes in human-readable terms | |-C | lay out listing in columns | |-1 | (digit one) list one file per line, no header | |-t | show the newest files first | |-r | reverse the order | |-F |append a symbol to indicate the type of file (ordinary, executable, directory) | {{< /table >}}\\n\\nbash $ls -ltr ./projects\\n\\ncp\\n\\ncp to copy a file. bash $cp file1.txt file2.txt $cp mymod.py ../projects/python_code\\n\\nCommonly-used options:\\n\\n{{< table >}} | Option | Purpose | |-------|-----| | -i | ask for confirmation before overwriting an existing file | | -r | copy recursively all subdirectories| | -n | \"noclobber\"; do not overwrite an existing file| | -f | force an overwrite of an existing file| {{< /table >}}\\n\\nbash $cp -r /share/resources/tutorials/rivanna-cl ~\\n\\nmv\\n\\nmv to rename or move a file. bash $mv file1.txt file2.txt $mv mymod.py ../projects/python_code\\n\\nOptions for mv are similar to cp.\\n\\nrm\\n\\nrm to remove a file or directory\\n\\nbash $rm file1.txt $rm file1.txt data.csv Once the file is removed, it is gone and can no longer be accessed.\\n\\nOptions for rm are similar to cp.\\n\\n{{< warning >}} By default, the rm command does not ask for confirmation before deleting a file! Use the -i option if you are unsure. {{< /warning >}}\\n\\nDirectory Commands\\n\\ncd\\n\\ncd change directory bash $cd With no argument, cd moves to the user\\'s home directory. If you are hopelessly lost, you can always type cd and start over.\\n\\nbash $cd ../projects/project1\\n\\nmkdir\\n\\nmkdir to create a directory. Works relative to current working directory. bash $mkdir new_project or bash $mkdir new_project $mkdir ~/projects/new_project/src\\n\\nrmdir\\n\\nrmdir to remove an empty directory. Does not affect directories with content. bash $rmdir ~/projects/new_project/src\\n\\nrm -rf\\n\\nrm -rf to force the removal of a directory and all its contents, including subdirectories.\\n\\nbash $rm -rf ~/projects/project1/src\\n\\ncp -r\\n\\nDirectories are copied with the cp -r command previously discussed.\\n\\nExercise\\n\\nStart a terminal on a loginnode by whatever means you prefer. Type (the $ is the prompt and is not typed):\\n\\nbash $echo $SHELL $pwd $mkdir test_dir $cd test_dir $ls .. $mkdir sub_dir $ls\\n\\nQ1: What is the full path of your home directory?\\n\\nQ2: Delete the sub_dir folder.\\n\\nQ3: Copy the directory /share/resources/tutorials/rivanna-cl/shakespeare into your home directory.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1208 of 1477]\n",
      "Found 1207 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/section4.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: IV - I/O, Pipes and Processes date: 2023-12-11T00:00:00-05:00 type: docs toc: true weight: 40 menu: hpc-from-terminal:\\n\\nWildcards\\n\\nWildcards are special characters that can stand for strings. Wildcards enable you to work with groups of files without needing to type multiple files with similar names.\\n\\nThe asterisk * can replace zero to unlimited characters except for a leading period.\\n\\nThe question mark ? replaces exactly one character.\\n\\nExamples bash $ls *.py $cd array_test $ls input?.dat $ls input??.dat $ls input*.dat $rm list?.sh\\n\\n{{< warning >}} BE CAREFUL when using wildcards with rm! Gone is gone! On some systems there may be backups, or there may not be, and on your personal system you would need to set up backups and learn to retrieve files. It is advisable to first run an ls with the pattern you plan to use with rm. {{< /warning >}}\\n\\nStandard Streams\\n\\nEach executable has associated with it three input/output streams: standard input , standard error , and standard output. Normally these streams come from or go to your console (i.e. your terminal).\\n\\nMost Unix commands read from standard input and/or write to standard output.\\n\\nThese I/O streams are often represented as stdin, stderr, and stdout.\\n\\nThe Unix commands we have studied so far all write to standard output.\\n\\nbash $ls -l produces output to the terminal.\\n\\nStandard Stream Redirection\\n\\nThe standard streams are normally associated with the console. The command will print to the terminal, or will read input typed into the terminal. Stdin and stout can also be redirected to write to or read from a file.\\n\\nRedirect standard input with < bash $./mycode < params.txt\\n\\nRedirect standard output with > bash $ls l > filelist.txt\\n\\nIf the file exists, > will overwrite it. Append with >>. bash $cat file1 >> bigfile.csv\\n\\nRedirection of standard error depends on the shell and is needed for only a few commands.\\n\\nFor bash bash $make >& make.out redirects both stdout and stderr from the make command to make.out.\\n\\nPipes\\n\\nOne of the most powerful properties of Unix is that you can pipe the standard output of one command into the standard input of another.\\n\\nThe pipe symbol | is above the backslash on most US keyboards. Pipes can be chained indefinitely, though most uses need just one. no-highlight cmd1 | cmd2 | cmd3\\n\\nExample\\n\\nCommands such as ls have lengthy manpages that will tend to scroll off our terminal window. bash $man ls | more Now we can page through the listing.\\n\\nFinding and Searching Files\\n\\nSearching with grep\\n\\nThe grep command is commonly used in UNIX to filter a file or input, line by line, against a pattern. Patterns can be complex and use regular expressions, but most of the time wildcards are sufficient.\\n\\nno-highlight grep [OPTIONS] PATTERN FILENAME Example\\n\\nThe -i option stands for \"ignore case.\" bash $grep -i Unix intro_basic-unix.txt\\n\\nGrep is frequently used with wildcards and pipes. bash $grep -i write *f90 $grep weight: *md | grep 100\\n\\nExample\\n\\nHow many sequences are in a FASTA-formatted file? Each sequence record in a FASTA file has one line of description that always starts with >, followed by multiple lines of the sequence itself. Each sequence record ends when the next line starts with >.\\n\\nbash $grep -c \\'>\\' sequences.fasta The -c option returns the number of lines containing the pattern. Please be sure to include the quotes around the > or the shell will interpret it as a redirection.\\n\\nA Handy Trick\\n\\nTo find all occurrences of a pattern in all files in a directory, use grep -r. bash $grep -r \"print\" python_programs Be careful with the pattern for a recursive search, or the output can be excessive.\\n\\nFinding Files by Name\\n\\nThe find command can locate a file if you cannot remember its directory. It can take wildcards, in which case it is best to use quotes around the name pattern.\\n\\nbash $find . -name 2col.txt ./shakespeare/2col.txt $find . -name \"people*\" ./data/people.txt The period . tells find to start at the current working directory.\\n\\nFind has many options to locate files by name, type, date, and others. See here for examples.\\n\\nRunning Executables\\n\\nExecutables are often also called binaries. The terms are synonymous in most cases.\\n\\nThe shell has a predefined search path. It will look in a sequence of directories for an executable with the specified name, and will invoke the first one it encounters. If the executable is in this search path, you can simply type its name at the prompt.\\n\\nbash $gedit hello_world.sh\\n\\nhere gedit is the name of the executable. Its actual location is /usr/bin/gedit, but /usr/bin is in the default search path.\\n\\nIf the location of the binary is not in your search path, you must type the path to the executable (it can be absolute or relative)\\n\\nbash $./hello_world.sh\\n\\nFor security reasons the current directory is not in your default search path. Hence you must explicitly provide the ./ path to execute a binary in the current directory. If you wish to add it, type (for bash) bash $export PATH=$PATH:. PATH is called an environment variable. It holds the list of paths to be searched by the shell. In this example it is essential to add the first $PATH or you will lose the default path set by the system.\\n\\nIf you are unsure of the path to the binary you wish to run, the which command will tell you the path to the binary the shell will start. bash $which g++ /apps/software/standard/core/gcc/11.4.0/bin/g++\\n\\nProcess Control\\n\\nA running executable is a process to the Unix operating system. When it is run at a command line, a process can be running in the foreground, which suppresses a prompt, or in the background, which returns a prompt to the shell.\\n\\nTo start in the background, add an ampersand & at the end of the command. bash $./myexec -o myopt myfile&\\n\\nManaging Processes\\n\\nThe jobs command lists your running jobs (processes) with their job index.\\n\\nThe key combination control-z (ctrl-z or ^z) suspends the foreground job. To resume the job in the background, type bg.\\n\\nThis can be combined with output from jobs bash $bg %1 # place the job number 1 into the background $fg %4 # place the job number 4 back to the foreground\\n\\nFor more general information about processes, use ps (process status) The -u option limits it to processes owned by user mst3k. bash $ps -u mst3k PID TTY TIME CMD 498571 ? 00:00:00 systemd 498575 ? 00:00:00 (sd-pam) 498581 ? 00:00:00 pulseaudio 498582 ? 00:00:00 sshd 498593 pts/3 00:00:00 bash 498665 ? 00:00:00 dbus-daemon 498670 ? 00:00:00 dbus-daemon 498672 ? 00:00:00 dbus-kill-proce 498677 ? 00:00:00 gio 498685 ? 00:00:00 gvfsd 498691 ? 00:00:00 gvfsd-fuse 517189 pts/3 00:00:00 ps\\n\\nThe pid is the process id.\\n\\nKilling Processes\\n\\nYou have accidentally started a production job on a loginnode node. What to do?\\n\\nYou can kill your foreground process with Crtl c. ```bash\\n\\noops, I was supposed to run this through Slurm\\n\\n$./myexe ^c ```\\n\\nIf you need to kill a background process, you can use jobs to locate and foreground it. You may also have processes that don\\'t appear with jobs. Use ps to find the PID, then bash $kill -9 <pid> Do not type the angle brackets, just the number. Many processes will ignore the kill command without the -9 option so we routinely include it.\\n\\nTo kill by executable name bash $killall -9 <executable name> The kill command with -9 immediately kills the process without allowing the process to clean up or save data. The killall command can be used to kill all the processes that match a specific name or pattern.\\n\\nIf you find yourself in a jam and do not know what is wrong and you must start over, bash $kill -9 -1 kills all your processes, including your login.\\n\\nDotfiles\\n\\nDotfiles are files that describe resources to programs that look for them. They begin with a period or dot (hence the name). In general, they are used for configuration of various software packages.\\n\\nDotfiles are hidden from ls, but ls -a shows them. Sometimes ls is aliased to ls a.\\n\\nBash has configuration dotfiles: .bash_profile and .bashrc. * if no .bash_profile is present it will read .profile * .bash_profile is sourced only for login shell * the default .bash_profile on our HPC system incorporates the .bashrc; otherwise on a general Linux system, .bashrc is not run for a login shell.\\n\\nDot \"files\" may also be, and often are, directories.\\n\\nbash $ls -a . .bash_logout .bashrc .lesshst shakespeare .Xauthority .. .bash_profile data .mozilla .ssh')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1209 of 1477]\n",
      "Found 1208 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/section5.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: V - HPC Specifics date: 2023-12-11T00:00:00-05:00 type: docs toc: true weight: 50 menu: hpc-from-terminal:\\n\\nMost high-performance computing clusters have commands that are specific to that environment, and are not part of Unix per se.\\n\\nHome Directory\\n\\nThe default home directory provides 50GB of storage capacity, e.g., /home/mst3k. Each user also has access to 10 TB of temporary storage in the \"scratch\" folder, e.g. /scratch/mst3k\\n\\nThe /home and /scratch directories are for personal use and not shareable with other users.\\n\\n{{< warning >}} /scratch is NOT permanent storage and files that have not been accessed for more than 90 days will be marked for deletion. {{< /warning >}}\\n\\nResearch groups can lease permanent storage.\\n\\nChecking Your Storage\\n\\nTo see how much disk space, you have used in your home and scratch directories, open a terminal window and type hdquota at the command-line prompt:\\n\\nbash $hdquota Type Location Name Size Used Avail Use% ======================================================================= home /home mst3k 51G 12G 39G 24% Scratch /project slurmtests 2.0P 1.9P 144T 93% Project /project arcs 16T 12T 3.8T 75% Project /project rivanna_software 1.1T 4.2M 1.0T 1% Project /project ds5559 51G 3.7G 47G 8% Value /nv vol174 5.5T 1.2T 4.4T 21%\\n\\nNote: only home, and other storage just for some\\n\\nChecking Your Allocation\\n\\nTo see how many SUs you have available for running jobs, type at the command-line prompt allocations.\\n\\nbash $allocations Allocations available to Misty Tea (mst3k): ds5559: less than 25,000 service-units remaining ga_bioinfo-test: less than 100,000 service-units remaining\\n\\nFor more information about a specific allocation, please run bash $allocations -a <allocation name>\\n\\nThe Modules Environment\\n\\nEnvironment modules are not strictly a part of Unix, but are widely used by many HPC sites, including ours. Modules enable the user to set complex paths, environment variables, and so forth, simply by loading a module.\\n\\nThe commands are set up automatically when you log in. Loaded modules only affect the shell in which the command is run.\\n\\nModules required for a job must be loaded in the batch job script.\\n\\nModule Commands\\n\\n{{< table >}} | Command | Result | | ------- | ------ | | module load \\\\<name> | load the default module for the\\n\\nExamples bash $module load gcc $module load matlab/R2023a $module spider R/4.3.1 $module load gcc/11.4.0 openmpi/4.1.4 R/4.3.1 $module purge\\n\\nRunning Jobs\\n\\nIn an HPC environment, the tasks that users want to perform are generically called jobs. These must not be confused with the \"jobs\" of the Unix jobs command, although the concepts are related. An HPC \"job\" is a combination of resource requests, any setup required such as loading modules, and the actual commands required to run the desired software.\\n\\nHPC jobs are run on compute nodes, not on the interactive loginnodes.\\n\\nIn the Introduction we discussed using the OOD job composer to submit and monitor jobs. When working at the command line, we must use more detailed features of Slurm. Please go through our tutorial to learn how to write and submit Slurm scripts from the command line.\\n\\nNeed Help?\\n\\nResearch Computing is ready to help you learn to use our systems efficiently. You can submit a ticket. For in-person help, please attend one of our weekly sessions of office hours.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1210 of 1477]\n",
      "Found 1209 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/section1.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: I - Intro to Unix and Bash Shell date: 2023-12-11T00:00:00-05:00 type: docs weight: 10 toc: true menu: hpc-from-terminal:\\n\\nUNIX\\n\\nUNIX is a text-oriented operating system (OS) originally developed at Bell Labs during the 1960s. Two versions of this OS are dominant today, Linux and macOS.\\n\\nStrictly speaking, \"Linux\" refers just to the kernel, which is the part of an operating system that manages the hardware interfaces. On top of the kernel sits a number of utilities that enable users and applications to interact with the kernel.\\n\\nLinux is the operating system most widely used at HPC facilities, internet servers, and the majority of financial trading system worldwide. A version of Linux powers Android systems.\\n\\nmacOS is based on a slightly different version of Unix.\\n\\nShell\\n\\nIn all version of Unix, the shell is a program that interprets commands and acts as an interface between the user and the kernel.\\n\\nMultiple shells are available. In Linux systems, the default is the bash shell. MacOS formerly defaulted to bash as well, but has recently switched to zsh.\\n\\nThe shell displays a prompt, which indicates that it is ready to accept commands. In this tutorial, we will utilize the dollar sign $ as the prompt; yours may be different, and later in this tutorial we will learn how to customize it to your preferences.\\n\\nTo determine your current shell, at the prompt type\\n\\nbash $echo $SHELL\\n\\nIt is important to keep in mind that Unix in general and the shell in particular is case-sensitive. The commands LS and ls would not be the same.\\n\\nLogging In\\n\\nLogging into a remote UNIX based system requires a program generally called a client. The options for the client depends on your OS.\\n\\nSSH\\n\\nCommand line access through a terminal on your computer is based on the ssh or Secure Shell protocol. It is * Encrypted * Available on most UNIX systems\\n\\nYour ssh client communicates with the ssh server program running on the remote system. Once established, the connection is secure even if the network is insecure.\\n\\nExample\\n\\nIf your computer is a macOS or Linux system, you log in with bash ssh -Y mst3k@login.hpc.virginia.edu Throughout this tutorial we will use mst3k as our example user ID. You should substitute your own. The option -Y allows access to graphical applications and requires that an X11 server application must be installed on your computer. This should be the default for Linux, but macOS users must install XQuartz before this command-line option will be useful.\\n\\nGraphical Applications\\n\\nThe command-line secure shell is not the only option for accessing the HPC system. Windows users in particular may wish to use other methods, since although ssh is available for it, Windows is not particularly friendly to command lines.\\n\\nOpen OnDemand (OOD)\\n\\nOpen OnDemand is a Web-based interface to the system. It provides a graphical file-management interface and access to several popular applications running on the compute nodes. A simple terminal that opens on a loginnode is also provided. See the introduction in our basic tutorial.\\n\\nFastX\\n\\nFastX is a Web-based graphical interface to a loginnode. It is also covered in the introduction.\\n\\nMobaXterm (Windows)\\n\\nMobaXterm combines an ssh client, a sftp client for file transfers, and an X11 server into a single bundle. More details are available at our Website or in the introduction.\\n\\nRunning Shell Commands\\n\\nThe syntax of Unix commands is not completely standardized but in general follow the pattern of a two or three-letter abbreviation followed by command-line options, which are single-letter options preceded by one hyphen or multiple-letter options with two hyphens. Many commands also take arguments.\\n\\nbash $cmd -o --option argument\\n\\nExample\\n\\nInvoke the utility rm to delete a file. bash $rm myfile In this example, the shell issues a request to the kernel to delete myfile. The kernel then communicates with the software that manages file storage to execute the operation.\\n\\nWhen it is complete the shell then returns the UNIX prompt to the user, indicating that it is waiting for further commands.\\n\\nRunning Our First Command\\n\\nLets run our first command. Into a terminal type bash $pwd /home/mst3k This command stands for print working directory. It prints the name of the folder in which the shell is currently working.\\n\\nNavigating the Bash Shell\\n\\nModern shells provide useful \"hotkey\" commands that can save considerable typing. The \"control-\" notation means that the Ctrl (control) key and the following key should be depressed at the same time.\\n\\n{{< table >}}\\n\\nFunction Key Tab completion: expand typed string to as far as it has a unique name. tab Search for earlier command control-r Move to the beginning of the line control-a Move to the end of the line control-e Clear the screen clear or control-l {{< /table >}}\\n\\nBash History\\n\\nWhen using bash you may use its built-in history mechanism to save yourself some keystrokes.\\n\\n{{< table >}} | Function | Key | |-------|-----| |scroll through the previous commands you have typed | up arrow| |if already scrolled back, scroll to more recent commands | down arrow | |edit text on a line | right or left arrow | {{< /table >}}\\n\\nLogging Out\\n\\nTo log out of a shell, type exit bash $exit\\n\\nThis logs you out of your current terminal window. If that is a login window, for example your ssh shell, it will log you out of the system entirely.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1211 of 1477]\n",
      "Found 1210 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Using UVA\\'s HPC System from a Terminal type: docs weight: 1 date: \"2023-12-11T00:00:00\"\\n\\nmenu: hpc-from-terminal:\\n\\nThis tutorial is an introduction to the command-line interface of high-performance computing systems. Well learn how to use commands to perform basic operations in the terminal: creating and navigating directories, listing and displaying files, moving and copying files. We will also cover creating files, searching files, and managing file permissions. Working in the command line, we can combine existing programs and utilities, automate repetitive tasks, and connect to remote resources.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1212 of 1477]\n",
      "Found 1211 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-from-terminal/section3.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: III - File Manipulation date: 2023-12-11T00:00:00-05:00 type: docs toc : true weight: 30 menu: hpc-from-terminal:\\n\\nFile Permissions\\n\\nEach file and directory has a set of permissions associated with it. Traditionally, Unix has assigned permissions to the owner (the user), the group (a set of users), others (users not the owner nor a member of the group that may have permissions on the file), and all (all users on the system). These are generally denoted by ugoa.\\n\\nWithin each category, a user can have permission to read, write, or execute the file. These are denoted by rwx.\\n\\nThe command bash $ls -l shows the permissions associated with each file. Since in Unix a directory is a special type of file, the permissions are the same.\\n\\n```bash $ls -l total 8 drwxr-xr-x. 2 mst3k mst3k 4096 Dec 18 10:39 data drwxr-xr-x. 2 mst3k mst3k 4096 Dec 18 10:22 shakespeare\\n\\n`` The output ofls -l` is\\n\\n{{< table >}} | Permissions | Number of \"Hard Links\" | Owner | Group | Size | Date and Time Last Modified | Name| | ---- | ---- | -------- | ------ | ---- | ----------- | ---- | | drwxr-xr-x | 2 | mst3k | mst3k | 4096 | Dec 18 10:39 | data | {{< /table >}}\\n\\nPermissions not granted to a user are indicated with a hyphen -.\\n\\nThe permissions layout in the first columns should be read as\\n\\n{{< table >}} | Type | Owner | Group Owner | Others | | ---- | -------- | ------ | ---- | | d | rwx | r-x | r-x | {{< /table >}}\\n\\nIn the above example, the d indicates the listing is a directory. A directory must have \"execute\" x permission in order for a user to enter it.\\n\\nListing the files in a directory will result in output such as bash $ls -l shakespeare -rwxr-xr-x. 1 mst3k mst3k 91 Dec 18 10:22 2col.txt -rwxr-xr-x. 1 mst3k mst3k 173940 Dec 18 10:22 Hamlet.txt -rwxr-xr-x. 1 mst3k mst3k 162563 Dec 18 10:22 HamletWords.txt -rwxr-xr-x. 1 mst3k mst3k 34 Dec 18 10:22 k2sort.txt -rwxr-xr-x. 1 mst3k mst3k 180857 Dec 18 10:22 Lear.txt -rwxr-xr-x. 1 mst3k mst3k 154520 Dec 18 10:22 Othello.txt -rwxr-xr-x. 1 mst3k mst3k 25628 Dec 18 10:22 uniques -rwxr-xr-x. 1 mst3k mst3k 25628 Dec 18 10:22 uniques.txt -rwxr-xr-x. 1 mst3k mst3k 72 Dec 18 10:22 wcdemo.txt -rwxr-xr-x. 1 mst3k mst3k 26 Dec 18 10:22 words_and_num.txt The hyphen as Type indicates an ordinary file.\\n\\nChanging Permissions\\n\\nThe owner of a file or directory may change the permissions with the chmod command. Two formats are supported: a three- or four-digit code (in octal, i.e. base 8) indicating permissions, or the add/remove symbolic format. The digit format is advanced so we will not discuss it; a reference is available here. The symbolic format is more intuitive and mnemonic.\\n\\nExamples\\n\\nAdd execute permission to a file for its owner. This is frequently used with shell scripts. bash $chmod u+x ascript.sh\\n\\nAdd execute permissions for the owner and group members bash $chmod ug+x ascript.sh\\n\\nAllow others to read and write a file bash $chmod o+wr myfile.txt\\n\\nPlease note that on multiuser, central systems such as an HPC cluster, the administrators may not allow individual users to change the permissions on certain file sets such as home and scratch directories, for reasons of data security and privacy.\\n\\nCreating and Editing Files\\n\\nTo create files we use a text editor. Do not use a word processor such as LibreOffice.\\n\\nGraphical Options\\n\\nGraphical editors must be used from within a graphical environment. On Linux the standard graphical windowing system is called X11. Newer Linux versions provide some form of \"desktop\" environment similar to Windows or macOS on top of X11. On our system we provide the MATE Desktop Environment. It can be accessed from FastX on a loginnode. It can also be started on a compute node from the Open OnDemand Desktop Interactive Application.\\n\\n1. gedit/pluma\\n\\nModern Linux systems provide at least one graphical text editor. One option is gedit. On the MATE Desktop, the equivalent is pluma, but the gedit command starts pluma.\\n\\nGedit/pluma is very similar to Notepad on Windows.\\n\\n2. VS Code\\n\\nThis is accessed by a module. bash $module load code-server\\n\\nThen open a browser (Firefox is the default on MATE) and go to the URL http://127.0.0.1:8080. First set up would need a password that can be extracted from the file ~/.config/code-server/config.yaml.\\n\\nText-Based File Editors\\n\\nRegular Linux users are advised to learn at least one text-based editor, in case a graphical interface is not available or is too slow.\\n\\n1. vi (vim)\\n\\nThe oldest and most widely available text-based editor on Unix is vi for \"visual.\" Modern versions are nearly all based on vim (\"vi improved). On our system we generally alias the vi command to vim.\\n\\nVim/vi is used entirely through keyboard commands which must be memorized. The mouse is not utilized. Only a few commands are needed to be able to do basic editing and they are not difficult to learn. A beginner tutorial is here. One stumbling block for new users is that vim has command mode and insert mode and it must be toggled between the two.\\n\\nBasics: * To enter the insert mode press i * To enter the command mode press ESC * To save the file enter :w * To save under a new name :w filename * To exit :q\\n\\nMATE also provides a graphical interface called gvim. It can be accessed through the Applications->Accessories menu as Vi IMproved. GVim combines the keyboard-oriented commands of vim with some mouse-based capabilities.\\n\\n2. nano\\n\\nNano is simple text editor that is fairly self-explanatory and simple to learn. It is always in insert mode. A tutorial similar to that for vim above is here.\\n\\nBasics: * Immediately start typing * To exit: control+X * Type the filename and press Enter\\n\\n3. Emacs\\n\\nThe Emacs editor is another long-time editor on Unix. Similar to gvim, it combines a graphical interface, when available, with a keyboard-based command system. If the graphical interface is not available, such as from an Open OnDemand terminal, it will fall back to a text-only interface. Emacs is powerful and complex. The documentation is here.\\n\\nViewing Files\\n\\nPagers\\n\\nThe most widely used way to view files quickly without editing is to use a pager. A pager prints to the terminal window the amount of text that fits in that window. The default pager on Linux is more (also called less because \"less is more\").\\n\\nbash $more filename This displays the contents of a file on the screen with line scrolling. To scroll you can use arrow keys. To advance one line, press the Enter key. To advance a full page, press the space bar. Press q to exit.\\n\\nbash $more ~/rivanna-cl/shakespeare/Lear.txt\\n\\nTo page upward within the text, press b (back).\\n\\nSearching.\\n\\nYou can search in the forward direction with /\\n\\nbash $more ~/rivanna-cl/shakespeare/Lear.text /serpent\\n\\n ...skipping\\n     Turn all her mother\\'s pains and benefits\\n     To laughter and contempt, that she may feel\\n     How sharper than a serpent\\'s tooth it is\\n     To have a thankless child! Away, away!                Exit.\\n\\nSearch stops at the first occurrence. To locate the next one, type n.\\n\\nPrinting a file to the console\\n\\nThe cat (concatenate) command prints the contents of a file to the screen. bash $cat myfile It does not fit the output to the terminal windows size; it simply keeps printing to the end.\\n\\nIt can also be used to create or join files (hence its name). We will learn more about its behavior here when we look at standard streams.\\n\\n```bash\\n\\ncreate a file\\n\\n$cat > newfile Now I can enter some text It will be copied exactly into the file ^d `` The^dnotation means hold downCtrlandd` together. It is the end-of-file marker for bash.\\n\\n```bash\\n\\nappend a file to another\\n\\n$cat otherfile >> newfile `` {{< warning >}} If used single>in place of the double>>in the above,catwill overwritenewfilewithotherfile`. {{< /warning >}}\\n\\nDisplaying Parts of a File\\n\\nhead and tail\\n\\nhead filename\\n\\nDisplays only the starting lines of a file. The default is first ten lines. Use -n to specify the number of lines. bash $head ~/rivanna-cl/shakespeare/Lear.text\\n\\nThis Etext file is presented by Project Gutenberg, in\\ncooperation with World Library, Inc., from their Library of the\\nFuture and Shakespeare CDROMS.  Project Gutenberg often releases\\nEtexts that are NOT placed in the Public Domain!!\\n\\n*This Etext has certain copyright implications you should read!*\\n\\n<<THIS ELECTRONIC VERSION OF THE COMPLETE WORKS OF WILLIAM\\nSHAKESPEARE IS COPYRIGHT 1990-1993 BY WORLD LIBRARY, INC., AND IS\\nPROVIDED BY PROJECT GUTENBERG WITH PERMISSION.  ELECTRONIC AND\\n\\ntail filename\\n\\nDisplays the last 10 lines. bash $tail 30 ~/rivanna-cl/shakespeare/Lear.text\\n\\n     The cup of their deservings.- O, see, see!\\n  Lear. And my poor fool is hang\\'d! No, no, no life!\\n     Why should a dog, a horse, a rat, have life,\\n     And thou no breath at all? Thou\\'lt come no more,\\n     Never, never, never, never, never!\\n     Pray you undo this button. Thank you, sir.\\n     Do you see this? Look on her! look! her lips!\\n     Look there, look there!                            He dies.\\n  Edg. He faints! My lord, my lord!\\n  Kent. Break, heart; I prithee break!\\n  Edg. Look up, my lord.\\n  Kent. Vex not his ghost. O, let him pass! He hates him\\n     That would upon the rack of this tough world\\n     Stretch him out longer.\\n  Edg. He is gone indeed.\\n  Kent. The wonder is, he hath endur\\'d so long.\\n     He but usurp\\'d his life.\\n  Alb. Bear them from hence. Our present business\\n     Is general woe. [To Kent and Edgar] Friends of my soul, you\\n        twain\\n     Rule in this realm, and the gor\\'d state sustain.\\n  Kent. I have a journey, sir, shortly to go.\\n     My master calls me; I must not say no.\\n  Alb. The weight of this sad time we must obey,\\n     Speak what we feel, not what we ought to say.\\n     The oldest have borne most; we that are young\\n     Shall never see so much, nor live so long.\\n                                       Exeunt with a dead march.\\n\\nTHE END\\n\\nTransferring Files Using the Command Line\\n\\nFiles can be transferred by graphical clients such as MobaXterm and Filezilla, or through Globus. If you are using a terminal from your local computer, you can also use some command-line tools.\\n\\nscp and sftp\\n\\nThe secure shell protocol includes two file-transfer command-line tools; scp and sftp. Sftp is scp with a slightly different interface.\\n\\nbash $scp LOCAL_FILE mst3k@login.hpc.virginia.edu:REMOTE_PLACE $scp mst3k@login.hpc.virginia.edu:REMOTE_FILE LOCAL_PLACE REMOTE_PLACE and LOCAL_PLACE refer to the location on the appropriate host where you want the file to be written. REMOTE_PLACE can be omitted and the file will be transferred to your home directory under the same name. To change the name or specify a directory on the other system, use a different name or path for REMOTE_PLACE.\\n\\nLOCAL_PLACE must be present but can be . for the directory where the scp was run.\\n\\nThe colon : is required.\\n\\nTo copy a directory, use scp -r similarly to cp -r.\\n\\nExamples bash $scp myfile.txt mst3k@login.hpc.virginia.edu: $scp myscript.py mst3k@login.hpc.virginia.edu:project1 $scp myscript.py mst3k@login.hpc.virginia.edu:script.py $scp myfile.csv mst3k@login.hpc.virginia.edu:/scratch/mst3k $scp mst3k@login.hpc.virginia.edu:/scratch/mst3k/run11/output.txt .\\n\\nScp resembles cp. Sftp is an implementation over scp of the interface of a popular, but insecure, protocol widely used in the past called ftp (file transfer protocol).\\n\\nbash $sftp mst3k@login.hpc.virginia.edu sftp> put local_file sftp> get remote_file sftp> quit The sftp client permits other commands. ls lists files on the remote system. lls lists local files.\\n\\nrsync\\n\\nThe rsync command is used to synchronize files and folders. It has many options and some attention must be paid to whether a trailing slash is needed or not.\\n\\nbash $rsync -av ldir/ mst3k@login.hpc.virginia.edu:rdir $rsync my_file mst3k@login.hpc.virginia.edu:/scratch/$USER By default rsync does not transfer files that are older than the equivalent on the target. This can increase the transfer speed significantly. Rsync also resumes a transfer that was interrupted. Scp always starts again from the beginning.\\n\\nRsync is very powerful but has many options and can be confusing. For more details see our documentation. Several online resources with examples are also available, such as this.\\n\\nSetting up Passwordless ssh\\n\\nIf you will frequently use ssh, scp, sftp, or rsync to a remote system, it becomes inconvenient to repeatedly enter your password. Follow the instructions given here to generate a key to log in without a password.\\n\\nFinding Information About a Command\\n\\nBasic documentation for a command can be read from the shell with the man (manual) command. bash $man ls\\n\\nMany commands also provide a --help option which usually prints the same information. bash $ls --help\\n\\nThe output of man is often called the manpage of that command.\\n\\nExercise\\n\\nQ1: Create a directory called newdir. Navigate to it. Make the new file mynewfile and save it with ^d. Use nano or another editor of your preference and type a line or two of text.\\n\\nQ2: View the content of the mynewfile using more. Rename mynewfile to the_file. Copy the_file to old_file. List the files in long format.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1213 of 1477]\n",
      "Found 1212 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/biopython/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Biopython author: khs highlight_style: \"github\" date: \"2020-10-01T00:00:00\" toc: true type: article draft: false\\n\\nIntroduction\\n\\nFrom the official Biopython project website:\\n\\nBiopython is a set of freely available tools for biological computation written in Python by an international team of developers. It is a distributed collaborative effort to develop Python libraries and applications which address the needs of current and future work in bioinformatics. The source code is made available under the Biopython License, which is extremely liberal and compatible with almost every license in the world.\\n\\nThis workshop assumes a working knowledge of the Python programming language and basic understanding of the concepts of online DNA and Protein sequence repositories.\\n\\nIntroductions to Python can be found here and here.\\n\\nGetting Started\\n\\nPython code examples\\n\\nThe Python scripts and data files for this workshop can be downloaded from here. On your computer, unzip the downloaded folder and use it as working directory for this workshop.\\n\\nPython programming environment\\n\\nThe Anaconda environment from Anaconda Inc. is widely used because it bundles a Python interpreter, most of the popular packages, and development environments. It is cross-platform and freely available. There are two somewhat incompatible versions of Python; version 2.7 is deprecated but still fairly widely used. Version 3 is the supported version.\\n\\nNote: The latest Biopython package version (1.77+) requires Python 3.\\n\\nVisit the Anaconda download website and download the installer for Python 3 for your operating system (Windows, Mac OSX, or Linux). We recommend to use the graphical installer for ease of use.\\n\\nLaunch the downloaded installer, follow the onscreen prompts and install the Anaconda distribution on your local hard drive.\\n\\nThe Anaconda Documentation provides an introduction to the Anaconda environment and bundled applications. For the purpose of this workshop we focus on the Anaconda Navigator and Spyder.\\n\\nNavigator\\n\\nOnce you have installed Anaconda, start the Navigator application: * Instructions for Windows * Instructions for Mac * Instructions for Linux\\n\\nYou should see a workspace similar to the screenshot, with several options for working environments, some of which are not installed. We will use Spyder which should already be installed. If not, click the button to install the package.\\n\\nAnacondaNavigator\\n\\nSpyder\\n\\nNow we will switch to Spyder. Spyder is an Integrated Development Environment, or IDE, aimed at Python. It is well suited for developing longer, more modular programs.\\n\\nTo start it, return to the Anaconda Navigator and click on the Spyder tile. It may take a while to open (watch the lower left of the Navigator).\\n\\nOnce it starts, you will see a layout with an editor pane on the left, an explorer pane at the top right, and an iPython console on the lower right. This arrangement can be customized but we will use the default for our examples. Type code into the editor. The explorer window can show files, variable values, and other useful information. The iPython console is a frontend to the Python interpreter itself. It is comparable to a cell in JupyterLab.\\n\\nAnacondaNavigator\\n\\nInstallation of the Biopython package\\n\\nIt is recommended to install the biopython package from PyPI using the pip install command. Detailed instructions are available here.\\n\\nOn your own computer: Start the Anaconda Prompt command line tool following the instructions for your operating system. * Start Anaconda Prompt on Windows * Start Anaconda Prompt on Mac, or open a terminal window. * Linux: Just open a terminal window.\\n\\nAt the prompt, type the following command and press enter/return: bash pip install biopython This command will install the latest biopython package version in your current Anaconda Python environment.\\n\\nOn Rivanna (UVA\\'s HPC platform):\\n\\nRivanna offers several Anaconda distributions with different Python versions. Before you use Python you need to load one of the anaconda software modules and then run the pip install command.\\n\\nbash module load anaconda pip install --user biopython Note: You have to use the --user flag which instructs the interpreter to install the package in your home directory. Alternatively, create your own custom Conda environment first and run the pip install biopython command in that environment (without --user flag)\\n\\nTesting the Biopython Installation\\n\\nStart the Spyder IDE (see here). In the IPython console pane, type the following command and press enter/return:\\n\\nimport Bio print (Bio.__version__)\\n\\nIf the package is installed correctly, the output will show the biopython version number.\\n\\nBio Subpackages and Classes\\n\\nThe Bio package provides a large number of subpackages providing specific functionality. The Biopython website provides a full list of all subpackages.\\n\\nThe following table shows an excerpt of that list relevant for this workshop.\\n\\nSubpackages/Classes Purpose Bio.Entrez Functions to retrieve Entrez records and associated data Bio.ExPASy Tools to access data hosted on the ExPASy protein databases Bio.SwissProt Tools to work with the sprotXX.dat file from SwissProt Bio.Seq Sequence datastructure (immutable=read-only) Bio.MutableSeq Sequence datastructure (mutable=modifiable Bio.SeqRecord Datastucture for Seq object plus enriched information Bio.SeqIO Read/write sequences (various file formats ) Bio.AlignIO A new multiple sequence Alignment Input/Output interface for BioPython 1.46 and later Bio.Align.MultipleSeqAlignment Tools for Code for working with sequence alignments\\n\\nOnline Datasets and Databases\\n\\nThe Bio module provides several classes to process output and datasets provided by the following web services and tools: * FASTA * Blast output  both from standalone and WWW Blast * Clustalw * GenBank * PubMed and Medline * ExPASy files, like Enzyme and Prosite * SCOP, including dom and lin files * UniGene * SwissProt\\n\\nIn this workshop we will explore options to download nucleotide and protein sequences from Entrez and ExPASy.\\n\\nAccessing NCBI\\'s Entrez Databases\\n\\nThe Bio.Entrez submodule provides access to the Entrez databases. When you use this module you need to know the String descriptor of the database you want to query (aka its name). A list of valid database names is provided in column three of this table.\\n\\nNote: Please review the General Introduction to the E-utilities for accessing the Entrez Application Programming Interface Program. The E-utilities limit the frequency of API calls and your IP address may be blocked if you continuously exceed the limit.\\n\\nBasic Steps:\\n\\nProvide an email address. This is required! Entrez.email = \"your@somewhere\".\\n\\nUse an E-utility to get a handle for the data of interest, e.g. handle = Entrez.esearch(...).\\n\\nUse handle to read or parse data with handle.read() or handle.parse().\\n\\nClose the handle with handle.close().\\n\\nAlso read \"What the heck is a handle?\"\\n\\nFind Database Records:\\n\\nLet\\'s find the protein records associated with the human Pax6 gene and download the associated sequences in FASTA format.\\n\\nTo search the database we use the Entrez.esearch function. We need to specify the database via the db, argument and specify a search term (provided as a list of Strings).\\n\\nThe following code is available in the entrez-fasta.py file.\\n\\n```python from Bio import Entrez\\n\\nEntrez.email = \"YOU@SOMEWHERE.com\" # your email address is required handle = Entrez.esearch(db=\"protein\", term = [\"Homo sapiens[Orgn] AND pax6[Gene]\"], usehistory=\"y\") record = Entrez.read(handle) handle.close()\\n\\niterate over items\\n\\nfor k,v in record.items(): print (k,v) ```\\n\\nThe search results are returned as a dictionary and we can retrieve the list of unique IDs that match our query via record[\"IdList\"].\\n\\nNote: The IdList returned by esearch is limited to the top 20 hits by default (defined by retmax). There are two workarounds: 1. Use the retmax=<number> keyword argument to increase the maximum number of retrieved records. The problem is you need to know what a reasonable number is. 2. Or better, use the usehistory=\\'y\\' keyword argument. This will save the search results on the remote server and provide WebEnv and QueryKey entries that can be used with the efetch function (see next section) to retrieve all search records (beyond the top 20).\\n\\nBy default the returned IDs reflect the GI numbers. The accession.version numbers can be retrieved instead by passing idtype=\\'acc\\' as an optional keyword argument to the esearch function. See the detailed documentation of the esearch function here.\\n\\nDownload and save sequences as FASTA file:\\n\\nWith the ID list in hand, we can now download the sequence records using just a few lines of code and save them in a single multi-sequence FASTA file. The efetch function is used when you want to retrieve a full record from Entrez.\\n\\n```python\\n\\nfetch records using id list\\n\\nhandle = Entrez.efetch(db=\"protein\", rettype=\"fasta\", retmode=\"text\", id=record[\"IdList\"]) result = handle.read() # return type is simple string handle.close()\\n\\nremove empty lines\\n\\nfastaseq = result.replace(\"\\\\n\\\\n\",\"\\\\n\") with open(\\'HsPax6-protein.fasta\\', \\'w\\') as f: f.write(fastaseq) ```\\n\\nAlternatively, we can pull individual sequences one at a time and save each sequence into a separate file. To do this we implement a for loop that iterates over this list and use the Entrez.efetch function to retrieve the FASTA sequence record associated with each id. We wrap this for loop in an open file operation block to save the retrieved FASTA records into a single .fasta text file.\\n\\nLet\\'s retrieve the nucleotide sequences of our previous top 5 ID hits as GenBank files. We specify the database with the db=\"nucleotide\" and format with the rettype=\"gb\" keyword arguments.\\n\\nThe code is provided in the entrez-genbank.py file.\\n\\n```python from Bio import Entrez\\n\\nEntrez.email = \"YOU@SOMEWHERE.com\" # provide your email address handle = Entrez.esearch(db=\"nucleotide\", term = [\"Homo sapiens[Orgn] AND pax6[Gene]\"], retmax=5, usehistory=\"y\") record = Entrez.read(handle) handle.close() for k,v in record.items(): print (k,v)\\n\\niterate over ids in list\\n\\nfor seq_id in record[\"IdList\"]: # get entry from Entrez print (seq_id) handle = Entrez.efetch(db=\"nucleotide\", id=seq_id, rettype=\"gb\", retmode=\"text\") result = handle.read() handle.close() # save filename = f\"HsPax6-{seq_id}-nucleotide.gb\" print (\"Saving to file:\", filename) with open(filename, \\'w\\') as gbfile: # append fasta entry gbfile.write(result.rstrip()+\"\\\\n\") ```\\n\\nNote that the record[\\'IdList\\'] may not represent all the records. Remember that the record[\\'WebEnv\\'] and record[\\'QueryKey\\'] entries provide access to the search history on the remote server. So we can use these instead of the record[\\'IdList\\'] to get all records. ```\\n\\nAlternative: fetch all records using search history\\n\\nhandle = Entrez.efetch(db=\"protein\", rettype=\"fasta\", retmode=\"text\", webenv=record[\"WebEnv\"], query_key=record[\"QueryKey\"]) ```\\n\\nExercise: Find and download the top 10 FASTA EST nucleotide sequences for the mouse (Mus Musculus) TP53 tumor suppressor. Hint: look up the EST database descriptor in this table.\\n\\nRetrieve Protein Records from the ExPASy Database\\n\\nHere are a few examples demonstrating how to access the ExPASy databases Swissport and Prosite. The Biopython documentation provides more details.\\n\\nSwiss-Prot\\n\\n```python from Bio import ExPASy from Bio import SwissProt\\n\\nget single protein record\\n\\naccession_no = \"O23729\" handle = ExPASy.get_sprot_raw(accession_no) record = SwissProt.read(handle) print (record.entry_name) print (record.sequence_length) print (record.data_class) print (record.accessions) print (record.organism)\\n\\nprint first 10 aa\\n\\nprint (record.sequence[:10]) # string ```\\n\\nThe return type of SwissProt.read() is a Bio.SwissProt.Record object. In the above example we\\'re printing only a subset of its fields. The record.sequence field is a string, but it can easily be converted into a Bio.Seq object.\\n\\nTip: Use dir(record) to get a list of all record attribute names.\\n\\nProsite\\n\\n```python from Bio import ExPASy from Bio.ExPASy import Prosite\\n\\nhandle = ExPASy.get_prosite_raw(\"PS00001\") record = Prosite.read(handle) print (record.name) print (record.type) # e.g. PATTERN, MATRIX, or RULE print (record.pattern) print (record.rules) print (record.matrix) ```\\n\\nThe return type of Prosite.read() is a Bio.ExPASy.Prosite.Record object. Note: Use the Bio.ExPASy.Prosite.parse() function to parse files containing multiple records.\\n\\nProsite Documentation ``` from Bio import ExPASy from Bio.ExPASy import Prodoc\\n\\nhandle = ExPASy.get_prosite_raw(\"PDOC00001\") record = Prodoc.read(handle) ```\\n\\nExercise: Retrieve the SwissProt records for proteins with the following IDs: \"O23729\", \"O23730\", \"O23731\". Try to use list comprehension to create a list containing the records for all retrieved proteins.\\n\\nLearn more about SwissProt.\\n\\nScanProsite\\n\\nWe can query the Prosite database with protein sequences or motifs to find proteins with corresponding matches, see ScanProsite for details.\\n\\nOption 1: Submit protein sequence (use the seq= keyword argument) * UniProtKB accessions e.g. P98073 * Identifiers e.g. ENTK_HUMAN * PDB identifiers e.g. 4DGJ * Sequences in FASTA format.\\n\\nOption 2: Submit motif sequence (use the sig= keyword argument) * PROSITE accession e.g. PS50240 * Identifier e.g. TRYPSIN_DOM * Your own pattern e.g. P-x(2)-G-E-S-G(2)-[AS]. * Combinations of motifs can also be used.\\n\\n```python from Bio.ExPASy import ScanProsite\\n\\nuniprot_id = \"P26367\" # human Pax-6 handle = ScanProsite.scan(seq=uniprot_id) results = ScanProsite.read(handle) `` By executinghandle.read(), you can obtain the search results in raw XML format. Here we useBio.ExPASy.ScanProsite.readto parse the raw XML into aBio.ExPASy.ScanProsite.Record` object which represents a specialized list.\\n\\nWe can now access the found matches like this: print (\"Number of matches:\", results.n_match) for r in results: print (r)\\n\\nYou see that each item r represents a dictionary describing a specific match.\\n\\nWorking with Sequence Files\\n\\nSequence Objects\\n\\nThe Seq object is similar to a string object augmented with methods for nucleotide sequence operations including * find(), count() * complement(), reverse_complement() * transcribe(), back_transcribe() * translate()\\n\\nThe following code examples are in the seq.py script.\\n\\n```python from Bio.Seq import Seq\\n\\nmy_dna = Seq(\"ATGAGTACACTATAGA\") print (my_dna)\\n\\nfind position of first subsequence\\n\\nprint (my_dna.find(\"TAC\")) print (my_dna.find(\"AC\")) print (my_dna.find(\"CTC\"))\\n\\ncount\\n\\nprint (\"A count:\", my_dna.count(\"A\")) print (\"AC count:\", my_dna.count(\"AC\")) print (\"AA count:\", Seq(\"AAAA\").count(\"AA\")) # non-overlapping ```\\n\\nNote the return of -1 if no sequence match was found.\\n\\n```python\\n\\ncomplement and reverse complement\\n\\ncompl = my_dna.complement() rev_compl = my_dna.reverse_complement() print (\"original: \\\\t\", my_dna) print (\"complement:\\\\t\", compl) print (\"rev complement:\\\\t\", rev_compl)\\n\\ntranscription\\n\\nmy_rna = my_dna.transcribe() print (\"RNA:\", my_rna)\\n\\ntranslation\\n\\nmy_peptide = my_dna.translate() print (\"Peptide:\", my_peptide) ```\\n\\nLike Strings, Seq objects are immutable; this means that the sequence is read-only and cannot be modified in place. However, you can convert a Seq object into a MutableSeq object that allows you to manipulate the sequence after object initialization.\\n\\npython my_dna[2] = \\'A\\' # error, immutable Seq object mutable_dna = my_dna.tomutable() mutable_dna[2] = \\'A\\' print (my_dna) print (mutable_dna)\\n\\nNote that the sequence is zero-indexed: the first nucleotide has index 0, the second has index 1, and so forth. So in this example we\\'re changing the third nucleotide (index 2, G->A).\\n\\nExercise: Create a Seq object with a DNA nucleotide sequence of your choice. Find the first putative start codon (ATG), replace each \"C\" with a \"G\", and transcribe and translate the original as well as the modified sequence. Hint: As an intermediary step, convert Seq object to a string and use a string method for replacement.\\n\\nHandling Sequence Records\\n\\nThe SeqRecord class provides the following fields: * .seq: a sequence (as a Seq object) * .id: the identifier, e.g. an accession number (String) * .name: can be just the accession number or the locus name (String) * .description: self-explanatory (String) * .annotations: dictionary of additional often unstructured info (optional) * .letter_annotations: often used for quality scores or secondary structure info * .features: list of SeqFeature objects; more structured than annotations, e.g. gene position in a genome, or domain position in a protein * .dbxref: list of database cross-references\\n\\nSo it is used to wrap around a Seq object with richer information. We can manually create a SeqRecord object like this: ```python from Bio.Seq import Seq from Bio.SeqRecord import SeqRecord\\n\\nrecord = SeqRecord( Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"), id=\"YP_025292.1\", name=\"HokC\", description=\"toxic membrane protein, small\") print(record) ```\\n\\nThe above code example is in the seqrecord.py script.\\n\\nSequence File Operations\\n\\nThe Bio.SeqIO class provides simple tools to read and write a variety of sequence file formats (including multiple sequence alignments). It operates exclusively on SeqRecord objects.\\n\\nRead Fasta File ```python from Bio import SeqIO\\n\\nfile = open(\\'HsPax6-protein.fasta\\') fastarecords = SeqIO.parse(file, \"fasta\")\\n\\ncreate a list of SeqRecords\\n\\nfastalist = [entry for entry in fastarecords]\\n\\niterate over fasta entries\\n\\nfor entry in fastalist: print (f\"ID={entry.id}\") print (f\"Name={entry.name}\") print (f\"Description={entry.description}\") print (f\"Seq length={len(entry.seq)}\") print (f\"Features={entry.features}\") # empty for Fasta format print (f\"Sequence={entry.seq}\\\\n\") ```\\n\\nExercise: Filter the list of records to only include sequences with less than 300 amino acids.\\n\\nConvert Genbank to Fasta File\\n\\n```python from Bio import SeqIO\\n\\ngb_file = \\'HsPax6-208879460-nucleotide.gb\\' with open(gb_file) as f: gb_generator = SeqIO.parse(f, format=\\'gb\\') for entry in gb_generator: with open(f\\'Hs-pax6-{entry.id}-nucleotide.fasta\\', \\'w\\') as fileout: SeqIO.write(entry, fileout, \\'fasta\\') ```\\n\\nThe later versions of Biopython also include a Bio.SeqIO.convert() function. ```\\n\\nconvert GenBank to Fasta\\n\\ncount = Bio.SeqIO.convert(\"my_file.gb\", \"genbank\", \"my_file.fasta\", \"fasta\") ```\\n\\nAlignIO: Reading Sequence Alignment Files\\n\\nThe Bio.AlignIO class provides functions to handle paired or multiple sequence alignment files. It does not perform the alignment but provides tools to read/write alignment files and manipulate alignment objects. Bio.AlignIO uses the same set of functions for input and output as in Bio.SeqIO, and the same names are supported for the file formats.\\n\\nThe key functions are: * Bio.AlignIO.read(): For a file that contains one and only one alignment. The return type is a Bio.Align.MultipleSeqAlignment object. * Bio.AlignIO.parse(): A more general function when the file may contain multiple separate alignments. The return type is a generator that can be converted into a list of Bio.Align.MultipleSeqAlignment objects.\\n\\nExample:\\n\\nLet\\'s create a Fasta file with Pax6 orthologs from human, mouse, xenopus, pufferfish, zebrafish (2), and fruitfly. The following code example is in the createPax6_fasta.py script.\\n\\n```python from Bio import Entrez\\n\\nget human, mouse, xenopus, pufferfish, zebrafish 1, zebrafish 2, Drosophila 1, Drosophila 2\\n\\nids = [\\'1587062735\\',\\'AAH36957.1\\',\\'NP_001006763.1\\',\\'XP_029701655.1\\',\\'NP_571379.1\\',\\'NP_571716.1\\',\\'NP_524628\\',\\'NP_524638\\'] handle = Entrez.efetch(db=\"protein\", rettype=\"fasta\", retmode=\"text\", id=ids) result = handle.read() handle.close() fastaseq = result.replace(\"\\\\n\\\\n\",\"\\\\n\") with open(\\'Pax6-multispec-protein.fasta\\', \\'w\\') as f: f.write(fastaseq) ```\\n\\nThis will create the Pax6-multispec-protein.fasta Fasta file with 8 sequences. The alignment was performed using Clustal Omega and you can download the Pax6-multispec-protein.aln alignment file and move it to your Python script folder that you use for this workshop.\\n\\nAlternatively, create the alignment yourself: 1. Visit the Clustal Omega website and upload the Pax6-multispec-protein.fasta file as input. 2. Under Step 1, click the Choose File button and upload the Pax6-multispec-protein.fasta file as input. 3. Under Step 3, click Submit. 4. When the alignment is done, click the Alignments tab, select the entire alignment output in the window and paste it into a text editor. Do not use Microsoft Word for this but programs like Text Edit, Notepad++, Emacs or vim instead. 5. Save the alignment in the text editor as Pax6-multispec-protein.aln in your Python script folder that you use for this workshop.\\n\\nThe following code examples are in the alignio-parse_clustal.py script.\\n\\nParse the alignment file ``` from Bio import AlignIO\\n\\ninputfile = open(\"Pax6-multispec-protein.aln\", \"r\")\\n\\nassuming single alignment in file; use AlignIO.parse for multiple alignments\\n\\nalignment = AlignIO.read(inputfile, \"clustal\") inputfile.close() print (\"Alignment length:\", alignment.get_alignment_length()) print (alignment,\"\\\\n\") ```\\n\\nUpdate identifier python species = [\\'H.sapiens\\', \\'M.musculus\\', \\'X.tropicalis\\', \\'T.rubripes\\', \\'D.rerio\\', \\'D.rerio\\', \\'D.melanogaster\\', \\'D.melanogaster\\'] for idx,line in enumerate(alignment): line.id = f\"{species[idx]}:{line.id}\" print (alignment)\\n\\nSlicing and joining ```python\\n\\nslice: first axis defines line, second axis defines column index (zero-indexed)\\n\\nget lines 1-6, first 50 columns\\n\\nsubset = alignment[:6,:50] print (subset) ```\\n\\nLet\\'s join two alignment blocks: python edited = alignment[:,:50] + alignment[:,500:] print (edited)\\n\\nExporting to other alignment file formats ```python\\n\\nsave as Stockholm\\n\\nwith open(\"Pax6-multispec-protein.sth\", \"w\") as outputfile: AlignIO.write(alignment, outputfile, \"stockholm\")\\n\\nget alignment as formatted string\\n\\nprint (\"Formatted Alignment:\") print (format(alignment, \"clustal\")) ```\\n\\nExercise: Find the first alignment block that shows no gaps across all 8 aligned sequences. 1. Print the block. 2. Save the block as a new clustal formatted text file. 3. From that block, extract the D. rerio (zebrafish) sequences and print the two sequences\\n\\nResources\\n\\nBiopython Tutorial and Cookbook\\n\\nUVA Research Computing')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1214 of 1477]\n",
      "Found 1213 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Large Language Models (LLMs) on HPC authors: [kal, abd, mab] type: docs weight: 1 date: \"2025-02-25T00:00:00\"\\n\\nmenu: llms-hpc:\\n\\nIn this tutorial, we will be discussing the following topics:\\n\\nLLM overview\\n\\nSetup/Installation\\n\\nHPC Resources for LLMs\\n\\nModel selection\\n\\nInference and fine-tuning\\n\\nSlurm scripts')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1215 of 1477]\n",
      "Found 1214 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/example-ft.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Fine-Tuning Classification date: \"2025-02-23T00:00:00\" type: docs weight: 2750 menu: llms-hpc: parent: Fine-Tuning\\n\\nSupervised Full Fine-Tuning\\n\\nThe data for supervised learning includes labels, e.g., a text review and sentiment label (positive or negative).\\n\\nAn LLM is generally pre-trained for the task of masked language modeling. Through fine-tuning, we can change the task to text classification.\\n\\nThis means that the LLM head (the last layers) will change to text classification layers. There is a transformers function that will do this for us.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1216 of 1477]\n",
      "Found 1215 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/exercise_5.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 5 date: \"2025-02-23T00:00:00\" type: docs weight: 2850 menu: llms-hpc: parent: Fine-Tuning\\n\\nSupervised Full Fine-Tuning\\n\\nText Classification\\n\\nOpen the ex4.ipynb file from the workshop folder.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1217 of 1477]\n",
      "Found 1216 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/hf-trainer-class.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Hugging Face Trainer Class date: \"2025-02-23T00:00:00\" type: docs weight: 2800 menu: llms-hpc: parent: Fine-Tuning\\n\\nThe Trainer class allows a user to train or fine-tune a model using a convenient function, rather than using native PyTorch.\\n\\nWhen training, the Trainer will automatically use the GPU if one is present.\\n\\nThere are many options that can be set for the TrainingArguments (number of epochs, learning rate, save strategy, etc). * More TrainingArguments\\n\\nThe Trainer will not automatically evaluate the LLM, so we will pass it an evaluation metric.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1218 of 1477]\n",
      "Found 1217 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/fine-tuning-intro.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Introduction to Fine-Tuning date: \"2025-02-23T00:00:00\" type: docs weight: 2600 menu: llms-hpc: name: Fine-Tuning\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_10.png width=70% height=70% >}}\\n\\nLLMs are pre-trained on huge amounts of text data to learn general language patterns.\\n\\nLLMs can be fine-tuned on a much smaller amount of data to excel at a particular task (e.g., classification of financial text).\\n\\nNote: LLM pre-training is generally unsupervised.\\n\\nTypes of Fine-Tuning\\n\\nFine-tuning can be a supervised or unsupervised process and involves: * Changing some of the LLM weights, * Changing all of the LLM weights (full fine-tuning), or * Parameter Efficient Fine-Tuning (PEFT), i.e., keeping the LLM weights the same but updating a small number of additional parameters that will adjust the LLM weights (e.g., LoRA).\\n\\nThe more weights you update, the more computational resources you need.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1219 of 1477]\n",
      "Found 1218 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/selecting-gpu-ft.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Selecting a GPU for Fine-Tuning date: \"2025-02-23T00:00:00\" type: docs weight: 3000 menu: llms-hpc: parent: Fine-Tuning\\n\\nFor fine-tuning, select a GPU based on how much GPU memory you will need.\\n\\nBut, it is a hard problem to determine how much GPU memory a LLM will need for training before training the model.\\n\\nA training iteration requires a forward and backward pass of the model. In addition to storing the LLM, training also requires additional storage space such as: * Optimizer states * Gradients * Activations * Data (how much is determined by the batch size)\\n\\nAccording to the Hugging Face Model Memory Calculator, for a batch size of 1, $$ \\\\text{GPU Memory Estimate for Fine-Tuning (B)} = 4 \\\\times (\\\\text{LLM Memory in B})$$ * While this formula can help ballpark an estimate, I recommend tracking GPU memory using the GPU Dashboard to make a more informed GPU selection.\\n\\nFor a more specific formula, see https://blog.eleuther.ai/transformer-math/ (Note: this blog requires some understanding of transformers).\\n\\nDetermining LLM memory for fine-tuning is an active area of research. The paper LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs by Kim, et al. (April 2024) presents a method for doing so within 3% of the actual memory required.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1220 of 1477]\n",
      "Found 1219 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/why-use-ft.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Optimizing LLMs with Fine-Tuning date: \"2025-02-23T00:00:00\" type: docs weight: 2700 menu: llms-hpc: parent: Fine-Tuning\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_11.png width=65% height=65% >}}\\n\\nFine-tuning builds on a pre-trained language model (LLM) by using a smaller, labeled dataset to specialize and improve its performance for a specific task. Pre-training requires a large dataset and is computationally demanding, but fine-tuning is much less resource-intensive and allows models to adapt to domain-specific needs efficiently.\\n\\nExample:\\n\\ndistilbert/distilbert-base-uncased was pre-trained on BookCorpus and English Wikipedia, ~25GB of data\\n\\ndistilbert/distilbert-base-uncased-finetuned-sst-2-english was fine-tuned on Stanford Sentiment Treebank (sst2), ~5MB of data')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1221 of 1477]\n",
      "Found 1220 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/cpu-allocation-ft.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: CPU Allocation - Fine-Tuning date: \"2025-02-23T00:00:00\" type: docs weight: 2950 menu: llms-hpc: parent: Fine-Tuning\\n\\nCPU memory * Interactive Partition: The interactive partition requests 6GB RAM per core requested. * Standard Partition: The standard partition requests 9GB RAM per core requested (no GPU). * GPU partition: You can select the amount of CPU RAM.\\n\\nYou should have enough RAM to comfortably work with your GPU. In other words, request at least as much RAM as the GPU you select. If you are using a large dataset and/or want to do extensive preprocessing, more RAM is probably helpful.\\n\\nCPU cores\\n\\nUse multiple cores - especially if you are using a dataset from the Datasets package and a GPU (So that DataLoader can utilize multiple cores under the hood).\\n\\nA good starting point is to use 8 cores.\\n\\nNotes:\\n\\nCheck your resource usage with the GPU Dashboard, or use seff for completed jobs and sstat for running jobs.\\n\\nIt may be the case that even if CPU Efficiency is a low percentage, you need all of the requested CPU cores for a specific part of the code, e.g., data preprocessing. In this case, request the number of CPU cores that you need for the compute intensive part of the code.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1222 of 1477]\n",
      "Found 1221 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/fine-tuning/general-advice.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: General Advice date: \"2025-02-23T00:00:00\" type: docs weight: 3050 menu: llms-hpc: parent: Fine-Tuning\\n\\nIf you are learning about LLMs and doing tutorials, choose a small LLM. The GPUs in the Interactive partition are probably ok to use.\\n\\nYou can leave the GPU choice as default on the GPU partition and work on whichever GPU you get or choose a GPU with a smaller amount of memory first.\\n\\nFine-tune your model for one epoch and monitor the GPU memory usage using GPU Dashboard.\\n\\nIf you are getting OOM (out of memory) GPU errors, try lowering the batch size.\\n\\nThere are other advanced techniques to reduce the amount of memory used in fine-tuning.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1223 of 1477]\n",
      "Found 1222 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/model-selection/hugging-face.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Hugging Face date: \"2025-02-23T00:00:00\" type: docs weight: 1450 menu: llms-hpc: parent: Model Selection\\n\\nHugging Face is a machine learning platform that includes models, datasets, and spaces (AI apps).\\n\\nInformation and/or code is provided to show how to use the models and datasets. Information on how the models were trained, benchmarked, etc. may also be provided.\\n\\nModels and datasets are filterable by task (e.g., text classification, question answering). Some models may require you to sign an agreement before using them.\\n\\nModels and datasets include metrics such as number of downloads and date of last update.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1224 of 1477]\n",
      "Found 1223 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/model-selection/benchmarking.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Benchmarking LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 1650 menu: llms-hpc: parent: Model Selection\\n\\nOnce you have narrowed down your choice of LLMs to a few, benchmarking can help you make a final decision on a model.\\n\\nBenchmarking results may be given in the model documentation on standard (or other) datasets. It is always good to test models on your data!')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1225 of 1477]\n",
      "Found 1224 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/model-selection/finding-model-size.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Finding Model Size on Hugging Face date: \"2025-02-23T00:00:00\" type: docs weight: 1600 menu: llms-hpc: parent: Model Selection\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_7.png height=80% width=80% >}}\\n\\nUse the information on the model card.\\n\\n$$ \\\\text{Model Size (B)} = \\\\text{(Number of parameters)} \\\\times \\\\text{(bytes/parameter)} $$\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_8.png height=60% width=60% >}}\\n\\nUse information on the Files and versions tab.\\n\\nLook for the pytorch model in the list of files. (It will have a .bin extension.)\\n\\nThe size of the model will be given.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1226 of 1477]\n",
      "Found 1225 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/model-selection/model-selection.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Model Selection date: \"2025-02-23T00:00:00\" type: docs weight: 1400 menu: llms-hpc: name: Model Selection\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_6.png height=50% width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1227 of 1477]\n",
      "Found 1226 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/model-selection/choosing-hf.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Choosing a Hugging Face Model date: \"2025-02-23T00:00:00\" type: docs weight: 1550 menu: llms-hpc: parent: Model Selection\\n\\nPlanning to Choose a Hugging Face Model\\n\\nThings to consider: * What type of task will you do? (text classification, question answering, etc.) * What type of data will you work with? Is the text data from a specific domain (financial, scientific, Tweets, etc.)? What language is it in?\\n\\nMore specific text data will most likely need a fine-tuned model, otherwise a more general LLM may work better. If you need to fine-tune a model, do you have the computational resources to do so?\\n\\nLarger models (i.e., models with more parameters) will need more resources.\\n\\nSource and more information\\n\\nChoosing the Model\\n\\nAppropriately use model filters (task, language, license, etc).\\n\\nSelect either a general LLM or a fine-tuned model.\\n\\nCheck number of downloads. While a more popular model isnt always better, it is good to know what models other people find useful.\\n\\nCheck model size (how to examples on next slides).\\n\\nRead model card (documentation), including * The datasets that the model was trained on and fine-tuned on (if applicable). * The model license (does this meet your needs?) * Any benchmarking results.\\n\\nSource and more information')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1228 of 1477]\n",
      "Found 1227 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/uva-gpus.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPUs on UVA HPC date: \"2025-02-23T00:00:00\" type: docs weight: 1050 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\n{{< table >}} | GPU | Full Name | Year Launched | Memory | # of Tensor Cores | | --- | --- | --- | --- | --- | | A100 | NVIDIA A100 | 2020 | 40GB or 80GB | 432 (3rd gen) | | A6000 | NVIDIA RTX A6000 | 2020 | 48GB | 336 (3rd gen) | | A40 | NVIDIA A40 | 2020 | 48GB | 336 (3rd gen) | | RTX3090 | NVIDIA GeForce RTX 3090 | 2020 | 24GB | 328 (3rd gen) | | RTX2080Ti | NVIDIA GeForce RTX 2080 Ti | 2018 | 11GB | 544 (2nd gen) | | V100 | NVIDIA V100 | 2018 | 32GB | 640 (1st gen) | {{< /table >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1229 of 1477]\n",
      "Found 1228 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/memory-usage-gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPU Memory Usage date: \"2025-02-23T00:00:00\" type: docs weight: 1300 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\nPyTorch\\n\\nCorrect GPU memory usage will be reported by GPU Dashboard.\\n\\nTensorFlow/Keras\\n\\nBy default, TF automatically allocates ALL of the GPU memory so GPU Dashboard may show that all (or almost all) of the GPU memory is being used.\\n\\nTo track the amount of GPU memory actually used, you can add these lines to your python script:\\n\\n```python import os\\n\\nos.environ[\\'TF_FORCE_GPU_ALLOW_GROWTH\\'] = \\'true\\'\\n\\n```\\n\\nMore Info\\n\\nHomework for Keras users: try out GPU dashboard and see if it reports all of the GPU memory as used.\\n\\nResource Allocation for LLMs\\n\\nResource needs will vary based on LLM use (inference, fine-tuning, etc.)\\n\\nWe will cover good starting choices in the Inference and Fine-Tuning sections of todays workshop.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1230 of 1477]\n",
      "Found 1229 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/computations-cpu-gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: When to Use CPU vs. GPU date: \"2025-02-23T00:00:00\" type: docs weight: 950 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\n{{< table >}} | Task | CPU or GPU | | --- | --- | | Tokenization | CPU | | LLM Training/Fine-tuning | GPU | | LLM Inference | Either, but GPU recommended | {{< /table >}}\\n\\nWhen you request memory for HPC, that is CPU memory.\\n\\nIf you request a GPU, you will receive all of that GPUs memory.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1231 of 1477]\n",
      "Found 1230 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/queue-wait.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Wait Time in the Queue date: \"2025-02-23T00:00:00\" type: docs weight: 1150 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\nYou may not need to request an A100 GPU!\\n\\nRequesting an A100 may mean you wait in the queue for a much longer time than using another GPU. This could give you a slower overall time (wait time + execution time) than if you had used another GPU.\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_4.png width=90% height=90% >}}\\n\\nWhen you request memory for HPC, that is CPU memory.\\n\\nIf you request a GPU, you will receive all of the GPU memory.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1232 of 1477]\n",
      "Found 1231 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/gpu-dashboard.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPU Dashboard date: \"2025-02-23T00:00:00\" type: docs weight: 1250 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_5.png width=50% height=50% >}}\\n\\nThe GPU Dashboard is included in OOD (Open On Demand). It checks CPU and GPU efficiency. This will be demoed during the exercises in this workshop.\\n\\nIt includes GPU and CPU memory and utilization tracking in real time. This is helpful for GPU selection in future OOD sessions.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1233 of 1477]\n",
      "Found 1232 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/nvidia-basepod.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: UVA HPC - NVIDIA DGX BasePOD date: \"2025-02-23T00:00:00\" type: docs weight: 1100 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\n10 DGX A100 nodes\\n\\n8 NVIDIA A100 GPUs.\\n\\n80 GB GPU memory options.\\n\\nDual AMD EPYC 7742 CPUs, 128 total cores, 2.25 GHz (base), 3.4 GHz (max boost).\\n\\n2 TB of system memory.\\n\\nTwo 1.92 TB M.2 NVMe drives for DGX OS, eight 3.84 TB U.2 NVMe drives forstorage/cache.\\n\\nAdvanced Features:\\n\\nNVLink for fast multi-GPU communication\\n\\nGPUDirect RDMA Peer Memory for fast multi-node multi-GPU communication\\n\\nGPUDirect Storage with 200 TB IBM ESS3200 (NVMe) SpectrumScale storage array\\n\\nIdeal Scenarios:\\n\\nJob needs multiple GPUs on a single node or multi node\\n\\nJob (single or multi-GPU) is I/O intensive\\n\\nJob (single or multi-GPU) requires more than 40GB of GPU memory\\n\\nThe POD is good if you need multiple GPUs and very fast computation.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1234 of 1477]\n",
      "Found 1233 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/rivanna-gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPU Access on Rivanna date: \"2025-02-23T00:00:00\" type: docs weight: 1200 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\nGeneral\\n\\nChoose GPU or Interactive as the Rivanna Partition in OOD.\\n\\nOptional: choose GPU type and number of GPUs.\\n\\nPOD nodes\\n\\nPOD nodes are contained in the gpu partition with a specific Slurm constraint.\\n\\nSlurm script:\\n\\n```bash\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:a100:X # X number of GPUs\\n\\nSBATCH -C gpupod\\n\\n```\\n\\nOpen OnDemand:\\n\\nbash --constraint=gpupod\\n\\nOnly one person can be using a GPU at a time.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1235 of 1477]\n",
      "Found 1234 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/gpu-workflow.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: General GPU workflow date: \"2025-02-23T00:00:00\" type: docs weight: 1000 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\nCreate data on the CPU.\\n\\nSend data from the CPU to the GPU (for DL this is done in batches).\\n\\nCompute result on the GPU.\\n\\nSend the result back to the CPU.\\n\\nDepending on the DL framework/LLM pipeline you are using, some of these steps may be automatically done for you.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1236 of 1477]\n",
      "Found 1235 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/gpus-llms.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPUs for LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 900 menu: llms-hpc: parent: HPC Resources for LLMs\\n\\nBecause LLMs involve a huge number of computations, we need a form of parallelization to speed up the process. For example, the free version of ChatGPT (based on GPT-3.5) has 175 billion parameters, while the paid version (based on GPT-4) has over 1 trillion parameters.\\n\\nGPUs (graphics processing units) provide the needed parallelization and speed up. All the major deep learning Python libraries (Tensorflow, PyTorch, Keras,) support the use of GPUs and allow users to distribute their code over multiple GPUs.\\n\\nNew GPUs have been developed and optimized specifically for deep learning.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1237 of 1477]\n",
      "Found 1236 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/hpc-resources-llms/resources-needed.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Resources Needed for LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 850 menu: llms-hpc: name: HPC Resources for LLMs\\n\\nHPC Resources: * CPU memory * CPU cores * GPU\\n\\nThe resources you choose will depend on your specific LLM use, whether it involves inference, fine-tuning, or training an LLM from scratch (which we are not covering today).')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1238 of 1477]\n",
      "Found 1237 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/batching-pipeline.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Pipeline Batching with GPU date: \"2025-02-23T00:00:00\" type: docs weight: 2150 menu: llms-hpc: parent: Inference\\n\\nData (sequences) are passed in batches to the GPU, instead of one at a time. This allows the GPU to stay busy computing without waiting on more data to be passed from the CPU.\\n\\nBatching can be used if the pipeline is passed a list of data or a dataset from the datasets package.\\n\\nBatching may or may not speed up your code! You will need to test it.\\n\\nThe default batch_size for a pipeline is 1.\\n\\nIf a dataset from the datasets package is used, DataLoader is being called under the hood in the pipeline. Use multiple CPU cores and set the num_workers parameter (default is 8).\\n\\nSource and more information\\n\\nNote: Do not use batching on CPU.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1239 of 1477]\n",
      "Found 1238 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/what-is-inference.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: What is Inference? date: \"2025-02-23T00:00:00\" type: docs weight: 1750 menu: llms-hpc: name: Inference\\n\\nInference is the process in which a trained (or fine-tuned) LLM makes a prediction for a given input.\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_9.png height=90% width=90% >}}\\n\\nEOS: end of sequence')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1240 of 1477]\n",
      "Found 1239 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/gpu-inference-select.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Selecting a GPU for Inference date: \"2025-02-23T00:00:00\" type: docs weight: 2400 menu: llms-hpc: parent: Inference\\n\\nSelect a GPU for inference based on how much GPU memory you will need.\\n\\nThe GPU memory will contain the LLM (i.e., the model weights), input and output data, and extra variables for the forward pass (about 20% of the LLM size). $$ (\\\\text{LLM Memory (B)}) = (\\\\text{number of parameters}) \\\\times (\\\\text{number of bytes/parameter}) $$\\n\\nThe number of bytes/parameter depends on the models precision, e.g., fp32 is 4 bytes/parameter.\\n\\nGPU Memory Estimate for Inference (B): $$ 1.2 \\\\times (\\\\text{LLM Memory in B})$$\\n\\nI have found this formula to underestimate UVA GPU memory. It is most likely a ballpark estimate, but I recommend tracking GPU memory using the GPU Dashboard to make a more informed GPU selection.\\n\\nNote: B is for bytes.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1241 of 1477]\n",
      "Found 1240 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/using-llm.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Using an LLM date: \"2025-02-23T00:00:00\" type: docs weight: 1800 menu: llms-hpc: parent: Inference\\n\\nLLMs can be used as-is (i.e., out-of-the-box) or after fine-tuning.\\n\\nHugging Face model cards will generally provide code for how to get started. Code may be PyTorch or TensorFlow, raw (using the model directly), or pipeline code (using the pipeline from transformers library).\\n\\nEx 1\\n\\nprovides raw PyTorch code\\n\\nEx 2\\n\\nprovides pipeline code\\n\\nCode for at least loading the model (directly and using the pipeline) is provided by clicking the Use this model button on Hugging Face. You may have to dig through the links to find the code you need.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1242 of 1477]\n",
      "Found 1241 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/exercise_3b.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 3b date: \"2025-02-23T00:00:00\" type: docs weight: 2100 menu: llms-hpc: parent: Inference\\n\\nHugging Face Datasets & Debugging\\n\\nText Summarization\\n\\nOpen the ex3b.ipynb file from the workshop folder.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1243 of 1477]\n",
      "Found 1242 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/transformers-pipeline.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Transformers Pipeline date: \"2025-02-23T00:00:00\" type: docs weight: 1850 menu: llms-hpc: parent: Inference\\n\\nThe transformers pipeline consists of a tokenizer, model, and post processing for getting model output.\\n\\nPros: * Easy to use. * Efficiently manages data batching and gpu memory for you  good for HPC!\\n\\nCons: * Harder to debug when something goes wrong.\\n\\nRecommendation: Use the pipeline first. If you get errors, you may have to use the model directly to diagnose the problem.\\n\\nThe pipeline \"hides\" details from the programmer, which can be good and bad.\\n\\nThe tokenizer runs on CPU, and the model runs on GPU.\\n\\nSource and more information')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1244 of 1477]\n",
      "Found 1243 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/cpu-allocation-inference.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: CPU Allocation -Inference date: \"2025-02-23T00:00:00\" type: docs weight: 2350 menu: llms-hpc: parent: Inference\\n\\nCPU memory * Interactive Partition: 6GB RAM per core is requested. * Standard Partition: 9GB RAM per core is requested (no GPU). * GPU partition: You can select the amount of CPU RAM.\\n\\nYou should have enough RAM to comfortably work with your GPU. In other words, request at least as much RAM as the GPU you select.\\n\\nIf you are using a large dataset and/or want to do extensive preprocessing, more RAM is probably helpful.\\n\\nCPU cores Use multiple cores - especially if you are using a dataset from the Datasets package and a GPU. (So that DataLoader can utilize multiple cores under the hood.)\\n\\nA good starting point is to use 8 cores.\\n\\nCheck your resource usage with the GPU Dashboard, or use seff for completed jobs and sstat for running jobs.\\n\\nIt may be the case that even if CPU Efficiency is a low percentage, you need all of the requested CPU cores for a specific part of the code, e.g., data preprocessing. In this case, request the number of CPU cores that you need for the compute intensive part of the code.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1245 of 1477]\n",
      "Found 1244 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/exercise_4.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 4 date: \"2025-02-23T00:00:00\" type: docs weight: 2450 menu: llms-hpc: parent: Inference\\n\\nSelect a GPU for Inference\\n\\nSuppose you are going to run inference using the model google-bert/bert-base-uncased. Which UVA GPU would you select and why?\\n\\nUVA GPU Full Name Year Launched Memory # of Tensor Cores A100 NVIDIA A100 2020 40GB or 80GB 432 (3rd gen) A6000 NVIDIA RTX A6000 2020 48GB 336 (3rd gen) A40 NVIDIA A40 2020 48GB 336 (3rd gen) RTX3090 NVIDIA GeForce RTX 3090 2020 24GB 328 (3rd gen) RTX2080Ti NVIDIA GeForce RTX 2080 Ti 2018 11GB 544 (2nd gen) V100 NVIDIA V100 2018 32GB 640 (1st gen)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1246 of 1477]\n",
      "Found 1245 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/pipeline-debug-tips.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Pipeline Debugging Tips date: \"2025-02-23T00:00:00\" type: docs weight: 2000 menu: llms-hpc: parent: Inference\\n\\nUse the CPU. Error messages for code running on the CPU tend to be more helpful than those for code running on the GPU.\\n\\nRun the pipeline tokenizer and model separately to see where the error is being generated.\\n\\nCheck out the data you are feeding to the pipeline that is causing the error. Is it somehow different than other pieces of data?\\n\\nIf you get stuck, please submit a ticket to RC. We can help!')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1247 of 1477]\n",
      "Found 1246 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/exercise_3a.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 3a date: \"2025-02-23T00:00:00\" type: docs weight: 1950 menu: llms-hpc: parent: Inference\\n\\nDirect LLM Usage vs Pipeline\\n\\nText Summarization\\n\\nOpen the ex3a.ipynb file from the workshop folder.\\n\\nRun each cell of this notebook and complete the EXERCISES as you go.\\n\\nWatch the GPU memory using GPU Dashboard as you run the cells.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1248 of 1477]\n",
      "Found 1247 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/inference/exercise_3c.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 3c date: \"2025-02-23T00:00:00\" type: docs weight: 2250 menu: llms-hpc: parent: Inference\\n\\nBatch Size and GPU Memory\\n\\nAs batch_size increases, so does GPU memory usage. If you get an OOM (out of memory) error while using the GPU, try decreasing the LLM batch size.\\n\\nSource and more information\\n\\nExercise 3c: Batch Size and Num Workers - Text Summarization\\n\\nOpen the ex3c.ipynb file from the workshop folder.\\n\\nRun each cell of this notebook and complete the EXERCISES as you go.\\n\\nWatch the GPU memory using GPU Dashboard as you run the cells.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1249 of 1477]\n",
      "Found 1248 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/exercise_2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 2 date: \"2025-02-23T00:00:00\" type: docs weight: 800 menu: llms-hpc: parent: Setup\\n\\nInstalling LLM Software\\n\\nInstall the transformers and datasets packages in the PyTorch 2.4.0 container.\\n\\nOpen the ex2.ipynb file from the workshop folder.\\n\\nRun each cell of this notebook.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1250 of 1477]\n",
      "Found 1249 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/ood.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Open OnDemand  JupyterLab date: \"2025-02-23T00:00:00\" type: docs weight: 600 menu: llms-hpc: parent: Setup\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_3.png height=70% width=70% >}}\\n\\nClick on the kernel to open a Jupyter Notebook.\\n\\nPackages from the selected kernel will be available for use in the notebook.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1251 of 1477]\n",
      "Found 1250 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/exercise_1.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Exercise 1 date: \"2025-02-23T00:00:00\" type: docs weight: 650 menu: llms-hpc: parent: Setup\\n\\nLog On, Copy Materials\\n\\nLog in to Rivanna using the Interactive partition.\\n\\n2 hours, 4 cores\\n\\nAllocation: hpc_training\\n\\nGPU: yes, 1\\n\\nShow Additional Options: Yes\\n\\nOptional Slurm Option: --reservation=llm_workshop\\n\\nCopy the workshop folder /project/hpc_training/llms_on_hpc to your home or scratch account.\\n\\ncp r /project/hpc_training/llms_on_hpc ~/<>\\n\\nOR\\n\\ncp r /project/hpc_training/llms_on_hpc /scratch/<ID>/<>\\n\\nOpen a Jupyter Notebook for PyTorch 2.4.0.\\n\\nIn the first cell of the notebook run the command pip list to see a list of software (i.e., packages) available in the PyTorch 2.4.0 kernel.\\n\\nDo you see a package called transformers or datasets?')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1252 of 1477]\n",
      "Found 1251 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/modules-containers.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Software Modules and Containers date: \"2025-02-23T00:00:00\" type: docs weight: 550 menu: llms-hpc: parent: Setup\\n\\nSoftware on Rivanna is accessed via environment modules or containers .\\n\\nSoftware Modules:\\n\\nR, Rstudio, JupyterLab, TensorFlow, and PyTorch are all examples of software modules.\\n\\nList of software available on Rivanna\\n\\nContainers:\\n\\nContainers bundle an application, the libraries and other executables it may need, and even the data used with the application into portable, self-contained files called images.\\n\\nContainers simplify installation and management of software with complex dependencies and can also be used to package workflows.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1253 of 1477]\n",
      "Found 1252 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/software-llms.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Software for LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 500 menu: llms-hpc: name: Setup\\n\\nWe will use Python deep learning libraries, such as PyTorch and TensorFlow/Keras, to run and fine-tune large language models (LLMs).\\n\\nThe transformers package is compatible with both PyTorch and TensorFlow.\\n\\nAccording to its documentation, \"Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models.\"\\n\\nThis package supports various applications, including Natural Language Processing (which is the focus of this workshop), Computer Vision, Audio, and Multimodal tasks.\\n\\nNote: There are packages in R/Rstudio that can do deep learning and/or use LLMs. We are not using those in this workshop.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1254 of 1477]\n",
      "Found 1253 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/install-transformers.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Install transformers and datasets packages date: \"2025-02-23T00:00:00\" type: docs weight: 700 menu: llms-hpc: parent: Setup\\n\\nUsing the PyTorch container:\\n\\n```bash module load apptainer pytorch/2.4.0\\n\\napptainer exec $CONTAINERDIR/pytorch-2.4.0.sif pip install transformers datasets\\n\\n```\\n\\nThese packages are provided by Hugging Face (more details on Hugging Face in a bit).\\n\\nFor the fine-tuning example we will do later today, we will also need to install the accelerate and evaluate packages.\\n\\nbash apptainer exec $CONTAINERDIR/pytorch-2.4.0.sif pip install accelerate evaluate')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1255 of 1477]\n",
      "Found 1254 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/setup/downloading-llms.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Downloading LLMs on UVA HPC date: \"2025-02-23T00:00:00\" type: docs weight: 750 menu: llms-hpc: parent: Setup\\n\\nWhen you use a transformers LLM for inference, it is downloaded to your home account.\\n\\n~/.cache/huggingface/hub\\n\\nDatasets (from the datasets package) are also downloaded to your home account.\\n\\n~/.cache/huggingface/datasets\\n\\nMake sure you have enough storage in your home account!\\n\\nCurrently, each user has access to 200GB of home storage.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1256 of 1477]\n",
      "Found 1255 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/wrap-up/more-help.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Need more help? date: \"2025-02-23T00:00:00\" type: docs weight: 3450 menu: llms-hpc: parent: Wrap-up\\n\\nOffice Hours via Zoom\\n\\nTuesdays: 3 pm - 5 pm\\n\\nThursdays: 10 am - noon\\n\\nZoom Links are available at https://www.rc.virginia.edu/support/#office-hours\\n\\nRC Website')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1257 of 1477]\n",
      "Found 1256 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/wrap-up/recap.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Recap date: \"2025-02-23T00:00:00\" type: docs weight: 3350 menu: llms-hpc: name: Wrap-up\\n\\nWe learned\\n\\nWhat an LLM is, the types of problems LLMs can solve, and LLM terminology\\n\\nHow to download and set up LLM software on UVA HPC\\n\\nThe HPC resources (CPU memory, CPU cores, GPU) needed for LLM inference and fine-tuning\\n\\nHow to use GPU Dashboard on UVA HPC\\n\\nHow to select an LLM from Hugging Face for a given task\\n\\nLLM inference and supervised full fine-tuning on UVA HPC\\n\\nHow to write a Slurm script for LLM code using PyTorch\\n\\nResearch Computing Data Analytics Center\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_13.png width=80% height=80% >}}\\n\\nhttps://www.rc.virginia.edu/service/dac/')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1258 of 1477]\n",
      "Found 1257 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/slurm-scripts/what-is-slurm.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: What is a Slurm Script? date: \"2025-02-23T00:00:00\" type: docs weight: 3150 menu: llms-hpc: name: Slurm Scripts\\n\\nHPC environments are generally shared resources among a group of users.\\n\\nIn order to manage user jobs, we use Slurm, a resource manager for Linux clusters. This includes deciding which jobs run, when those jobs run, and which node(s) they run on.\\n\\nA Slurm script provides Slurm with the necessary information to run a job, including details about the required computational resources, the necessary software, and the command(s) needed to execute the code file.\\n\\nFrom our website: Jobs are submitted to the Slurm controller, which queues them until the system is ready to run them. The controller selects which jobs to run, when to run them, and how to place them on the compute node or nodes, according to a predetermined site policy meant to balance competing user needs and to maximize efficient use of cluster resources.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1259 of 1477]\n",
      "Found 1258 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/slurm-scripts/slurm-ex.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Example Slurm Script - PyTorch date: \"2025-02-23T00:00:00\" type: docs weight: 3200 menu: llms-hpc: parent: Slurm Scripts\\n\\nBelow is an example Slurm script which runs a task using the Pytorch framework and GPUs on the cluster.\\n\\n```bash\\n\\n!/bin/bash\\n\\nSBATCH -A mygroup\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:1\\n\\nSBATCH -c 1\\n\\nSBATCH -t 00:01:00\\n\\nSBATCH -J pytorchtest\\n\\nSBATCH -o pytorchtest-%A.out\\n\\nSBATCH -e pytorchtest-%A.err\\n\\nload software\\n\\nmodule purge module load apptainer pytorch\\n\\nrun code\\n\\napptainer run --nv $CONTAINERDIR/pytorch-2.4.0.sif pytorch_example.py\\n\\n```\\n\\nSet up resources: * -A: allocation * -p: partition * --gres=gpu:1 : use 1 gpu * -c: number of cores * -t: time limit * -J: job name * -o: standard output file (%A is the job #) * -e: standard error file (%A is the job #)\\n\\nThe default command defined in each container is python so using run basically executes python file_name.py.\\n\\nThe load software and run code lines are what a user would use to run their script at the command line.\\n\\nTensorFlow example')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1260 of 1477]\n",
      "Found 1259 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/slurm-scripts/options-slurm.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: More Slurm Options date: \"2025-02-23T00:00:00\" type: docs weight: 3250 menu: llms-hpc: parent: Slurm Scripts\\n\\nTo request a specific amount of memory per node:\\n\\nEx: --mem=64G\\n\\nUnits are given with a suffix (K, M, G, or T). If no unit is given, megabytes is assumed.\\n\\nOther options are available at https://slurm.schedmd.com/sbatch.html\\n\\nFor more information, see the RC tutorial Using SLURM from a Terminal.\\n\\nTip: if you have a Jupyter notebook file (.ipynb) that you would like to run using a Slurm script, first convert it to a .py file using the following command (make sure you are in the directory that contains the file):\\n\\njupyter nbconvert --to python file_name.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1261 of 1477]\n",
      "Found 1260 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/llm-overview/terminology.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Terminology date: \"2025-02-23T00:00:00\" type: docs weight: 300 menu: llms-hpc: parent: Overview of LLMs\\n\\nLLMs can have billions of parameters (unknown quantities in the model).\\n\\nAn LLM is trained (model parameters are determined) using a very large amount of text data.\\n\\nA pre-trained LLM has already been trained. This process allows the model to learn the language.\\n\\nA fine-tuned LLM is a pre-trained LLM that then is further trained on additional data for a specific task. Model parameters are updated in the fine-tuning process.\\n\\nInference is the process in which a trained (or fine-tuned) LLM makes a prediction for a given input.\\n\\nThe input to an LLM is a sequence of tokens (words, characters, subwords, etc.)\\n\\nThe batch size for an LLM is the number of sequences passed to the model at once.\\n\\nGenerally, raw text is passed through a tokenizer which processes it into tokens and sequences and then numerical data which can be sent to the LLM.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1262 of 1477]\n",
      "Found 1261 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/llm-overview/llm-overview.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Overview of LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 200 menu: llms-hpc: name: Overview of LLMs\\n\\nA Large Language Model (LLM) is a deep learning model that generally solves a natural language processing problem. ChatGPT is an example of an LLM.\\n\\nThere are many different types of LLMs that are suited to particular tasks.\\n\\nHubs such as Hugging Face provide many LLMs for download.\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_0.png height=90% width=90% caption=\"Graphic Source: https://attri.ai/blog/introduction-to-large-language-models\" >}}\\n\\nYou may hear people talk about LLMs for image classification, computer vision, etc. These are also called VLMs (vision language models) and we are not covering those today.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1263 of 1477]\n",
      "Found 1262 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/llm-overview/theory-llms.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Theory Behind LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 400 menu: llms-hpc: parent: Overview of LLMs\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_2.png height=50% width=50% >}}\\n\\nLLMs are based on the transformer architecture. We are not covering this in todays workshop.\\n\\nMore Information: * Attention Is All You Need by Vaswani et al. (2017) * https://jalammar.github.io/illustrated-transformer/')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1264 of 1477]\n",
      "Found 1263 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/llms-hpc/llm-overview/nlp-problems.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: NLP Problems Solved by LLMs date: \"2025-02-23T00:00:00\" type: docs weight: 250 menu: llms-hpc: parent: Overview of LLMs\\n\\n{{< figure src=/notes/llms-hpc/img/LLMS_on_HPC_1.png height=75% width=75% >}}\\n\\nProblems:\\n\\nClassify : An example of classification is sentiment analysis of Tweets.\\n\\nRewrite : An example of rewriting is text translation.\\n\\nExtract : An example of extraction is finding company names in news articles.\\n\\nGenerate : An example of generation is creating a story.\\n\\nSearch : An example of search is question answering from a text passage.\\n\\nApplications of solutions to NLP problems include chatbots, virtual assistants, and recommendation systems.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1265 of 1477]\n",
      "Found 1264 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/gpu-applications-rivanna/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"GPU-Enabled Applications on Rivanna\" type: article toc: true date: 2022-10-19T00:00:00-05:00\\n\\nweight: 5000\\n\\nIn this workshop participants are introduced to the gpu computing resources on Rivanna.\\n\\nIntroduction to GPU\\n\\nThe graphics processing unit was invented specifically for graphics rendering. Nowadays they are also used as accelerators for parallel computing; you may also hear the term \"general-purpose GPU\" (GPGPU).\\n\\n{{< table >}} |Property|CPU|GPU| |---|---|---| |Number of cores|$10^{0-1}$ | $10^{3-4}$ | |Throughput | Low | High | |Per-core performance | High | Low | |Workload type| Generic | Specific (e.g. rendering, deep learning)| |Memory on Rivanna| up to 1.5 TB per node | up to 80 GB per device | {{< /table >}}\\n\\nIntegrated vs discrete GPU\\n\\nIntegrated GPUs are mostly for graphics rendering and light gaming. They are integrated on the CPU motherboard to achieve more compact systems.\\n\\nDiscrete (or dedicated) GPUs are designed for resource-intensive computations.\\n\\nGPU vendors and types\\n\\nNVIDIA, AMD, Intel\\n\\nDatacenter: H100, A100, V100, P100, K80\\n\\nWorkstation: A6000, Quadro\\n\\nGaming: GeForce RTX 40xx, 30xx, 20xx\\n\\n(bold means available on Rivanna)\\n\\nMyths\\n\\nGPUs are better than CPUs and will eventually replace them. CPU and GPU complement each other. GPU will not replace CPU.\\n\\nIf I run my CPU code on a GPU, it\\'ll be way faster. This depends on whether your code can run on a GPU at all. Even so, if the computation is not resource-intensive enough, there will be no acceleration. In fact, your code may even be slower on a GPU.\\n\\nRunning a GPU program on two GPU devices will be twice as fast as running it on one. Again, this depends on whether your program can run on multiple GPU devices and the computation intensity.\\n\\nGPU acceleration only applies to data science and machine/deep learning. Many scientific codes are making use of GPU acceleration: VASP, QuantumEspresso, GROMACS, ... See here for a list compiled in 2018.\\n\\nGPUs on Rivanna\\n\\nGo to this page. GPUs are indicated by \"GPU\" under the specialty hardware column.\\n\\nCommand to check the current status of GPU nodes:\\n\\n```bash $ qlist -p gpu\\n\\nSTATE NODE CPUS(A/I/O/T) TOTALMEM(MB) ALLOCMEM(MB) AVAILMEM(MB) GRES(M:T:A) JOBS\\n\\nmix udc-an28-1 8/120/0/128 1000000 40960 959040 gpu:a100:8(S:0-7):1 1 mix udc-an28-7 28/100/0/128 1000000 680960 319040 gpu:a100:8(S:0-7):6 6 mix udc-an33-37 12/24/0/36 384000 384000 0 gpu:v100:4(S:0-1):3 3 ... ```\\n\\nImportant things to note:\\n\\nCPU memory is not GPU memory\\n\\nEach GPU node contains multiple GPU devices\\n\\nDifferent GPU types have different specs (GPU memory, CPU cores, etc.)\\n\\nIn descending order of performance: A100, V100, P100, K80\\n\\nGPU-Enabled Applications on Rivanna\\n\\nPopular GPU applications on Rivanna at a glance\\n\\n{{< table >}} |nvhpc|gcc/goolf|nvompic|singularity|Jupyter kernels| |---|---|---|---|---| |(User code)|gromacs |quantumespresso|pytorch |PyTorch| | |gpunufft|berkeleygw |tensorflow|TensorFlow| | |mumax3 |yambo |rapidsai |RAPIDS| | | | |amptorch |AMPTorch| | | | |alphafold || | | | |deeplabcut|| | | | |isaacgym || {{< /table >}}\\n\\nModules\\n\\nThe nvhpc module (NVIDIA HPC SDK) provides these libraries and tools: - Compilers (nvc, nvc++, nvfortran) - CUDA - Mathematical libraries: cuBLAS, cuRAND, cuFFT, cuSPARSE, cuTENSOR, cuSOLVER - Communication libraries: NVSHMEM, NCCL - Tools: CUDA-GDB, Nsight System\\n\\nIn addition, applications are installed under three toolchains goolfc, nvompic (compiled languages), and singularity (container).\\n\\ngoolfc\\n\\nStands for:\\n\\nGCC compilers (g)\\n\\nOpenMPI (o)\\n\\nOpenBLAS (o)\\n\\nScaLAPACK (l)\\n\\nFFTW (f)\\n\\nCUDA (c)\\n\\n```bash\\n\\ngoolfc: goolfc/9.2.0_3.1.6_11.0.228\\n\\nDescription:\\n  GNU Compiler Collection (GCC) based compiler toolchain along with CUDA\\n  toolkit, including OpenMPI for MPI support with CUDA features enabled,\\n  OpenBLAS (BLAS and LAPACK support), FFTW and ScaLAPACK with CUDA features\\n  enabled.\\n\\n\\nThis module can be loaded directly: module load goolfc/9.2.0_3.1.6_11.0.228\\n\\n```\\n\\nThe toolchain version consists of three subversions joined by _, corresponding to the version of gcc, openmpi, and cuda, respectively.\\n\\n```bash $ module load goolfc $ module avail\\n\\n------- /apps/modulefiles/standard/mpi/gcc-cuda/9.2.0-11.0.228/openmpi/3.1.6 ------- fftw/3.3.8 (L,D) hoomd/2.9.6 python/3.8.8 (D) gromacs/2021.2 python/3.7.7 scalapack/2.1.0 (L)\\n\\n----------- /apps/modulefiles/standard/compiler/gcc-cuda/9.2.0-11.0.228 ------------ gpunufft/2.1.0 mumax3/3.10 nccl/2.7.8 openmpi/3.1.6 (L,D) ```\\n\\nUsage instructions\\n\\nGROMACS\\n\\nnvompic\\n\\nStands for:\\n\\nNVIDIA compilers (nv)\\n\\nOpenMPI (ompi)\\n\\nCUDA (c)\\n\\n```bash $ module spider nvompic\\n\\nnvompic: nvompic/21.9_3.1.6_11.4.2\\n\\nDescription:\\n  NVHPC Compiler including OpenMPI for MPI support.\\n\\n\\nThis module can be loaded directly: module load nvompic/21.9_3.1.6_11.4.2\\n\\n```\\n\\nThe toolchain version consists of three subversions joined by _, corresponding to the version of nvhpc, openmpi, and cuda, respectively.\\n\\n```bash $ module load nvompic $ module avail ------------- /apps/modulefiles/standard/mpi/nvhpc/21.9/openmpi/3.1.6 ------------- berkeleygw/3.0.1 fftw/3.3.10 (D) quantumespresso/7.0 yambo/5.0.4 elpa/2021.05.001 hdf5/1.12.1 (D) scalapack/2.1.0\\n\\n----------------- /apps/modulefiles/standard/compiler/nvhpc/21.9 ------------------ hdf5/1.12.1 openblas/0.3.17 (D) openmpi/3.1.6 (L,D) ```\\n\\nUsage Instructions\\n\\nBerkeleyGW\\n\\nQuantumEspresso\\n\\nsingularity\\n\\nThe popular deep learning frameworks, TensorFlow and PyTorch, are backed by containers. (To learn more about containers, see Using Containers on Rivanna.)\\n\\nbash module load singularity tensorflow\\n\\nOn JupyterLab, you may conveniently select the kernel of the desired framework and version.\\n\\nUsage instructions\\n\\nTensorFlow\\n\\nPyTorch\\n\\nRAPIDS (also see workshop)\\n\\nJupyter kernels\\n\\nTensorFlow\\n\\nPyTorch\\n\\nRAPIDS\\n\\nRequesting a GPU\\n\\nOpen OnDemand\\n\\nSelect the gpu partition. If you need a specific GPU type, select from the dropdown menu. Default will assign you the first available GPU.\\n\\nSlurm script\\n\\nYour Slurm script must contain these lines:\\n\\n```bash\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu\\n\\n```\\n\\nSee here for further information.\\n\\nDemo (Python & Matlab)\\n\\nCongratulations - you have completed this tutorial!\\n\\nReferences\\n\\nCPU vs GPU: What\\'s the Difference\\n\\nNVIDIA HPC SDK documentation\\n\\n\"That Was Fast: GPUs Now Accelerate Almost 600 HPC Apps\"')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1266 of 1477]\n",
      "Found 1265 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/bioinfo-tools-riv/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Using Bioinformatics Tools on Rivanna\" date: \"2021-03-02T21:13:14-05:00\" authors: [gka]\\n\\n{{< slideshow folder=\"slides/bioinfomatics-tools-riv\" ext=\"png\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1267 of 1477]\n",
      "Found 1266 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/benchmark-parallel-programs/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Benchmarking Parallel Programs\" type: article toc: true date: 2020-10-29T00:00:00-05:00\\n\\nMotivation\\n\\nTrue or false:\\n\\n\"If I use more cores/GPUs, my job will run faster.\"\\n\\n\"I can save SU by using more cores/GPUs, since my job will run faster.\"\\n\\n\"I should request all cores/GPUs on a node.\"\\n\\nNew HPC users may implicitly assume that these statements are true and request resources that are not well utilized. The disadvantages are:\\n\\nWasted SU. All requested cores/GPUs count toward the SU charge, even if they are idle. (SU is the \"currency\" for resource usage on a cluster. The exact definition will be presented later.)\\n\\nLong waiting time. The more resources you request, the longer it is likely to wait in the queue.\\n\\nUnpleasant surprise to see little or no performance improvement.\\n\\nThe premise of parallel scalability is that the program has to be parallelizable. Please read the documentation of your program to determine whether there is any benefit of using multiple cores/GPUs. (Exception: A serial program may need more memory than a single core can provide. You will need to request multiple cores, but this is a memory-bound issue and is different from the execution speed. We shall not consider this scenario for the remainder of the tutorial.)\\n\\nWhat is benchmarking? And why/when should I benchmark?\\n\\nA benchmark is a measurement of performance. We will focus on the execution time of a program for a given task. (This is also known as strong scaling in parallel computing.) However, even for a serial program, a benchmark can still be useful when you run the program on different platforms. For instance, if a certain task takes 1 hour to complete on your laptop and 5 hours on Rivanna, there could be something wrong with how the program was installed on Rivanna.\\n\\nBut doesn\\'t benchmarking cost SU? Two things. First, the dev partition is the perfect choice for benchmarking and debugging purposes, as long as you stay within the limits. Remember, you do not need to complete the entire task if it takes too long; a fixed subtask would do. This could be an epoch in machine learning training, a time step in molecular dynamics simulation, a single iteration, etc., instead of reaching full convergence. This way you can perform the benchmark without spending SU.\\n\\nSecond, if the benchmark cannot be performed on dev for whatever reason (e.g. even the smallest subtask would take more than 1 hour, or the job needs more cores than the limit), it is true that you will have to spend SU for benchmarking, but you may still gain in the long term, especially if you are running many production jobs of a similar nature (high-throughput). If you manage to prevent overspending say 10 SU per job, then after 10,000 jobs you would have saved 100k SU, an entire allocation. (Linear term trumps constant, eventually.)\\n\\nBesides the amount of hardware, sometimes certain parameters of a program can have a huge impact on performance as well (e.g. batch size in machine learning training, NPAR/KPAR in VASP). You will need to find the optimum parameter to achieve the best performance specific to your problem. This may not translate across platforms - what\\'s optimal on one platform can be suboptimal on another, so you must perform a benchmark whenever you use a different platform!\\n\\nBenchmarking will also help you get a better sense of the scale of your project and how many SU it entails. Instead of blindly guessing, you will be able to request cores/GPUs/walltime wisely.\\n\\nConcepts and Theory\\n\\nDefinitions\\n\\nDenote the number of cores (or GPU devices) as $N$ and the walltime as $t$. The reference for comparison is the job that uses $N=1$ and has a walltime of $t_1$.\\n\\nSpeedup is defined as $s=t_1/t$. For example, a job that finishes in half the time has a speedup factor of 2.\\n\\nPerfect scaling is achieved when $N=s$. If you manage to halve the time ($s=2$) by doubling the resources ($N=2$), you achieve perfect scaling.\\n\\nOn Rivanna, the SU (service unit) charge rate is defined as $$SU = (N_{\\\\mathrm{core}} + 2N_{\\\\mathrm{gpu}}) t,$$ where $t$ is in units of hours.\\n\\nWe can define a relative SU, i.e. the SU relative to that of the reference: $$\\\\frac{SU}{SU_1} = \\\\frac{Nt}{t_1} = \\\\frac{N}{s}.$$\\n\\nIn the case of perfect scaling, $N=s$ and so the relative SU is 1, which means you spend the same amount of SU for the parallel job as for its serial reference. Since sublinear scaling ($s<N$) almost always occurs, the implication is that you need to pay an extra price for parallelization. For example, if you use 2 cores ($N=2$) and reduce the walltime by only one-third ($s=1.5$), then the relative SU is equal to $N/s=1.33$, which means you spend 33% more SU than the serial job reference. Whether this is worth it will of course depend on:\\n\\nthe actual value of $s$,\\n\\nthe maximum walltime limit for the partition on Rivanna, and\\n\\nyour deadline.\\n\\nAmdahl\\'s Law\\n\\nA portion of a program is called parallel if it can be parallelized. Otherwise it is said to be serial. In this simple model, a program is strictly divided into parallel and serial portions. Denote the parallel portion as $p$ ($0 \\\\le p \\\\le 1$) and the serial portion as $1-p$ (so that the sum equals 1).\\n\\nSuppose the program takes a total execution time of $t_1$ to run completely in serial. Then the execution time of the parallelized program can be expressed as a function of $N$: $$t = \\\\left[(1-p) + \\\\frac{p}{N}\\\\right] t_1,$$ where the time spent in the serial portion, $(1-p)t_1$, is irrespective of $N$.\\n\\nThe speedup is thus $$s=\\\\frac{t_1}{t} = \\\\frac{1}{1-p+\\\\frac{p}{N}}.$$\\n\\nAs $N\\\\rightarrow\\\\infty$, $s\\\\rightarrow 1/(1-p)$. This is the theoretical speedup limit.\\n\\nExercise: a) Find the maximum speedup if 99%, 90%, 50%, 10%, and 0% of the program is parallelizable. b) For $N=100$, what is the relative SU in each case?\\n\\nb) First calculate the actual speedup (not the theoretical limit): 50.25, 9.17, 1.98, 1.11, 1. Relative SU: 1.99, 10.9, 50.5, 90.1, 100.\\n\\nNotice how the wasted SU increases dramatically.\\n\\nExercise: What is the theoretical limit in relative SU? $$\\\\lim_{N\\\\rightarrow\\\\infty} \\\\frac{SU}{SU_1}$$ Hint: Consider cases $s<N$ and $s=N$ separately.\\n\\nTools\\n\\nThe performance is usually tracked by the execution time.\\n\\ntime\\n\\nThe time command is included in most Linux distributions. You can simply prepend it to whatever command you want to time. For example:\\n\\n```bash $ time sleep 5\\n\\nreal 0m5.026s user 0m0.001s sys 0m0.006s ```\\n\\nNotice there are 3 lines of output - real, user, and sys. A good explanation of these can be found here; for this tutorial, it is sufficient to use the real time. (The CPU time is given by user + sys, which in this case is almost 0 because the command is just sleep.)\\n\\nperf\\n\\nA more dedicated tool for performance measurement is perf. Instead of a single measurement, it is more accurate to run a benchmark multiple times and take the average. The perf tool contains built-in statistical analysis. Advanced users please refer to the official tutorial. Load the module if you would like to use perf: module load perf.\\n\\nIf you just want to get a rough idea with an error bar of say 5-10%, time suffices. The task should last significantly longer than 1 second.\\n\\nExamples\\n\\nMulti-core: Gaussian\\n\\nGaussian is a quantum chemistry software package that can run on multiple CPU cores. This example is the open-shell vanilomycin test (#0709) included with the software.\\n\\nSetup\\n\\nFirst load the module: bash module load gaussian\\n\\nIf you are using Gaussian only through a course: bash module load gaussian/grads16\\n\\nCopy the input file: bash cp $g16root/g16/tests/com/test0709.com .\\n\\nPrepare a SLURM script (job.slurm): ```bash\\n\\n!/bin/bash\\n\\nSBATCH -A\\n\\nSBATCH -p standard\\n\\nSBATCH -t 10:00:00\\n\\nSBATCH -N 1\\n\\nSBATCH -c 1\\n\\nSBATCH -C skylake\\n\\nmodule purge module load gaussian # or gaussian/grads16 hostname grep -c processor /proc/cpuinfo cp $g16root/g16/tests/com/test0709.com . g16 -p=$SLURM_CPUS_PER_TASK test0709.com ```\\n\\nNote: - The number of cores (#SBATCH -c <num>) is passed through the $SLURM_CPUS_PER_TASK environment variable to Gaussian\\'s -p flag. This ensures consistency. - $g16root is an environment variable made available to you after you load the Gaussian module. - The time command is not needed here because Gaussian will time the job automatically.\\n\\nSubmit the job: bash sbatch job.slurm\\n\\nBenchmark\\n\\nModify the SLURM script to use 4, 8, 16, and 32 cores. Submit these jobs. The walltime can be read from the test0709.log file.\\n\\nbash $ grep Elapsed test0709.log Elapsed time: 0 days 0 hours 15 minutes 35.4 seconds.\\n\\nYou should obtain similar results as follows:\\n\\nN Time (s) Speedup Relative SU 1 12323.9 1.00 1.00 4 2968.3 4.15 0.96 8 1528.5 8.06 0.99 16 935.4 13.18 1.21 32 842.2 14.63 2.19\\n\\nDon\\'t get excited about the apparent superlinear scaling ($s>N$ for $N=4,8$) - it is within the margin of error.\\n\\nThe speedup is plotted below. Notice the perfect scaling up to $N=8$. The scaling performance worsens beyond 8 cores and drastically beyond 16. This does not mean 8 is the magic number to use for all Gaussian jobs - it only applies to calculations of a similar nature.\\n\\n{{< figure src=\"gaussian.png\" width=\"600px\" >}}\\n\\nExercise: Does this obey Amdahl\\'s Law? Why or why not?\\n\\nMulti-GPU: PyTorch\\n\\nPyTorch can make use of multiple GPU devices through the DistributedDataParallel (DDP) backend. This example is based on our PyTorch 1.7 container using the Python script provided by PyTorch Lightning with minor modifications. (The container uses CUDA 11 which is compatible with Rivanna hardware after the December 2020 maintenance.)\\n\\nSetup\\n\\nDownload the container. The following command will create a Singularity container pytorch_1.7.0.sif. bash module load singularity singularity pull docker://uvarc/pytorch:1.7.0\\n\\nCopy the following as a plain text file (example.py).\\n\\n```python import os import torch from torch import nn import torch.nn.functional as F from torchvision.datasets import MNIST from torch.utils.data import DataLoader, random_split from torchvision import transforms import pytorch_lightning as pl\\n\\nclass LitAutoEncoder(pl.LightningModule):\\n\\ndef __init__(self):\\n    super().__init__()\\n    self.encoder = nn.Sequential(nn.Linear(28 * 28, 128), nn.ReLU(), nn.Linear(128, 3))\\n    self.decoder = nn.Sequential(nn.Linear(3, 128), nn.ReLU(), nn.Linear(128, 28 * 28))\\n\\ndef forward(self, x):\\n    # in lightning, forward defines the prediction/inference actions\\n    embedding = self.encoder(x)\\n    return embedding\\n\\ndef training_step(self, batch, batch_idx):\\n    # training_step defined the train loop. It is independent of forward\\n    x, y = batch\\n    x = x.view(x.size(0), -1)\\n    z = self.encoder(x)\\n    x_hat = self.decoder(z)\\n    loss = F.mse_loss(x_hat, x)\\n    self.log(\\'train_loss\\', loss)\\n    return loss\\n\\ndef validation_step(self, batch, batch_idx):\\n    x, y = batch\\n    x = x.view(x.size(0), -1)\\n    z = self.encoder(x)\\n    x_hat = self.decoder(z)\\n    loss = F.mse_loss(x_hat, x)\\n    self.log(\\'val_loss\\', loss)\\n    return loss\\n\\ndef configure_optimizers(self):\\n    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\\n    return optimizer\\n\\ndataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor()) train, val = random_split(dataset, [55000, 5000])\\n\\nautoencoder = LitAutoEncoder() trainer = pl.Trainer(max_epochs=1, gpus=1) trainer.fit(autoencoder, DataLoader(train), DataLoader(val)) ```\\n\\nPrepare a SLURM script (job.slurm) that runs the above Python script. We would like to download the MNIST data files first and exclude the download time from the actual benchmark. (More on this later.) Also specify a GPU type for consistency.\\n\\n```\\n\\n!/bin/bash\\n\\nSBATCH -A\\n\\nSBATCH -t 00:10:00\\n\\nSBATCH -N 1\\n\\nSBATCH --ntasks-per-node=1\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:1\\n\\nmodule purge module load singularity\\n\\ntime singularity run --nv pytorch_1.7.0.sif example.py ```\\n\\nSubmit the job. bash sbatch job.slurm\\n\\nBenchmark\\n\\nSet download=False in example.py: python dataset = MNIST(os.getcwd(), download=False, transform=transforms.ToTensor())\\n\\nResubmit the job to set the reference ($t_1$). Next, to make use of multiple GPU devices, use the ddp backend: python trainer = pl.Trainer(max_epochs=1, gpus=2, distributed_backend=\\'ddp\\') For this example, use the same number in --ntasks-per-node and --gres=gpu in your SLURM script. Also add srun (important): bash time srun singularity run --nv pytorch_1.7.0.sif example.py\\n\\nResults on a K80 GPU:\\n\\nN Time (s) Speedup Relative SU 1 226 1.00 1.00 2 134 1.69 1.18 3 95 2.38 1.26 4 76 2.97 1.35\\n\\nThe speedup is plotted below. Notice how the deviation from perfect scaling (light diagonal line) increases with $N$.\\n\\n{{< figure src=\"ddp_k80.png\" width=\"400px\" >}}\\n\\nThe same benchmark was performed on RTX 2080Ti:\\n\\nN Time (s) Speedup Relative SU 1 171 1.00 1.00 2 108 1.58 1.26 3 79 2.16 1.39 4 64 2.67 1.50 5 57 3.00 1.67 6 52 3.29 1.82 7 51 3.35 2.09 8 49 3.49 2.29 9 49 3.49 2.58 10 49 3.49 2.87\\n\\nNotice the plateau beyond $N=6$, which implies that you should not request more than 6 GPU devices for this particular task. (A good balance between speed and SU effectiveness may be $2\\\\le N \\\\le 4$.)\\n\\n{{< figure src=\"ddp_rtx.png\" width=\"400px\" >}}\\n\\nExercise: Deduce the parallel portion $p$ of this program using Amdahl\\'s Law.\\n\\nThe performance of K80 vs RTX 2080Ti is compared below. On a single GPU device, the latter is 30% faster.\\n\\n{{< figure src=\"k80_rtx.png\" width=\"400px\" >}}\\n\\nRemarks\\n\\nA complete machine learning benchmark would involve such parameters as batch size, learning rate, etc. You may pass a sparse grid to locate a desirable region and, if necessary, use a finer grid in that region to identify the best choice.\\n\\nExercise: Revisit the true-or-false questions at the beginning of this tutorial and answer them in your own words.\\n\\nExercise: A user performed a benchmark on the standard partition and determined that a serial job would take 10 days to complete and that the theoretical speedup limit is 4. The entire project involves 1,000 such jobs. Assume that all 1,000 jobs can start running immediately. (The standard partition has a walltime limit of 7 days. No job extensions can be granted.) a) What is the minimum amount of SU needed to finish the entire project? b) The user has a deadline of 3 days. How many cores should the user request per job? How many extra SU will need to be spent compared to the minimum in a)? c) Suppose the user did not perform the benchmark and just randomly decided to use 20 cores per job. How much time and how many SU will the user spend for this project? Compare your answer with b). d) Repeat b) but this time the deadline is in 50 hours.\\n\\nThe moral of this exercise is two-fold: do your benchmark and plan ahead!')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1268 of 1477]\n",
      "Found 1267 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/pytorch_coding.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Coding a PyTorch date: \"2022-06-09T00:00:00\" type: docs weight: 600 menu: python-machine-learning: parent: PyTorch\\n\\nGeneral Steps\\n\\nImport the torch package\\n\\nRead in the data\\n\\nPreprocess the data 3a. Scale the data 3b. Split the data 3c. Convert data to tensors 3d. Load the tensors\\n\\nDesign the Network Model\\n\\nDefine the Learning Process\\n\\nTrain the model\\n\\nApply the model to the test data\\n\\nDisplay the results\\n\\n1. Import torch Package\\n\\n```python import torch if torch.cuda.is_available(): device_type = \"cuda:\" + str(torch.cuda.current_device()) else: device_type = \"cpu\"\\n\\ndevice = torch.device(device_type) ```\\n\\n2. Read in the Data\\n\\npython import numpy as np data_file = \\'Data/cancer_data.csv\\' target_file = \\'Data/cancer_target.csv\\' x=np.loadtxt(data_file,dtype=float,delimiter=\\',\\') y=np.loadtxt(target_file, dtype=float, delimiter=\\',\\') print(\"shape of x: {}\\\\nshape of y: {}\".format(x.shape,y.shape))\\n\\n3a. Scale the data\\n\\n```python\\n\\nfeature scaling\\n\\nfrom sklearn.preprocessing import StandardScaler sc = StandardScaler() x = sc.fit_transform(x) ```\\n\\n3b. Split the Data\\n\\npython from sklearn import model_selection test_size = 0.30 seed = 7 train_data, test_data, train_target, test_target = model_selection.train_test_split(x, y, test_size=test_size, random_state=seed)\\n\\n3c. Convert data to tensors\\n\\n```python\\n\\ndefining dataset class\\n\\nfrom torch.utils.data import Dataset\\n\\nclass dataset(Dataset): def init(self,x,y): self.x = torch.tensor(x,dtype=torch.float32) self.y = torch.tensor(y,dtype=torch.float32) self.length = self.x.shape[0]\\n\\ndef getitem(self,idx): return self.x[idx],self.y[idx]\\n\\ndef len(self): return self.length\\n\\ntrainset = dataset(train_data,train_target) ```\\n\\n3d. Load the tensors\\n\\n```python\\n\\nDataLoader\\n\\nfrom torch.utils.data import DataLoader\\n\\ntrainloader = DataLoader(trainset,batch_size=64,shuffle=False) ```\\n\\n4. Design the Network Model\\n\\n```python from torch import nn\\n\\nclass Net(nn.Module): def init(self,input_shape): super(Net,self).init() self.fc1 = nn.Linear(input_shape,32) self.fc2 = nn.Linear(32,64) self.fc3 = nn.Linear(64,1)\\n\\ndef forward(self,x): x = torch.relu(self.fc1(x)) x = torch.relu(self.fc2(x)) x = torch.sigmoid(self.fc3(x)) return x\\n\\nmodel = Net(input_shape=x.shape[1]) ```\\n\\n5. Define the Learning Process\\n\\n```python learning_rate = 0.01 epochs = 700\\n\\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) loss_fn = nn.BCELoss() ```\\n\\n6. Fit the Model\\n\\n```python losses = [] accur = []\\n\\nfor i in range(epochs): for j,(x_train,y_train) in enumerate(trainloader):\\n\\n#calculate output\\noutput = model(x_train)\\n\\n#calculate loss\\nloss = loss_fn(output,y_train.reshape(-1,1))\\n\\n#accuracy\\npredicted = model(torch.tensor(x,dtype=torch.float32))\\nacc = (predicted.reshape(-1).detach().numpy().round() == y).mean()\\n#backprop\\noptimizer.zero_grad()\\nloss.backward()\\noptimizer.step()\\n\\nif i%50 == 0: losses.append(loss) accur.append(acc) print(\"epoch {}\\\\tloss : {}\\\\t accuracy : {}\".format(i,loss,acc)) ```\\n\\n7. Apply the Model to Test Data\\n\\npython testset = dataset(test_data,test_target) trainloader = DataLoader(testset,batch_size=64,shuffle=False) predicted = model(torch.tensor(test_data,dtype=torch.float32))\\n\\n8. Evaluate the Results\\n\\n```python acc = (predicted.reshape(-1).detach().numpy().round() == test_target).mean()\\n\\nprint(\\'\\\\nAccuracy: %.3f\\' % acc)\\n\\nfrom sklearn.metrics import confusion_matrix predicted = predicted.reshape(-1).detach().numpy().round()\\n\\nprint(confusion_matrix(test_target, predicted)) ```\\n\\nActivity: PyTorch Program\\n\\nMake sure that you can run the PyTorch code: 06_PyTorch.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1269 of 1477]\n",
      "Found 1268 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/tensorflow_coding.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Coding a Tensor Flow date: \"2022-06-09T00:00:00\" type: docs weight: 500 menu: python-machine-learning: parent: TensorFlow\\n\\nGeneral Steps\\n\\nLoad the neural network packages\\n\\nRead in the data\\n\\nDivide the data into a training set and a test set.\\n\\nPreprocess the data\\n\\nDesign the Network Model\\n\\nTrain the model\\n\\nApply the model to the test data\\n\\nDisplay the results\\n\\n1. Load Keras Packages\\n\\npython from tensorflow import keras from tensorflow.keras import layers from tensorflow.keras.utils import to_categorical\\n\\n2. Read in the Data\\n\\npython import numpy as np data_file = \\'Data/cancer_data.csv\\' target_file = \\'Data/cancer_target.csv\\' cancer_data=np.loadtxt(data_file,dtype=float, delimiter=\\',\\') cancer_target=np.loadtxt(target_file, dtype=float, delimiter=\\',\\')\\n\\n3. Split the Data\\n\\npython from sklearn import model_selection test_size = 0.30 seed = 7 train_data, test_data, train_target, test_target = model_selection.train_test_split(cancer_data,cancer_target, test_size=test_size, random_state=seed)\\n\\n4. Pre-process the Data\\n\\n```python from sklearn.preprocessing import StandardScaler scaler = StandardScaler()\\n\\nFit only to the training data\\n\\nscaler.fit(train_data)\\n\\nNow apply the transformations to the data:\\n\\nx_train = scaler.transform(train_data) x_test = scaler.transform(test_data)\\n\\nConvert the classes to \\'one-hot\\' vector\\n\\ny_train = to_categorical(train_target, num_classes=2) y_test = to_categorical(test_target, num_classes=2) ```\\n\\n5. Define the Model\\n\\n```python def define_model(): from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Dropout from tensorflow.keras.optimizers import SGD\\n\\nmodel = keras.Sequential([ layers.Dense(30, activation=\"relu\"), layers.Dropout(0.5), layers.Dense(60, activation=\"relu\"), layers.Dropout(0.5), layers.Dense(2, activation=\"softmax\") ])\\n\\nmodel.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\\n\\nreturn(model)\\n\\nmodel = define_model() ```\\n\\n7.Fit the Model\\n\\npython b_size = int(.8*x_train.shape[0]) num_epochs = 20 model.fit(x_train, y_train, epochs=num_epochs, batch_size=b_size)\\n\\n8.Apply the Model to Test Data\\n\\npython predictions = np.argmax(model.predict(x_test), axis=-1)\\n\\n9.Evaluate the Results\\n\\npython score = model.evaluate(x_test, y_test, batch_size=b_size) print(\\'\\\\nAccuracy: %.3f\\' % score[1]) from sklearn.metrics import confusion_matrix print(confusion_matrix(test_target, predictions))\\n\\nActivity: TensorFlow Program\\n\\nMake sure that you can run the TensorFlow code: 04_TensorFlow.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1270 of 1477]\n",
      "Found 1269 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/machine_learning_overview.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Machine Learning Overview date: \"2022-06-09T00:00:00\" type: docs weight: 100 toc: true menu: python-machine-learning:\\n\\nMachine learning is a branch of artificial intelligence where computers learn from data, and adapt the computational models to enhance performance. It is a method of analysis that allows computers to reveal information within data. The \"learning\" is not the type of learning that you and I do. Instead, it is a systematic approach to finding an appropriate data transformation from inputs to output.\\n\\nWhy Machine Learning?\\n\\nComputers can sort through data faster than humans can.\\n\\nComputers can identify patterns quickly and use these patterns for predictions or classifications.\\n\\nMachine learning can handle noisy data  it doesn\\'t find a perfect answer, but rather a \"really good\" answer.\\n\\nProblems that ML can solve\\n\\nRegression\\n\\nRegression models determine a mathematical model for the relationship among features or attributes so that an outcome can be predicted.\\n\\nResults can be any value within a possible range (e.g., what will the average Earth temperature be in 2050?)\\n\\nClassification\\n\\nClassification techniques identify a combination of attributes that best fits a class or category so that an object can be classified.\\n\\nResults can be from a list of known possibilities (e.g., is the tumor benign or malignant?)\\n\\nTypes of Machine Learning\\n\\nSupervised Learning:\\n\\nA data set exists where the samples can be categorized into two or more classifications.\\n\\nThe computer uses the data set to learn how to predict the classification of an unknown sample.\\n\\nExamples include Decision Trees and Deep Learning\\n\\nUnsupervised Learning:\\n\\nThe collected data has no known classification or pattern.\\n\\nThe computer must identify the groups or hidden structures within the data.\\n\\nExamples include Dendograms, K-means clustering, Self-organizing Maps\\n\\nReinforcement Learning:\\n\\nComputer learns from positive or negative feedback\\n\\nExample includes Swarm intelligence\\n\\nData for Machine Learning\\n\\nData are plural, and the singular is datum\\n\\nFor many Machine Learning algorithms, the data are expected to be in a table format, where:\\n\\neach row represents an object, and\\n\\neach column has the measurements for a specific attribute or feature of the object\\n\\nFor supervised learning, the classifications of the objects must be known.\\n\\nThe data with known classifications are divided into a training set and a testing set.\\n\\nThe data are used to develop a model.\\n\\nThe training data are submitted to an algorithm that will fit a model to the data.\\n\\nThe test data are submitted to the model to produce predicted classifications and determine the accuracy of the model.\\n\\nFinally, the model can be used to predict classifications for \"unknown\" data.\\n\\nIdeas behind Machine Learning\\n\\nThe algorithm determines the best mathematical model for the code. However, you still need to provide a \"framework\" for the algorithm.The framework provides the algorithm with tools for performing the learning: * Machine Learning Algorithm * Data Measurements * Model defining the relationship between the input and the output * Label or Classification\\n\\n{{< figure src=/notes/python-machine-learning/img/ml_overview.png caption=\"\" width=75% height=75% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1271 of 1477]\n",
      "Found 1270 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/multi_gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Multi-GPU Example date: \"2022-06-09T00:00:00\" type: docs weight: 650 menu: python-machine-learning:\\n\\nActivity: Multi-GPU Program\\n\\nBefore running this next notebook, you will need to create a new JupyterLab session and request 2 GPUs rather than 1.\\n\\nMake sure that you can run the PyTorch code: 07_Tensorflow_Parallel.ipynb\\n\\nSupplemental Information\\n\\nCheck out our material on Convolutional Neural Networks: https://learning.rc.virginia.edu/notes/deep-learning-distributed/cnn/\\n\\nActivity: Convolutional Neural Networks:\\n\\nMake sure that you can run the CNN code: 05_CNN.ipynb\\n\\nQuestions or Need More help?\\n\\nOffice Hours via Zoom:\\n\\nTuesdays: 3 pm - 5 pm\\n\\nThursdays: 10 am - noon\\n\\nZoom Links are available at https://www.rc.virginia.edu/support/#office-hours * Website: https://rc.virginia.edu')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1272 of 1477]\n",
      "Found 1271 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/random_forest.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Random Forest date: \"2022-06-09T00:00:00\" type: docs weight: 250 toc: true menu: python-machine-learning:\\n\\nRandom forest is a classification algorithm within supervised learning. It uses an Ensemble Technique. * Ensemble techniques combine a group of \"weaker\" learning techniques to build a stronger technique. * Random Forest combines the results of multiple decision trees to create a more robust result.\\n\\nRandom Forest: How does it work?\\n\\n{{< figure src=/notes/python-machine-learning/img/random_forest_dt.png caption=\"Image borrowed from https://ai-pool.com/a/s/random-forests-understanding\" width=70% height=70% >}}\\n\\nDifferent decision tree algorithms can produce different results.The random forest aggregates the decisions from the trees to determine an overall solution.\\n\\nSuppose that the data fall into one of two categories (blue or orange) depending on two values, x and y, as shown in this figure: {{< figure src=/notes/python-machine-learning/img/linear_decision.png caption=\"\" width=25% height=25% >}}\\n\\nA decision tree could choose a relationship between x, y, and the categories that matches one of the following figures: {{< figure src=/notes/python-machine-learning/img/decision_tree_choices.png caption=\"\" width=50% height=50% >}}\\n\\nBy combining the many, many outcomes, the random forest can approach the desired mapping. {{< figure src=/notes/python-machine-learning/img/random_forest.png caption=\"\" width=60% height=60% >}}\\n\\nRandom Forests can use different techniques for selecting features for computing each decision value. This can lead to the choice of different features.\\n\\n{{< figure src=/notes/python-machine-learning/img/random_forest_tree.png caption=\"\" width=70% height=70% >}}\\n\\nRandom Forest: Feature Importance\\n\\n{{< figure src=/notes/python-machine-learning/img/feature_importance.png caption=\"\" width=50% height=50% >}}\\n\\nWe would like to know the \"importance\" of the features (e.g., which features are the most important for making decisions).\\n\\nDifferent algorithms use various metrics to determine the importance of the features.\\n\\nThe value of the measurements are not as important as the order of the features.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1273 of 1477]\n",
      "Found 1272 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/pytorch.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: PyTorch date: \"2022-06-09T00:00:00\" type: docs weight: 550 toc: true menu: python-machine-learning:\\n\\nPyTorch is another interface for example of TensorFlow. It is a software library, developed by Facebook and maintained by Mega AI.\\n\\nBecause PyTorch uses Tensorflow as the underlying code, many of the required functions (e.g., activation, loss, optimizer) will be the same.\\n\\nActivation Function\\n\\nThe activation function will be determine if a node should \"fire\".\\n\\nExamples include nn.ReLU, nn.Sigmoid, and nn.Softmax.\\n\\nA complete list is available at\\n\\nhttps://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity\\n\\nhttps://pytorch.org/docs/stable/nn.html#non-linear-activations-other\\n\\nLoss Function\\n\\nThe loss function will be optimized to improve the performance of the model.\\n\\nExamples include nn.BCELoss (Binary CrossEntropy) and nn.CrossEntropyLoss.\\n\\nA complete list is available at https://pytorch.org/docs/stable/nn.html#loss-functions\\n\\nOptimizer functions\\n\\nThe optimizer function is used for tweaking the weights.\\n\\nExamples include SGD, Adam, and RMSprop.\\n\\nA complete list is available at https://pytorch.org/docs/stable/optim.html?highlight=optimizer#torch.optim.Optimizer')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1274 of 1477]\n",
      "Found 1273 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/random_forest_coding.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Coding a Random Forest date: \"2022-06-09T00:00:00\" type: docs weight: 300 menu: python-machine-learning: parent: Random Forest\\n\\nThe Data\\n\\nFor the Random Forest example, we will reuse the winequality_red data set.\\n\\nCoding Random Forest: General Steps\\n\\nLoad the random forest packages\\n\\nRead in the data\\n\\nIdentify the target feature\\n\\nDivide the data into a training set and a test set. a. Choose the sample size b. Randomly select rows c. Separate the data\\n\\nFit the random forest model\\n\\nApply the model to the test data\\n\\nDisplay the feature importance\\n\\n1. Load Random Forest Package\\n\\npython from sklearn.ensemble import RandomForestClassifier\\n\\n2, 3, 4.\\n\\n```python\\n\\nRepeat steps 2-4 from the Decision Tree example\\n\\nimport pandas as pd . . . train_data, test_data, train_target, test_target = model_selection.train_test_split(wine_data, wine_target, test_size=test_size, random_state=seed) ```\\n\\n5. Fit the Random Forest Model\\n\\npython model = RandomForestClassifier() model.fit(train_data, train_target)\\n\\n6. Apply the Model to the Test Data\\n\\npython forest_results = model.predict(test_data)\\n\\n7. Compute Feature Importance\\n\\npython importances = model.feature_importances_\\n\\n8. List Feature Importance\\n\\npython import numpy as np indices = np.argsort(importances)[::-1] print(\"Feature ranking:\") col_names = list(train_data.columns.values) for f in range(len(indices)): feature = col_names[indices[f]] space = \\' \\'*(20 - len(feature)) print(\"%d.\\\\t %s %s (%f)\" % \\\\ (f + 1, feature, space, importances[indices[f]]))\\n\\nActivity: Random Forest Program\\n\\nMake sure that you can run the Random Forest code: 02_Random_Forest.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1275 of 1477]\n",
      "Found 1274 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/decision_trees.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Decision Trees date: \"2022-06-09T00:00:00\" type: docs toc: true weight: 150 menu: python-machine-learning:\\n\\nDecision trees are a classification algorithm within supervised learning. The algorithm determines a set of questions or tests that will guide it toward a classification of an observation and it organizes a series of attribute tests into a tree-structure to help determine classification of the unlabeled data.\\n\\nMotivating Question: Given a set of data, can we determine which attributes should be tested first to predict a category or outcome (i.e., which attributes lead to \"high information gain\")?\\n\\nSimple Scenario\\n\\nSuppose we have: * a group of people, each one with a tumor, and * two measurements (x, y) for each tumor.\\n\\nPlotting the data, and coloring the points red for malignant tumors and blue for benign tumors, we might see a plot as follows:\\n\\n{{< figure src=/notes/python-machine-learning/img/pre_decision_plot.png caption=\"\" width=60% height=60% >}}\\n\\nClearly, something happens near x=3.\\n\\n{{< figure src=/notes/python-machine-learning/img/decision_plot.png caption=\"\" width=60% height=60% >}}\\n\\nWith very few errors, we can use x=3 as our \"decision\" to categorize the tumor as malignant versus benign.\\n\\nResulting decision tree:\\n\\n{{< figure src=/notes/python-machine-learning/img/result_decision_tree.png caption=\"\" width=30% height=30% >}}\\n\\nUnfortunately, it is not always this easy, especially if we have much more complex data. More layers of questions can be added with more attributes.\\n\\nExample: What should you do this weekend?\\n\\n{{< table >}} | Weather | Parents Visiting | Have extra cash | Weekend Activity | | :-: | :-: | :-: | :-: | | Sunny | Yes | Yes | Cinema | | Sunny | No | Yes | Tennis | | Windy | Yes | Yes | Cinema | | Rainy | Yes | No | Cinema | | Rainy | No | Yes | Stay In | | Rainy | Yes | No | Cinema | | Windy | No | No | Cinema | | Windy | No | Yes | Shopping | | Windy | Yes | Yes | Cinema | | Sunny | No | Yes | Tennis | {{< /table >}}\\n\\nThis table can be represented as a tree.\\n\\n{{< figure src=/notes/python-machine-learning/img/tree_first.png caption=\"\" width=65% height=65% >}}\\n\\nThis tree can be made more efficient.\\n\\n{{< figure src=/notes/python-machine-learning/img/tree_second.png caption=\"\" width=50% height=50% >}}\\n\\nAlso with complex data, it is possible that not all features are needed in the Decision Tree.\\n\\nDecision Tree Algorithms\\n\\nThere are many existing Decision Tree algorithms. If written correctly, the algorithm will determine the best question/test for the tree.\\n\\nHow do we know how accurate our decision tree is?\\n\\nDecision Tree Evaluation\\n\\nA confusion matrix is often used to show how well the model matched the actual classifications.\\n\\nThe matrix is not confusing  it simply illustrates how \"confused\" the model is!\\n\\nIt is generated based on test data.\\n\\n{{< figure src=/notes/python-machine-learning/img/decision_tree_chart.png caption=\"\" width=70% height=70% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1276 of 1477]\n",
      "Found 1275 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Machine Learning for Python date: \"2022-06-09T00:00:00\" type: docs weight: 1\\n\\nmenu: python-machine-learning:\\n\\nIn this tutorial we will be covering the following topics: * Overview of Machine Learning * Decision Trees * Coding Decision Trees * Random Forest * Coding Random Forest * Overview of Neural Networks * Coding Neural Networks * Tensorflow/Keras * Coding Tensorflow * PyTorch * Coding PyTorch * Overview of Parallelizing Deep Learning * Coding\\n\\nAs mentioned above, example codes will be provided for respective topics. Prior experience with the Python programming language and some familiarity with machine learning concepts are helpful for this tutorial. Please download and unzip the following file to follow along on code activities.\\n\\n{{< file-download file=\"notes/python-machine-learning/code/ML_with_Python.zip\" text=\"ML_with_Python.zip\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1277 of 1477]\n",
      "Found 1276 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/tensorflow.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: TensorFlow date: \"2022-06-09T00:00:00\" type: docs weight: 450 toc: true menu: python-machine-learning:\\n\\nTensorFlow is an example of deep learning, a neural network that has many layers. It is a software library developed by the Google Brain Team.\\n\\nDeep Learning Neural Network\\n\\n{{< figure src=/notes/python-machine-learning/img/deep_neural_network.jpg caption=\"Image borrowed from: http://www.kdnuggets.com/2017/05/deep-learning-big-deal.html\" width=50% height=50% >}}\\n\\nTerminology: Tensors\\n\\nA Tensor is a multi-dimensional array.\\n\\nExample: A sequence of images can be represented as a 4-D array: [image_num, row, col, color_channel]\\n\\n{{< figure src=/notes/python-machine-learning/img/tensors.png caption=\"\" width=60% height=60% >}}\\n\\nTerminology: Computational Graphs\\n\\nComputational graphs help to break down computations.\\n\\nFor example, the graph for $y=(x1+x2)*(x2 - 5)$:\\n\\n{{< figure src=/notes/python-machine-learning/img/computational_graph.png caption=\"The beauty of computational graphs is that they show where computations can be done in parallel.\" width=40% height=40% >}}\\n\\nThe Need for GPUs\\n\\nWith deep learning models, you can have hundreds of thousands of computational graphs. A GPU has the ability to perform a thousand or more of the computational graphs simultaneously. This will speed up your program significantly.\\n\\nNote: Most algorithms can run without GPUs, but they will be slower.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1278 of 1477]\n",
      "Found 1277 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/neural_networks_coding.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Coding a Neural Network date: \"2022-06-09T00:00:00\" type: docs weight: 400 menu: python-machine-learning: parent: Neural Networks\\n\\nExample: Breast Cancer Data\\n\\nThe Cancer data set originally was captured at UCI Repository (https://archive.ics.uci.edu/ml/datasets.html)\\n\\nLook at the data, so that you understand what is in each file.\\n\\n{{< table >}} | Filename | Brief Description | | :-: | :-: | | cancer_data.csv | The table of measurements cancer_DESCR.csv  an overview of the data | | cancer_feature_names.csv | The names of the columns in cancer_data.csv | | cancer_target.csv | The classification (0 or 1) of each row in cancer_data.csv | | cancer_target_names.csv | The names of the classifications (malignant or benign) | {{< /table >}}\\n\\nCoding a Neural Network: General Steps\\n\\nLoad the neural network packages\\n\\nRead in the data\\n\\nDivide the data into a training set and a test set.\\n\\nPreprocess the data\\n\\nDesign the Network Model\\n\\nTrain the model\\n\\nApply the model to the test data\\n\\nDisplay the results\\n\\n1. Load Neural Networks Package\\n\\npython from tensorflow import keras from tensorflow.keras import layers\\n\\n2. Read in the Data\\n\\npython import numpy as np data_file = \\'Data/cancer_data.csv\\' target_file = \\'Data/cancer_target.csv\\' cancer_data=np.loadtxt(data_file,dtype=float,delimiter=\\',\\') cancer_target=np.loadtxt(target_file, dtype=float, delimiter=\\',\\')\\n\\n3. Divide Data\\n\\n```python from sklearn import model_selection\\n\\ntest_size = 0.30\\n\\nseed = 7\\n\\ntrain_data, test_data, train_target, test_target = model_selection.train_test_split(cancer_data, cancer_target, test_size=test_size, random_state=seed) ```\\n\\n4. Preprocess the Data\\n\\n```python\\n\\nConvert the classes to \\'one-hot\\' vector\\n\\nfrom keras.utils import to_categorical y_train = to_categorical(train_target, num_classes=2) y_test = to_categorical(test_target, num_classes=2) ```\\n\\n5. Design the Network Model\\n\\n```python def define_model(): model = keras.Sequential([ layers.Dense(30, activation=\"relu\"), layers.Dense(2, activation=\"softmax\") ]) model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"] ) return(model)\\n\\nmodel = define_model() ```\\n\\n6. Train the Model\\n\\npython num_epochs = 10 batch_size = 32 model.fit(train_data, y_train, epochs=num_epochs, batch_size=batch_size)\\n\\n7. Apply the Model to the Test Data\\n\\npython predictions = np.argmax(model.predict(test_data), axis=-1)\\n\\n8. Display the Results\\n\\npython score = model.evaluate(test_data, y_test) print(\\'\\\\nAccuracy: %.3f\\' % score[1]) from sklearn.metrics import confusion_matrix print(confusion_matrix(test_target, predictions))\\n\\nActivity: Neural Network Program\\n\\nMake sure that you can run the Neural Network codes: 03_Neural_Network.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1279 of 1477]\n",
      "Found 1278 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/decision_trees_coding.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Coding a Decision Tree date: \"2022-06-09T00:00:00\" type: docs weight: 200 menu: python-machine-learning: parent: Decision Trees\\n\\nThe Data\\n\\nFor our first example, we will be using a set of measurements taken on various red wines.\\n\\nThe data set is from\\n\\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\\n\\nThe data is located at\\n\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\\n\\nThere are 12 measurements, taken on 1599 different red wines.\\n\\nAttribute Summary\\n\\n{{< figure src=/notes/python-machine-learning/img/attribute_summary.png caption=\"\" width=50% height=50% >}}\\n\\nQuestion: Can we predict the quality of the wine from the attributes?\\n\\nCoding Decision Trees: General Steps\\n\\nLoad the decision tree packages\\n\\nRead in the data\\n\\nIdentify the target feature\\n\\nDivide the data into a training set and a test set.\\n\\nFit the decision tree model\\n\\nApply the model to the test data\\n\\nDisplay the confusion matrix\\n\\n1. Load Decision Tree Package\\n\\npython from sklearn import tree\\n\\n2. Read in the data\\n\\npython import pandas as pd data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" wine = pd.read_csv(data_url, delimiter=\\';\\') print(wine.info())\\n\\n3. Identify the target feature\\n\\n```python\\n\\nSplit the quality column out of the data\\n\\nwine_target = wine[\\'quality\\'] wine_data = wine.drop(\\'quality\\', axis=1) ``` For the functions that we will be using, the target values (e.g., quality) must be a separate object.\\n\\n4. Divide the Data\\n\\npython from sklearn import model_selection test_size = 0.30 seed = 7 train_data, test_data, train_target, test_target = model_selection.train_test_split(wine_data, wine_target, test_size=test_size, random_state=seed)\\n\\n5. Fit the Decision Tree Model\\n\\npython model = tree.DecisionTreeClassifier() model = model.fit(train_data, train_target)\\n\\n6. Apply the Model to the Test Data\\n\\npython prediction = model.predict(test_data)\\n\\n7. Display Confusion Matrix\\n\\npython row_name =\"Quality\" cm = pd.crosstab(test_target, prediction, rownames=[row_name], colnames=[\\'\\']) print(\\' \\'*(len(row_name)+3),\"Predicted \", row_name) print(cm)\\n\\nActivity: Decision Tree Program\\n\\nMake sure that you can run the decisionTree code: 01_Decision_Tree.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1280 of 1477]\n",
      "Found 1279 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/python-machine-learning/neural_networks.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Neural Networks date: \"2022-06-09T00:00:00\" type: docs weight: 350 toc: true menu: python-machine-learning:\\n\\nNeural networks are a computational model used in machine learning which is based on the biology of the human brain.\\n\\nThe building blocks of a neural network are neurons, also known as nodes. Within each node is a very basic algebraic formula that transforms the data.\\n\\nSimulation of a Neuron\\n\\n{{< figure src=/notes/python-machine-learning/img/neuron_simulation.png caption=\"\" width=60% height=60% >}}\\n\\nThe \"incoming signals\" would be values from a data set.\\n\\nA simple computation (like a weighted sum) is performed by the \"nucleus\". Then, an \"activation\" function is used to determine if the output is \"on\" or \"off\".\\n\\nThe weights, $w_i$, and the bias $b$, are not known at first. Random guesses are chosen. During training, the \"best\" set of weights are determined that will generate a value close to $y$ for the collection of inputs $x_i$.\\n\\nNetwork of Nodes\\n\\nA single node does not provide much information (often times, a 0 or 1 value), but creating a network or layer of nodes will provide more information.\\n\\n{{< figure src=/notes/python-machine-learning/img/node_network.png caption=\"\" width=60% height=60% >}}\\n\\nDifferent computations with different weights can be performed to produce different outputs. This is called a feedforward network  all values progress from the input to the output.\\n\\nThe Layers of a Network\\n\\n{{< figure src=/notes/python-machine-learning/img/neuron_network_layers.png caption=\"\" width=60% height=60% >}}\\n\\nA neural network has a single hidden layer. A neural network with two or more hidden layers is called a \"deep neural network\".\\n\\nHow does the machine learn?\\n\\nThe output values or \"predicted\" values of the network can be compared with the expected results/categories/labels.\\n\\nStart with a random guess for the weights and biases.\\n\\nAnother function, called a \"loss\" or \"cost\" function can be used to determine the overall error of the model.\\n\\nThat error can be used to work backwards through the network and tweak the weights/biases.\\n\\nThis step is called backward propagation .\\n\\nOverview of the Learning Process\\n\\n{{< video src=\"/notes/python-machine-learning/video/learning_process.mp4\" controls=\"yes\" >}}\\n\\nActivation Function\\n\\nAn activation function will determine if a node should \"fire\".\\n\\nExamples include relu, sigmoid, and softmax.\\n\\nA complete list is available at https://keras.io/api/layers/activations/ .\\n\\nLoss Function\\n\\nA loss function is a function that will be optimized to improve the performance of the model.\\n\\nExamples include BinaryCrossEntropy and CategoricalCrossEntropy.\\n\\nA complete list is available at https://keras.io/api/losses/ .\\n\\nMetrics: A formula for measuring the accuracy of the model. * Examples include Accuracy and MeanSquaredError. * A complete list is available at https://keras.io/api/metrics.\\n\\nOptimizer functions\\n\\nThe function for tweaking the weights.\\n\\nExamples include SGD, Adam, and RMSprop.\\n\\nA complete list is available at https://keras.io/api/optimizers/ .\\n\\nEpochs and Batch Size\\n\\nEpochs: Number of loops  how many times the forward/backward process should be performed.\\n\\nBatch Size: Within an epoch, the training data are divided into small batches and sent through the network. All training data are processed in an epoch.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1281 of 1477]\n",
      "Found 1280 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_7.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Environment Variables\" linktitle: \"Tutorial 7: Environment Variables\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 80 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nVariables are a way of passing information from the shell to programs when you run them. Programs look \"in the environment\" for particular variables and if they are found will use the values stored. Some are set by the system, others by you, yet others by the shell, or any program that loads another program. Standard Unix variables are split into two categories, environment variables and shell variables. In broad terms, shell variables apply only to the current instance of the shell and are used to set short-term working conditions. Environment variables are exported and have a farther reaching significance; those set at login are valid for the duration of the session. By convention, environment variables are written in UPPERCASE while shell variables usually have lowercase names.\\n\\nEnvironment Variables\\n\\nAn example of an environment variable is the $SHELL variable. The value of this is the current shell you are using. Type bash % echo $SHELL\\n\\nMore examples of environment variables are bash $USER (your login name) $HOME (the path name of your home directory) $PWD (current working directory) $DISPLAY (the name of the computer screen to display X windows; only set if X is enabled) $PATH (the directories the shell should search to find a command)\\n\\nUsing and Setting Variables\\n\\nEnvironment variables are set using the export command (bash or zsh) or the setenv command (tcsh or csh), displayed using the printenv (bash, tcsh) or env (bash, zsh) commands, and unset using the unsetenv command. To show all values of these variables, type\\n\\nbash % printenv | more\\n\\nTo set a value of an environment variable, type (for bash)\\n\\nbash % export VAR=value\\n\\nSourcing\\n\\nA group of shell commands can be placed into a file and then sourced. When a file is sourced, the commands are executed as if they had been typed at the command line in the current shell. For example, if several environment variables needed to be set over and over again, they could be collected into a file such as this simple script called envs.sh:\\n\\n{{< code-download file=\"/notes/unix-tutorial/snippets/envs.sh\" lang=\"bash\" >}}\\n\\nExercise 6A\\n\\nDownload the envs.sh file to the Unix system you are using. Run the command bash source envs.sh\\n\\nPrint the values of the environment variables in the file. To print the value of the shell variable ncpus, type bash echo $ncpus\\n\\nDotfiles\\n\\nEach time you log in to a Unix host, the system looks in your home directory for initialization files. Information in these files is used to set up your working environment. The first initialization file sourced is the login initialization. It is sourced only in the login shell. Note: modern \"desktop\" user interfaces tend to \"swallow\" the login setup file, and it may be difficult to determine what is happening in these cases if there is an error.\\n\\nAt login the bash shell first sources .bash_profile or .profile (if .bash_profile exists .profile will be ignored). Child shells source .bashrc. The zsh sources .zprofile and child shells source .zshrc. Two older shells, csh (C shell) and tcsh, read .login for login shells and .cshrc or .tcshrc for all other shells.\\n\\nNote that all these file names begin with periods or \"dots\"; hence they are called dotfiles. As we have learned, dotfiles are hidden and will only be visible with ls -a.\\n\\nThe .bash_profile, .profile, or .login is to set conditions which will apply to the whole session and/or to perform actions that are relevant only at login. The .bashrc, .zshrc, or .tcshrc file is used to set conditions and perform actions specific to the shell and to each invocation of it. The rc stands for resource; many Unix dotfiles use this convention to set resources.\\n\\nIf you wish for your login shell to source the .bashrc also, add the lines bash if [ -f ~/.bashrc ]; then . ~/.bashrc fi to the .bash_profile script.\\n\\nWarning: NEVER put commands that run graphical displays (e.g. web browsers) in your dotfiles. If you change your .bashrc you can force the shell to reread it by using the shell source command.\\n\\n% source ~/.bashrc\\n\\nSetting the Path\\n\\nWhen you type a command, your path (or $PATH) variable defines in which directories the shell will look to find the command you typed. If the system returns a message saying \"command: Command not found\", this indicates that either the command doesn\\'t exist at all on the system or it is simply not in your path.\\n\\nFor example, suppose you have installed a program called \"units\" into your home directory in a folder called units174. Units is a simple utility that can convert Imperial to metric and vice versa, from SI to cgi, and so forth. This folder contains a bin subdirectory in which the executable is located. To run units, you must either directly specify the units path (~/units174/bin/units), or you need to have the directory ~/units174/bin in your path. You can add it to the end of your existing path (the $PATH represents this) by issuing the command: bash % export PATH=$PATH:$HOME/units174/bin\\n\\nIf you have units installed you can test that this worked by trying to run units in any directory other than where units is actually located. % cd; units Hint: You can run multiple commands on one line by separating them with a semicolon.\\n\\nTo add this path permanently, add the export line to your .bashrc file after the list of other commands. Make sure that you include the $PATH when you reset it, or you will lose access to basic system commands!')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1282 of 1477]\n",
      "Found 1281 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_4.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Wildcards and File Access\" linktitle: \"Tutorial 4: Wildcards and File Access\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 50 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nWildcards\\n\\nThe Characters * and ?\\n\\nThe character * is called a wildcard, and will match against none or more character(s) in a file (or directory) name. For example, in your unixstuff directory, type\\n\\nbash % ls list* This will list all files in the current directory starting with list. Try typing % ls *list This will list all files in the current directory ending with list. The character ? will match exactly one character. So ls ?ouse will match files like house and mouse, but not grouse. Try typing bash % ls ?list\\n\\nFilename Conventions\\n\\nUnix regards a directory as merely a special type of file. So the rules and conventions for naming files apply also to directories. In naming files, characters with special meanings, such as / * & %, should be avoided. Also avoid using spaces within names. The safest way to name a file is to use only alphanumeric characters, that is, letters and numbers, together with _ (underscore) and . (dot). File names conventionally start with a lower-case letter, and may end with a dot followed by a group of letters indicating the contents of the file. For example, all files consisting of C code may be named with the ending .c, for example, prog1.c. Then in order to list all files containing C code in your home directory, you need only type ls *.c in that directory.\\n\\nBeware: some applications give the same name to all the output files they generate. For example, some compilers, unless given the appropriate option, produce compiled files named a.out. Should you forget to use that option, you are advised to rename the compiled file immediately, otherwise the next such file will overwrite it and the original file will be lost.\\n\\nThe Unix system itself ignores file suffixes. You could name your C++ program mycode.py and Linux will not care. However, many applications do care about file extensions. A C++ compiler will expect the file to end in .cpp or .cxx. It will not recognize a file ending in .py, but a Python interpreter would.\\n\\nFilesystem Security (Access Rights)\\n\\nIn your unixstuff directory, type % ls -l (l for long listing!) You will see that you now get lots of details about the contents of your directory, similar to the example below.\\n\\n{{< code file=\"/notes/unix-tutorial/snippets/ls-l.txt\" lang=\"bash\" >}}\\n\\nEach file (and directory) has associated access rights, which may be found by typing ls -l.\\n\\nIn the left-hand column is a 10-symbol string consisting of the symbols d, r, w, x, -, and, occasionally, s or S. If d is present, it will be at the left hand end of the string and indicates a directory; otherwise - will be the starting symbol of the string. The nine remaining symbols indicate the permissions, or access rights, and are taken as three groups of three.\\n\\nthe leftmost group of 3 gives the file permissions for the user that owns the file (or directory) (mst3k in the above example);\\n\\nthe middle group gives the permissions for the group of people to whom the file (or directory) belongs (users in the above example);\\n\\nthe rightmost group gives the permissions for all others. The symbols r, w, etc., have slightly different meanings depending on whether they refer to a simple file or to a directory.\\n\\nAccess Rights on Files\\n\\nr (or -), indicates read permission, that is, the presence or absence of permission to read and copy the file\\n\\nw (or -), indicates write permission, that is, the permission (or otherwise) to change a file\\n\\nx (or -), indicates execution permission, that is, the permission to execute a file, where appropriate\\n\\nAccess Rights on Directories\\n\\nr allows users to list files in the directory\\n\\nw means that users may delete files from the directory or move files into it\\n\\nx means the right to access files in the directory or to cd into it.\\n\\nSo, in order to read a file, you must have execute permission on the directory containing that file, and hence on any directory containing that directory as a subdirectory, and so on, up the tree.\\n\\nSome Examples\\n\\nPermissions Meaning -rwxrwxrwx a file that everyone can read, write and execute (and delete) -rw------- a file that only the owner can read and write: no one else can read or write and no one has execution rights (e.g., yourmailbox file)\\n\\nChanging Access Rights\\n\\nchmod (changing a file mode)\\n\\nOnly the owner of a file can use chmod to change the permissions of a file. The options of chmod are as follows:\\n\\nSymbol Meaning u user g group o other a all r read w write (and delete) x execute (and access directory) + add permission - take away permission For example, to remove read write and execute permissions on the file biglist for the group and others, type ``` % chmod go-rwx biglist ``` This will leave the other permissions unaffected. To give read and write permissions on the file biglist to all, ``` % chmod a+rw biglist ```\\n\\nExercise 4A\\n\\nTry changing access permissions on the file science.txt and on the directory backups. Use ls -l to check that the permissions have changed.\\n\\nShared Systems\\n\\nSome multiuser systems, such as high-performance clusters, may not permit chmod on certain directories, or may automatically revert to the default set of permissions (called the umask). This is for data protection and privacy for users.\\n\\nSummary\\n\\nCommand Operation * match any number of characters ? match one character chmod change file or directory permissions')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1283 of 1477]\n",
      "Found 1282 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_3.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"More About Files\" linktitle: \"Tutorial 3: More About Files\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 40 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nRedirection\\n\\nMost processes initiated by Unix commands write to the standard output (that is, they write to the terminal screen), and many take their input from the standard input (that is, they read it from the keyboard). There is also the standard error, where processes write their error messages, by default to the terminal screen. Type cat without specifying a file to read bash % cat Then type a few words on the keyboard and press the [Return] key. Finally hold the [CTRL] key down and press [d] (written as ^D for short) to end the input. What has happened? If you run the cat command without specifying a file to read, it reads the standard input (the keyboard), and on receiving the \\'end of file\\' (^D), copies it to the standard output (the screen). In UNIX, we can redirect both the input and the output of commands.\\n\\nRedirecting the Output\\n\\nWe use the > symbol to redirect the output of a command. For example, to create a file called list1 containing a list of fruit, type bash % cat > list1 Then type in the names of some fruit as follows. Press [Return] after each one. Terminate with the end-of-file marker control-d (^D). no-highlight pear banana apple ^D The cat command reads the standard input (the keyboard) and the > redirects the output, which normally goes to the screen, into a file called list1. To read the contents of the file, type bash % cat list1\\n\\nExercise 3A\\n\\nUsing the above method, create another file called list2 containing the following fruit: orange, plum, mango, grapefruit. The form >> appends standard output to a file. So to add more items to the file list1, type bash % cat >> list1 Then type in the names of more fruit no-highlight peach grape strawberry ^D To read the contents of the file, type bash % cat list1\\n\\nYou should now have two files. One contains six fruit names, the other contains four fruits. We will now use the cat command to join (concatenate) list1 and list2 into a new file called biglist. Type\\n\\nbash % cat list1 list2 > biglist This reads the contents of list1 and list2 in turn, then outputs the text to the file biglist. To read the contents of the new file, type bash % cat biglist\\n\\nRedirecting the Input\\n\\nWe use the < symbol to redirect the input of a command. The command sort alphabetically or numerically sorts a list. Type bash % sort Using < you can redirect the input to come from a file rather than the keyboard. For example, to sort the list of fruit, type bash % sort < biglist and the sorted list will be output to the screen. To output the sorted list to a file, type bash % sort < biglist > slist Use cat to read the contents of the file slist.\\n\\nPipes\\n\\nTo see who is on the system with you, type bash % who One method to get a sorted list of names is to type bash % who > names.txt % sort < names.txt This is a bit slow and you have to remember to remove the temporary file called names.txt when you have finished. What you really want to do is connect the output of the who command directly to the input of the sort command. This is exactly what pipes do. The symbol for a pipe is the vertical bar | which, on a US keyboard, is above Enter on the right, with the backslash. For example, typing bash % who | sort will give the same result as above, but quicker and cleaner. To find out how many users are logged on, use wc (word count) with the option -l (ell) for number of lines only: bash % who | wc -l\\n\\nExercise 3B\\n\\nUsing pipes, print all lines of list1 and list2 containing the letter \\'p\\', sort the result, and print to a file sorted_plist.txt. Hint: from grep --help find an option to print only the line, omitting the file name.\\n\\n{{< spoiler text=\"Solution\" >}} {{< code file=\"/notes/unix-tutorial/snippets/ex3b.txt\" lang=\"bash\" >}} {{< /spoiler >}}\\n\\nSummary\\n\\nCommand Operation command > file redirect standard output to a file command >> file append standard output to a file command < file redirect standard input from a file command1 command2 cat file1 file2 > file0 concatenate file1 and file2 to file0 sort sort data who list users currently logged in')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1284 of 1477]\n",
      "Found 1283 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_5.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Processes and Jobs\" linktitle: \"Tutorial 5: Processes and Jobs\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 60 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nA process is an executing program identified by a unique PID (process identifier). To see information about your processes, with their associated PID and status, type bash % ps -u mst3k\\n\\nA process may be in the foreground, in the background, or be suspended. In general the shell does not return the Unix prompt until the current process has finished executing. Some processes take a long time to run and hold up the terminal. Backgrounding a long process has the effect that the Unix prompt is returned immediately, and other tasks can be carried out while the original process continues executing.\\n\\nRunning Background Processes\\n\\nTo background a process, type an & at the end of the command line. For example, the command sleep waits a given number of seconds before continuing. Type bash % sleep 10 This will wait 10 seconds before returning the command prompt %. Until the command prompt is returned, you can do nothing in that terminal except wait. To run sleep in the background, type ```bash % sleep 10 &\\n\\n[1] 6259 `` The&` runs the process in the background and returns the prompt immediately, allowing you to run other programs while waiting for that one to finish. The first line in the above example is typed in by the user; the next line, indicating job number and PID, is returned by the machine. The user is notified of a job number (numbered from 1) enclosed in square brackets, together with a PID and is notified when a background process is finished. Backgrounding is useful for jobs which will take a long time to complete.\\n\\nTo the system, a \"job\" represents a group of processes (often just one) to which signals should be sent. Signals include backgrounding, foregrounding, and cancelling. This meaning of \"job\" must be distinguished from \"jobs\" submitted to a queueing system such as Slurm. To a resource manager (queueing system) a \"job\" is a set of instructions to be executed.\\n\\nBackgrounding a Current Foreground Process\\n\\nAt the prompt, type bash % sleep 100 You can suspend the process running in the foreground by holding down the [CTRL] key and typing [z] (written as ^Z) Then to put it in the background, type bash % bg Note: do not background programs that require user interaction.\\n\\nListing Suspended and Background Processes\\n\\nWhen a process is running, backgrounded or suspended, it will be entered onto a list along with a job number. To examine this list, type bash % jobs An example of a job list could be\\n\\nSuspended sleep 100\\n\\nRunning firefox\\n\\nRunning vi\\n\\nTo restart (foreground) a suspended processes, type bash % fg %jobnumber For example, to restart sleep 100, type bash % fg %1\\n\\nTyping fg with no job number foregrounds the last suspended process.\\n\\nKilling a Process\\n\\nkill (terminate or signal a process)\\n\\nIt is sometimes necessary to kill a process (for example, when an executing program is in an infinite loop). To kill a job running in the foreground, type ^C ([CTRL] + [c]). For example, run bash % sleep 100 ^C\\n\\nTo kill a suspended or background process, type bash % kill %jobnumber\\n\\nFor example, run ```bash % sleep 100 &\\n\\n% jobs ```\\n\\nIf it is job number 4, type bash % kill %4\\n\\nTo check whether this has worked, examine the job list again to see if the process has been removed.\\n\\nps (process status)\\n\\nAlternatively, processes can be killed by finding their process numbers (PIDs) and using kill PID_number: ``` % sleep 100 & % ps\\n\\nPID TTY TIME CMD 20077 pts/5 S 0:05 sleep 100 21563 pts/5 T 0:00 firefox 21873 pts/5 S 0:25 vi To kill off the process `sleep 100`, type % kill 20077 and then type ps again to see if it has been removed from the list. If a process refuses to be killed, uses the `-9` option, i.e., type % kill -9 20077 ```\\n\\nLinux systems support a command killall which takes the name of the process rather than its PID. bash killall -9 sleep Note: It is not possible to kill off other users\\' processes! Unless, of course, it is a system you control and for which you have root privileges. The root account is the system administrator, and on Linux is all-powerful.\\n\\nSummary\\n\\nCommand Operation ls -lag list access rights for all files chmod [options] file change access rights for named file command & run command in background ^C kill the job running in the foreground ^Z suspend the job running in the foreground bg background the suspended job jobs list current jobs fg %1 foreground job number 1 kill %1 kill job number 1 ps list current processes kill 26152 kill process number 26152 killall name kill process name')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1285 of 1477]\n",
      "Found 1284 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_6.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Other Useful Commands\" linktitle: \"Tutorial 6: Other Useful Commands\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 70 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nexit\\n\\nExit the current shell. If it is the login shell, this command logs the user off.\\n\\nwhich\\n\\nThe which command indicates the path to the executable specified. bash % which myexec The which command returns the location of the executable according to the rules used to search paths. The shell always searches from left to right in the list contained in the PATH environment variable; the first executable of the specified name is the one that is used.\\n\\nwc\\n\\nThe wc command returns the number of lines, words, and characters in an ASCII file. A word is defined as a non-zero length string surrounded by whitespace. % wc myfile.txt\\n\\nTo print only the number of lines, use bash % wc l myfile.txt\\n\\ndiff\\n\\ndiff shows the differences between two ASCII files on a per-line basis. bash % diff file1 file2\\n\\nfind\\n\\nfind is an extremely powerful command with many options. The simplest and most common use of it is to search for a file of a given name or with a name containing a pattern. bash % find . -name myscript.sh This starts from current directory (.) and searches for myscript.sh. The period is optional under Linux (but not under Mac OSX). To search for a name with a pattern it must typically be enclosed in quotes bash % find . -name \"*.sh\"\\n\\nSee the manpage or examples online for more usage patterns of this command.\\n\\ndu\\n\\nThe du command outputs the number of kilobytes used by each subdirectory. Useful if you have gone over quota and you want to find out which directory has the most files. Some options make it more useful; in particular, -s summarizes directories and -h prints it in human-readable format. In your home directory, type bash % du -s -h *\\n\\ngzip and zip\\n\\nThis reduces the size of a file, thus freeing valuable disk space. For example, type bash % ls -l science.txt and note the size of the file. Then to compress science.txt, type bash % gzip science.txt\\n\\nThis will compress the file and place it in a file called science.txt.gz. To see the change in size, type ls -l again. To uncompress the file, use the gunzip command. % gunzip science.txt.gz\\n\\nMost Linux systems also provide the standard zip and unzip commands. bash % zip science.txt.zip % unzip science.txt.zip\\n\\ntar (tape archive)\\n\\nThe standard archive format in Linux is tar. Tar is usually used to bundle directories. (Zip can also be used for this purpose.) Typically the output file is compressed with gzip. bash tar czf mydir.tar.gz mydir The c option creates the tarfile (also called a \"tarball\"). The f option is for file, and this form of the command must be followed by the name of the file to contain the archive. The z option gzips the file.\\n\\nTo extract the files bash tar xf mydir.tar.gz Newer versions of tar can detect that the archive is zipped, so a z is not necessary for extraction. The x option extracts. This will create the directory mydir if it does not exist. If it does, the contents will be replaced by the contents of mydir.tar.gz.\\n\\nfile\\n\\nfile classifies the named files according to the type of data they contain, for example ASCII (text), pictures, compressed data, etc. To report on all files in your home directory, type bash % file *\\n\\ncut\\n\\nThe cut command extracts selected portions of a line, based on fields separated by a delimiter % cut\\xad?d delim \\xad?fC1,C2,C3\\n\\nExamples: bash % cut -d \\' \\' ?f1 /etc/resolve.conf % cat myfile | cut -c 80\\n\\nsort\\n\\nThis command sorts lines of a text file, based on command-\\xadline options. The default is to sort alphabetically, based on lexicographical ordering (in which e.g. 100 comes before 2). bash % sort mylist.txt\\n\\nuniq\\n\\nRemoves duplicate lines (file must be sorted first since it only compares lines pairwise). bash % uniq mylist.txt\\n\\nA frequent pattern is to pipe the output of sort into uniq bash % sort animals | uniq\\n\\nhistory\\n\\nThe bash shell keeps an ordered list of all the commands that you have entered. Each command is given a number according to the order it was entered. bash % history (show command history list) If you are using the bash or tcsh shell, you can use the exclamation character (!) to recall commands easily.\\n\\nbash % !! (recall last command) % !-3 (recall third most recent command) % !5 (recall 5th command in list) % !grep (recall last command starting with grep) You can increase the size of the history buffer by typing % set history=100')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1286 of 1477]\n",
      "Found 1285 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Working with Files\" linktitle: \"Tutorial 2: Working with Files\" date: 2019-04-29T11:06:47-04:00 draft: false highlight_style: \"github\" toc: true type: docs weight: 30 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nCopying Files\\n\\ncp (copy)\\n\\ncp file1 file2 is the command which makes a copy of file1 in the current working directory and calls it file2.\\n\\nFor our example we will create a file science.txt. Click the down-arrow icon to download the file. Use whatever method you know to place this file into your home directory.\\n\\n{{< code-download file=\"/notes/unix-tutorial/snippets/science.txt\" lang=\"no-highlight\" >}}\\n\\nbash % cd ~/unixstuff\\n\\nThen at the Unix prompt, type,\\n\\nbash % cp ../science.txt .\\n\\nNote: Don\\'t forget the dot (.) at the end. Remember, in UNIX, the dot means the current directory.\\n\\nThe above command means copy the file science.txt from the parent directory to the current directory, keeping the name the same. To change the name, use bash % cp ../science.txt ./newname\\n\\nExercise 2A\\n\\nCreate a backup of your science.txt file by copying it to a file called science.bak.\\n\\nMoving Files\\n\\nmv (move)\\n\\nmv file1 file2 moves (or renames) file1 to file2. To move a file from one place to another, use the mv command. This has the effect of moving rather than copying the file, so you end up with only one file rather than two. It can also be used to rename a file, by moving the file to the same directory, but giving it a different name. We are now going to move the file science.bak to your backup directory. First, change directories to your unixstuff directory (can you remember how?). Then, inside the unixstuff directory, type\\n\\nbash % mv science.bak backups/.\\n\\nType ls and ls backups to see if it has worked.\\n\\nRemoving Files and Directories\\n\\nrm (remove), rmdir (remove directory)\\n\\nTo delete (remove) a file, use the rm command. As an example, we are going to create a copy of the science.txt file then delete it. Inside your unixstuff directory, type\\n\\nbash % cp science.txt tempfile.txt Confirm the file was created: bash % ls Now delete it: bash % rm tempfile.txt % ls\\n\\nYou can use the rmdir command to remove a directory, but only if it is empty. Try to remove the backups directory. You will not be able to since Unix will not let you remove a non-empty directory.\\n\\nTo remove a non-empty directory use bash rm -rf directory\\n\\n{{< warning >}} The above command will remove the directory without confirming anything! Be extremely careful with it! {{< /warning >}}\\n\\nYou can request confirmation with bash % rm -if directory though this may be tedious. The -i option (inquire) also works for rm bash % rm -i myfile\\n\\nExercise 2B\\n\\nCreate a directory called tempstuff using mkdir, then remove it using the rmdir command.\\n\\nDisplaying the Contents of a File on the Screen\\n\\ncat (concatenate)\\n\\nThe cat command can show a text file\\'s contents bash % cat science.txt Be sure to use the correct path to the file. Cat can also join two text files, hence its name. bash % cat file1 file2 > file3 THe > sign is a redirection, which we will discuss later.\\n\\nclear (clear screen)\\n\\nClear the screen.\\n\\nmore\\n\\nThe command more prints the contents of a file onto the screen a page at a time. Type\\n\\nbash % more science.txt Press the [space bar] if you want to see another page. Type [q] if you want to quit reading.\\n\\nThe more command is an example of a pager, a program that \"pages\" through a text file.\\n\\nhead\\n\\nThe head command writes the first ten lines of a file to the screen. bash % head science.txt Now type bash % head -5 science.txt What difference did the -5 make to the head command?\\n\\ntail\\n\\nThe tail command writes the last ten lines of a file to the screen. Clear the screen and type bash % tail science.txt How can you view the last 15 lines of the file?\\n\\nSearching the Contents of a File\\n\\nSimple Searching Using more\\n\\nUsing more, you can search through a text file for a keyword (pattern). For example, to search through science.txt for the word \\'science\\', type\\n\\nbash % more science.txt then, still in more (i.e. don\\'t press [q] to quit), type a forward slash [/] followed by the word to search no-highlight /science The more command finds and highlights the keyword. Type [n] to search for the next occurrence of the word.\\n\\ngrep (don\\'t ask why it is called grep)\\n\\ngrep is one of many standard Unix utilities. It searches files for specified words or patterns. First clear the screen, then type\\n\\nbash % grep science science.txt As you can see, grep has printed out each line containing the word science... or has it? Try typing\\n\\nbash % grep Science science.txt The grep command is case-sensitive; it distinguishes between Science and science. To ignore upper/lower case distinctions, use the -i option, i.e. type\\n\\nbash % grep -i science science.txt\\n\\nTo search for a phrase or pattern, you must enclose it in single quotes (the apostrophe symbol). For example to search for spinning top, type\\n\\nbash % grep -i \\'spinning top\\' science.txt\\n\\nSome other options for grep are: -v (display those lines that do NOT match); -n (precede each matching line with the line number); and -c (print only the total count of matched lines). Try some of them and see the different results. Don\\'t forget, you can use more than one option at a time, for example, the number of lines without the words science or Science is\\n\\nbash % grep -ivc science science.txt\\n\\nwc (word count)\\n\\nA handy little utility is the wc command, short for word count. To do a word count on science.txt, type bash % wc -w science.txt To find out how many lines the file has, type bash % wc -l science.txt\\n\\nSummary\\n\\nCommand Operation cp file1 file2 copy file1 and call it file2 mv file1 file2 move or rename file1 to file2 rm file remove file rmdir directory remove directory cat file display file more file display file a page at a time head file display the first few lines of a file tail file display the last few lines of file grep \\'keyword\\' file search file for keywords wc file` count number of lines/words/characters in file')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1287 of 1477]\n",
      "Found 1286 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"UNIX Tutorials for Beginners\" type: docs toc: true weight: 1 date: \"2023-12-11-14T00:00:00\"\\n\\nmenu: unix-tutorials:\\n\\nThese tutorials are derived from the excellent tutorials from the University of Surrey, UK, with some minor modifications for our site. The originals can be found here.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1288 of 1477]\n",
      "Found 1287 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/unix_tutorial_1.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Files in Unix\" linktitle: \"Tutorial 1: Files in Unix\" draft: false highlight_style: \"github\" toc: true type: docs weight: 20 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nFiles and Processes\\n\\nEverything in Unix is either a file or a process. A process is an executing program identified by a unique PID (process identifier). A file is a collection of data. They are created by users using text editors, running compilers etc. Examples of files:\\n\\na document (report, essay etc.)\\n\\nthe text of a program written in some high-level programming language\\n\\ninstructions comprehensible directly to the machine and incomprehensible to a casual user, for example, a collection of binary digits (an executable or binary file)\\n\\na directory, containing information about its contents, which may be a mixture of other directories (subdirectories) and ordinary files\\n\\nThe Directory Structure\\n\\nIn Unix, folders are generally called directories. Directories are arranged in a hierarchical structure, like an inverted tree. The top of the hierarchy is traditionally called root.\\n\\nListing Files and Directories\\n\\nls (list)\\n\\nWhen you first log in, your current working directory is your home directory. Your home directory has the same name as your username, for example, mst3k, and it is where your personal files and subdirectories are saved. To find out what is in your home directory, type % ls This is short for \"list.\" Most Unix commands are two to four letters, sometimes with unintuitive meanings.\\n\\nThe ls command lists the contents of your current working directory. There may be no files visible in your home directory, in which case the prompt will be returned. Alternatively, there may already be some files or folders created when your account was set up.\\n\\nIn most Unix systems, ls does not report hidden files by default. Files or directories with names beginning with a dot (.) are hidden and usually contain important program configuration information. They are hidden because you should not change them unless you understand what you are doing. To list all files in your home directory including those whose names begin with a dot, type % ls -a The -a is an example of a command-line option. The options change the behavior of the command. There are online manual pages that tell you which options a particular command can take, and how each option modifies the behavior of the command.\\n\\nMaking Directories\\n\\nmkdir (make directory)\\n\\nWe will now make a subdirectory in your home directory to hold the files you will be creating and using in the course of this tutorial. To make a subdirectory called unixstuff in your current working directory type % mkdir unixstuff To see the directory you have just created, type % ls\\n\\nChanging to a Different Directory\\n\\ncd (change directory)\\n\\nThe command cd _directory_ means change the current working directory to \"directory\". The current working directory may be thought of as the directory you are in, i.e. your current position in the directory tree. To change to the directory you have just made, type % cd unixstuff\\n\\nType ls to see the directory\\'s contents (it should be empty).\\n\\nExercise 1A\\n\\nMake another directory inside the unixstuff directory called backups.\\n\\nThe Directories . and ..\\n\\nWhile still in the unixstuff directory, type % ls -a The unixstuff directory (and in all other directories) contains two special directories called (.) and (..). In Unix, (.) means the current directory, so typing % cd . means stay where you are (the unixstuff directory). This may not seem very useful at first, but using (.) as the name of the current directory will save a lot of typing, as we shall see later in the tutorial. (..) means the parent of the current directory, so typing % cd .. will take you one directory up the hierarchy. Try it now.\\n\\nNote: there is a space between cd and the dot or double dot. Also note: typing cd with no argument always returns you to your home directory. This is very useful if you are lost in the file system.\\n\\nPathnames\\n\\npwd (print working directory)\\n\\nPathnames enable you to work out where you are in relation to the whole filesystem. For example, to find out the absolute pathname of your home directory, type cd to get back to your home directory and then type bash % pwd Most of the time you should see /home/mst3k. On a multiuser central system like Rivanna, /home may be a symbolic link, i.e. an alias, for something else. To see it, type bash % pwd -P The full pathname may look something like this: /sfs/qumulo/qhome/mst3k.\\n\\nExercise 1B\\n\\nUse the commands ls, pwd and cd to explore the file system. (Remember, if you get lost, type cd with no argument to return to your home directory.)\\n\\nMore About Home Directories and Pathnames\\n\\nUnderstanding Paths\\n\\nFirst type cd to get back to your home directory, then type bash % ls unixstuff to list the contents of your unixstuff directory. Now type bash % ls backups You will get a message like this: backups: No such file or directory The reason is that \"backups\" is not in your current working directory. To use a command on a file (or directory) not in the current working directory (the directory you are currently in), you must either cd to the correct directory, or specify its full pathname. To list the contents of your backups directory, you must type bash % ls unixstuff/backups This path starts from the current location. A path may be absolute or relative. An absolute path starts from the root location. The absolute path is bash ls /home/mst3k/unixstuff/backups\\n\\nA relative path starts from the current working directory. The special symbols . and .. are often used for relative paths.\\n\\n~ (your home directory)\\n\\nHome directories can also be referenced by the tilde ~ character. It can be used to specify paths starting at your home directory. So typing bash % ls ~/unixstuff will list the contents of your unixstuff directory, no matter where you currently are in the file system. What do you think bash % ls ~ would list? What do you think % ls ~/.. would list?\\n\\nGetting Help\\n\\nOnline Manuals\\n\\nThere are online manuals which give information about most commands. The manual pages tell you which options a particular command can take, and how each option modifies the behaviour of the command. Type man command to read the manual page for a particular command. For example, to find out more about the wc (word count) command, type bash % man wc In newer Linux systems, most commands have a --help option bash % wc --help However, man sends output through a pager, whereas --help prints directly to the console.\\n\\nAnother useful command, % whatis wc gives a one-line description of the command, but omits any information about options, etc.\\n\\nSummary\\n\\nCommand Operation ls list files and directories ls -a list all files and directories mkdir make a directory cd directory change to directory cd change to home directory cd ~ change to home directory cd .. change to parent directory pwd display the path of the current directory man display the manual pages for the specified command whatis display a description of the specified command')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1289 of 1477]\n",
      "Found 1288 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/unix-tutorial/introduction.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Introduction to Unix\" type: docs toc: true weight: 10 date: 2023-12-11-14T00:11:14Z menu: unix-tutorials:\\n\\nTypographical Conventions\\n\\nIn what follows, we shall use the following typographical conventions:\\n\\nCharacters written in color-coded typewriter font are commands to be typed into the computer as they stand.\\n\\nCharacters written in standard typewriter font indicate non-specific file or directory names.\\n\\nWords inserted within square brackets, e.g. [Ctrl], indicate keys to be pressed.\\n\\nSo, for example:\\n\\n% ls anydirectory [Enter]\\n\\nmeans \"at the Unix prompt %, type ls followed by the name of some directory, then press the key marked [Enter].\" Don\\'t forget to press the [Enter] key: commands are not sent to the computer until this is done.\\n\\nNote: Unix is case-sensitive, so \"LS\" is not the same as ls. The same applies to filenames, so myfile.txt, MyFile.txt and MYFILE.TXT are three separate files. Beware if copying files to a PC, since DOS and Windows do not make this distinction.\\n\\nIntroduction to the Unix Operating System\\n\\nAn operating system is the suite of programs that make the computer work. Historically, Unix had two \"flavors,\" System V from AT&T\\'s Bell Labs, and BSD (for Berkeley Software Distribution). Today that distinction is less relevant but the dominant versions of Unix still have different roots. Linux, used for some workstations and many high-performance computing clusters, arose from System V. Mac OS was derived from a version of BSD. Android is a heavily-modified Linux.\\n\\nThe \"windowing\" (graphical) system on Linux is called X11. Modern Linux systems all provide at least one \"desktop\" environment, similar to Windows or the Mac OS desktop. However, working at the command line is still often the most efficient use of teh system, so users can benefit by learning their way around a terminal.\\n\\nA Unix operating system is made up of three parts: the kernel, the shell and the programs (applications or \"apps\").\\n\\nThe Kernel\\n\\nThe kernel of Unix is the hub of the operating system: it allocates time and memory to programs and handles the filesystem and communications in response to system calls.\\n\\nThe Shell\\n\\nThe shell acts as an interface between the user and the kernel. When a user logs in, the login program checks the username and password, and then starts another program called the shell. The shell is a command line interpreter (CLI). It interprets the commands the user types in and arranges for them to be carried out. The commands are themselves programs: when they terminate, the shell gives the user another prompt. The adept user can customise his/her own shell, and users can use different shells on the same machine. The bash shell is the default on Linux. Mac OS formerly used bash, but on newer releases the zsh shell is the default. Most of the basic commands are the same.\\n\\nAs an illustration of the way that the shell and the kernel work together, suppose a user types rm myfile to delete the file myfile. The shell searches the filesystem, first for the file containing the program rm, and directs the kernel, through system calls, to execute the program rm on myfile. When the process rm myfile has finished, the shell then returns the prompt to the user, indicating that it is ready for further commands.\\n\\nSome Features\\n\\nFilename Tab Completion: By typing part of the name of a command, filename or directory and pressing the [Tab] key, the shell will complete the rest of the name automatically. If the shell finds more than one name beginning with those letters you have typed, it will halt, prompting you to type a few more letters before pressing the [Tab] key again.\\n\\nBoth bash and zsh support tab completion, but zsh has a somewhat more sophisticated set of features.\\n\\nHistory: The shell keeps a list of the commands you have typed in. If you need to repeat a command, use the cursor keys to scroll up and down the list or typehistory for a list of previous commands.\\n\\nSeveral discussions of the differences between bash and zsh are available online, such as here. The rest of these tutorials are targeted to bash.\\n\\nPrompt\\n\\nThe prompt is a character or string of characters that indicates the shell is ready for a command. It varies by shell and system, and can be customized by more advanced users. Throughout these tutorials we will us the percent sign % as the prompt.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1290 of 1477]\n",
      "Found 1289 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/metrics.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Metrics and Training Techniques date: \"2024-06-06T00:00:00\" type: docs weight: 500 toc: true menu: deep-learning-distributed: parent: Machine Learning and Deep Learning\\n\\nMetrics are a formula for measuring the accuracy of the model. * Examples include Accuracy and MeanSquaredError. * A complete list is available at https://keras.io/api/metrics.\\n\\nEpochs and Batch Size\\n\\nAn epoch is one pass through the training loop over all of the training data.\\n\\nDuring each epoch, training generally occurs on batches of data at a time instead of on the full dataset all at once. The number of samples in each batch is called the batch size.\\n\\nSmaller batch sizes\\n\\nguarantee that a batch can fit on the GPU\\n\\nallow the model to generalize well, but increase training time\\n\\nTraining, Validation, and Test Sets\\n\\nTraining set: inputs/outputs used during NN training.\\n\\nValidation set:\\n\\nused during training to see how well the network is generalizing to unseen data, but the NN parameters are not affected by these inputs/outputs.\\n\\nInputs are sent to the NN during each epoch and the loss/metrics are calculated on this set of inputs/outputs.\\n\\nIf NN performance on the validation set is poor, this is a sign that the NN hyperparametes (e.g. number of layers, number of neurons, etc.) need to be adjusted.\\n\\nTest set: Unseen data used to measure the performance of the NN.\\n\\nCallbacks\\n\\nGenerally, we set the number of epochs for a model to train.\\n\\nHowever, if model performance on the validation set is not improving, it would be nice if training could end early to avoid overfitting.\\n\\nCallback: inputs to the model.fit function, dictate actions to take during training or inference\\n\\nEarlyStopping: callback that stops the training process once model performance on the validation set no longer improves.\\n\\nModelCheckpoint: callback that saves the best model, e.g., the model with the lowest loss on the validation set. This is probably not the model produced at the last training epoch.\\n\\nDropout Regularization\\n\\nCan be used on input or hidden layers\\n\\nDuring each training epoch a percentage of random neurons in the layer are dropped out.\\n\\nPrevents overfitting\\n\\nNeurons are only dropped out during training, not inference.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1291 of 1477]\n",
      "Found 1290 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/deep-learning.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Deep Learning date: \"2024-06-06T00:00:00\" type: docs weight: 350 toc: true menu: deep-learning-distributed: parent: Machine Learning and Deep Learning\\n\\nDeep learning is a branch of artificial intelligence, where programs use multiple layers of neural networks to transform a set of input values to output values.\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dnn_overview.png width=65% height=65% >}}\\n\\nNodes\\n\\nEach \"node\" in the neural network performs a set of computations.\\n\\n{{< figure src=/notes/deep-learning-distributed/img/node_weights.png width=50% height=50% >}}\\n\\nThe weights, $_$, and the bias, $b$, are not known. Each node will have its own set of unknown values. During training, the best set of weights are determined that will generate a value close to $y$ for the collection of inputs $_$.\\n\\nNetwork of Neurons\\n\\n{{< figure src=/notes/deep-learning-distributed/img/multi_perceptron.png caption=\"Multi-layer Perceptron\" width=55% height=55% >}}\\n\\nDifferent computations with different weights can be performed to produce different outputs.\\n\\nThis is called a feedforward network  all values progress from the input to the output.\\n\\nA neural network has a single hidden layer\\n\\nA network with two or more hidden layers is called a deep neural network.\\n\\nDeep Learning Neural Network\\n\\n{{< figure src=/notes/deep-learning-distributed/img/neural_network.png caption=\"Multilayer Perceptron/ Fully Connected NN; Image borrowed from: http://www.kdnuggets.com/2017/05/deep-learning-big-deal.html\" width=75% height=75% >}}\\n\\nDL Algorithm\\n\\nDuring the training or fitting process, the Deep Learning algorithm is fed a set of measurements/features and the expected outcome (e.g., a label or classification).\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dl_algorithm.png width=60% height=60% >}}\\n\\nThe algorithm determines the best weights and biases for the data.\\n\\nHow Does the Machine Learn?\\n\\nStart with a random guess for the weights and biases.\\n\\nThe output values or predicted values of the network can be compared with the expected results/categories/labels.\\n\\nAnother function, called a loss or cost function can be used to determine the overall error of the model.\\n\\nThat error can be used to work backwards through the network and tweak the weights/biases.\\n\\nThis step is called backward propagation.\\n\\nOverview of the Learning Process\\n\\n{{< video src=\"/notes/deep-learning-distributed/video/learning_process.mp4\" controls=\"yes\" >}}\\n\\nDeep Neural Network\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dnn_ex.gif caption=\"An example of a Deep Neural Network (DNN)\" width=70% height=70% >}}\\n\\nDNN Examples\\n\\nFeed-Forward NN\\n\\nConsist of an input layer, an output layer and many hidden layers that are fully connected, and can be used to build speech-recognition, image-recognition, and machine-translation software.\\n\\nRecurrent NN\\n\\nRNNs are commonly used for image captioning, time-series analysis, natural-language processing, machine translation, etc.\\n\\nConvolution NN\\n\\nConsist of multiple layers and are mainly used for image processing and object detection.\\n\\nAnd many more such as RBFNs, GANs, Modular NN, etc.\\n\\nActivation Function\\n\\n{{< figure src=/notes/deep-learning-distributed/img/activation_function.png caption=\"\" width=40% height=40% >}} * The activation function introduces nonlinearity into the model. * Can choose different activation functions for each layer. * Examples include ReLU, Sigmoid(binary classification), and Softmax(multiclass classification). * A complete list is available at * https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity and https://pytorch.org/docs/stable/nn.html#non-linear-activations-other\\n\\nLoss Function\\n\\n{{< figure src=/notes/deep-learning-distributed/img/loss_function.png caption=\"\" width=50% height=50% >}} * The loss function tells us how good our model is at relating the input to the output. * A function that will be optimized to improve the performance of the model. * The cost value is the difference between the neural nets predicted output and the actual output from a set of labeled training data. * The choice of loss function is based on the task. * Examples include * Classification: BCELoss (Binary Cross Entropy) and Cross Entropy Loss. * Regression: Mean Squared Error (MSE) * A complete list is available at https://pytorch.org/docs/stable/nn.html#loss-functions and https://www.tensorflow.org/api_docs/python/tf/keras/losses\\n\\nOptimizer Function\\n\\nThe optimizer function is a function for tweaking/adjusting the parameters during training so that the best weights and biases are efficiently reached.\\n\\nExamples include SGD, Adam, and RMSprop.\\n\\nA complete list is available at https://pytorch.org/docs/stable/optim.html?highlight=optimizer#torch.optim.Optimizer and https://www.tensorflow.org/api_docs/python/tf/keras/optimizers')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1292 of 1477]\n",
      "Found 1291 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/machine-learning.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Machine Learning and Deep Learning date: \"2024-06-06T00:00:00\" type: docs weight: 250 toc: true menu: deep-learning-distributed:\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dl_ml_ai.png caption=\"Image borrowed from: https://www.edureka.co/blog/ai-vs-machine-learning-vs-deep-learning/\" width=75% height=75% >}}\\n\\nMachine Learning Overview\\n\\nMachine learning (ML) is a branch of artificial intelligence where computers learn from data and adapt the computational models to enhance performance. It is a method of analysis that allows computers to reveal information within data. * The learning is not the type of learning that you and I do. * It is a systematic approach to finding an appropriate data transformation from inputs to output.\\n\\nWhy ML? * Computers can sort through data faster than humans can. * Computers can identify patterns quickly and use these patterns for predictions or classifications. * Machine learning can handle noisy data  it doesnt find a perfect answer, but rather a really good answer.\\n\\nApplications of ML\\n\\nRegression techniques\\n\\nDetermines a mathematical model for the relationship among features or attributes so that an outcome can be predicted.\\n\\nResults can be any value within a possible range (e.g., what will the average Earth temperature be in 2050?)\\n\\nClassification problem\\n\\nIdentifies a combination of attributes that best fits a class or category so that an object can be classified.\\n\\nResults can be from a list of known possibilities (e.g., is the tumor benign or malignant?)\\n\\nNote: Examples included in this tutorial are all of classification type problems.\\n\\nTypes of ML\\n\\nSupervised Learning:\\n\\nA data set exists where the samples can be categorized into two or more classifications.\\n\\nThe computer uses the data set to learn how to predict the classification of an unknown sample.\\n\\nExamples include Decision Trees and Deep Learning\\n\\nUnsupervised Learning:\\n\\nThe collected data has no known classification or pattern.\\n\\nThe computer must identify the groups or hidden structures within the data.\\n\\nExamples include Dendograms, K-means clustering, Self-organizing Maps\\n\\nReinforcement Learning:\\n\\nComputer learns from positive or negative feedback\\n\\nExample includes Swarm intelligence\\n\\nNote: Examples included in this tutorial are all instances of supervised learning.\\n\\nData for ML\\n\\nFor many Machine Learning algorithms, the data is expected to be in a table format, where:\\n\\neach row represents an object, and\\n\\neach column has the measurements for a specific attribute or feature of the object\\n\\nFor supervised learning, the classifications of the objects must be known.\\n\\nThe data with known classifications are divided into a training set and a testing set.\\n\\nThe data is then used to develop a model.\\n\\nThe training data are submitted to an algorithm that will fit a model to the data.\\n\\nThe test data are submitted to the model to produce predicted classifications and determine the accuracy of the model.\\n\\nFinally, the model can be used to predict classifications for unknown data.\\n\\nML Algorithm\\n\\nThe algorithm determines the best mathematical model for the code. However, you still need to provide a framework for the algorithm. The framework provides the algorithm with tools for performing the learning.\\n\\n{{< figure src=/notes/deep-learning-distributed/img/ml_overview.png caption=\"\" width=75% height=75% >}}\\n\\nDeep Learning vs Machine Learning\\n\\nDeep Learning is a subset of Machine Learning that differentiates itself from ML algorithms based on the methods (neural networks) it uses to solve problems.\\n\\nAny deep learning algorithm would reiterate and perform a task repeatedly, improving a bit every time, in order to improve the outcome.\\n\\nA deep learning program builds the feature set by itself without supervision and domain expertise.\\n\\nUnsupervised learning is not only faster, but it is usually more accurate.\\n\\nUnsupervised learning needs access to immense amounts of data and compute power and takes much longer to train, but it is much faster to run tests.\\n\\nML algorithms have superior interpretability and are favorable for small amounts of data.\\n\\nML works only with sets of structured and semi-structured data, while deep learning works with both structured and unstructured data\\n\\nLimitations and Challenges\\n\\nDL models learn through observations. Outcome is not generalizable if data was small or if its scope was limited.\\n\\nIf a model trains on data that contains biases, the model will reproduce those biases in its predictions.\\n\\nIf the learning rate is too high, then the model will converge too quickly, producing a less-than-optimal solution. If the rate is too low, then the process may get stuck, and it will be even harder to reach a solution.\\n\\nThere are a large amount of data and parameters.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1293 of 1477]\n",
      "Found 1292 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/pytorch.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: PyTorch date: \"2024-06-06T00:00:00\" type: docs weight: 2850 toc: true menu: deep-learning-distributed: parent: PyTorch\\n\\nPytorch is another widely-used deep-learning platform known for its flexibility and speed. It is a popular library used by academics and researchers.\\n\\nIt is a software library, developed by Facebook and maintained by Mega AI.\\n\\nTorch is an open-source project for Deep Learning written in C and generally used via the Lua interface. Torch is no longer actively developed but libraries are used in Pytorch.\\n\\nBecause PyTorch and Tensorflow use some common underlying codes, many of the required functions (e.g., activation, loss, optimizer) will be the same.\\n\\nInstallation\\n\\nConda bash conda create --name torch-env pytorch torchvision pytorch-cuda=12.1 -c pytorch c nvidia\\n\\nContainer (NGC)\\n\\nhttps://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch\\n\\nBuilding from source\\n\\nhttps://github.com/pytorch/pytorch#from-source\\n\\nPerformance and Utilization:\\n\\nUse DataLoader and try increasing the value of cpus-per-task in tandem with num_workers to prepare the data and keep the GPU busy. This was shown to dramatically increase the GPU utilization.\\n\\nWriting a custom dataloader: https://www.youtube.com/watch?v=PXOzkkB5eH0\\n\\nExternal datal loading libraries: https://github.com/libffcv/ffcv, https://developer.nvidia.com/dali\\n\\nMixed precision training requires either the V100 or A100 GPU and is included in PyTorch as torch.cuda.amp. PyTorch will perform FP32 matrix multiplications using TF32 by default.\\n\\nAutomatic Mixed Precision: https://pytorch.org/docs/stable/amp.html\\n\\ngpustat, Line_profiler, nvprof or nsys (if on GPU)\\n\\nFor example, ./nvprof python mnist_classify.py --epochs=3\\n\\nTensorBoard is a useful tool for tracking the training process of a PyTorch model. Available through conda and container version.\\n\\nPerformance Tuning * Pytorch Performance Tuning Guide * Performance Tuning Guide Slides\\n\\nTorch Tensors\\n\\nA tensor is a multidimensional array (like a numpy ndarray) which can be used on GPUs\\n\\n```python import torch\\n\\nx = torch.rand(5,3, dtype=torch.long, device=\\'cuda\\') # if not specified, uses cpu y = torch.zeros(5,3) z = torch.add(x+y) # or z=x+y w = z.numpy() # convert to numpy array, same memory location t = torch.from_numpy(w) # numpy to torch tensor (on cpu) ```\\n\\nCUDA tensors\\n\\nTensors can be moved onto any device using the .to method.\\n\\npython if torch.cuda.is_available(): device = torch.device(\"cuda\") y = torch.rand(3,5, device=device) x = torch.rand(3,5).to(device) z = x + y print(z) print(z.to(\"cpu\", torch.double)) # ``.to`` can also change dtype together!\\n\\nCoding a Pytorch Model: General Steps\\n\\n1. Import the torch package 2. Read in the data 3. Preprocess the data 3a. Scale the data 3b. Split the data 3c. Convert data to tensors 3d. Load the tensors 4. Design the Network Model 5. Define the Learning Process 6. Train the model 7. Apply the model to the test data 8. Display the results\\n\\nMake sure that you can run the PyTorch code:\\n\\nPT_CNN_SingleGPU.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1294 of 1477]\n",
      "Found 1293 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/cnn.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Convolutional Neural Networks date: \"2024-06-06T00:00:00\" type: docs weight: 600 toc: true menu: deep-learning-distributed: parent: Machine Learning and Deep Learning\\n\\nWhat are Convolutional Neural Networks?\\n\\nOriginally, convolutional neural networks (CNNs) were a technique for analyzing images.\\n\\nApplications have expanded to include analysis of text, video, and audio.\\n\\nCNNs apply multiple neural networks to subsets of a whole image in order to identify parts of the image.\\n\\nThe idea behind CNN\\n\\n{{< figure src=/notes/deep-learning-distributed/img/cnn_idea.jpg width=55% height=55% >}} * Recall the old joke about the blind-folded scientists trying to identify an elephant. * A CNN works in a similar way. It breaks an image down into smaller parts and tests whether these parts match known parts. * It also needs to check if specific parts are within certain proximities. For example, the tusks are near the trunk and not near the tail.\\n\\nIs the image on the left most like an X or an O? {{< figure src=/notes/deep-learning-distributed/img/most_alike.png caption=\"Images borrowed from http://brohrer.github.io/how_convolutional_neural_networks_work.html\" width=40% height=40% >}}\\n\\nWhat features are in common?\\n\\n{{< figure src=/notes/deep-learning-distributed/img/features_in_common.png width=65% height=65% caption=\"\" >}}\\n\\nBuilding blocks of CNN\\n\\nCNN performs a combination of layers * Convolution Layer * This layer compares a feature with all subsets of the image * It creates a map showing where the comparable features occur * Rectified Linear Units (ReLU) Layer * This layer goes through the features maps and replaces negative values with $0$ * Pooling Layer * This layer reduces the size of the rectified feature maps by taking the maximum value of a subset\\n\\nThe CNN ends with a final layer * Classification (Fully-connected layer) layer * This combines the specific features to determine the classification of the image\\n\\n{{< figure src=/notes/deep-learning-distributed/img/cnn_steps.png caption=\"Convolution  Rectified Linear  Pooling\" width=70% height=70% >}}\\n\\nThese layers can be repeated multiple times. The final layer converts the final feature map to the classification.\\n\\n{{< figure src=/notes/deep-learning-distributed/img/final_layer.png width=60% height=60% >}}\\n\\nExample: MNIST Data\\n\\n{{< figure src=/notes/deep-learning-distributed/img/mnist.jpg caption=\"Image borrowed from Getting Started with TensorFlow by Giancarlo Zaccone\" width=40% height=40% >}}\\n\\nThe MNIST data set is a collection of hand-written digits (e.g., 0-9).\\n\\nEach digit is captured as an image with 28x28 pixels.\\n\\nThe data set is already partitioned into a training set (60,000 images) and a test set (10,000 images).\\n\\nThe tensorflow packages have tools for reading in the MNIST datasets.\\n\\nMore details on the data are available at http://yann.lecun.com/exdb/mnist/\\n\\nWhy Use GPUs?\\n\\n{{< figure src=/notes/deep-learning-distributed/img/params_overtime.png width=60% height=60% >}}\\n\\nOver time, bigger models have been developed to handle more complex tasks, and consequently, to handle more computations. The training process involves hundreds of thousands of computations, and we need a form of parallelization to speed up the process.\\n\\nHPC systems can help meet this demand through specialized hardware, like GPUs which can provide the needed parallelization, and other hardware.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1295 of 1477]\n",
      "Found 1294 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/effective-use.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Effective Use of HPC for Deep Learning date: \"2024-06-06T00:00:00\" type: docs weight: 4550 menu: deep-learning-distributed: name: Effective Use of HPC for Deep Learning\\n\\nOptimize single-node/single-GPU performance?\\n\\nUse performance analysis tools\\n\\nTune and optimize data pipeline\\n\\nMake effective use of the hardware (e.g. mixed precision)\\n\\nBefore running on multiple nodes, make sure the job can scale well to 8 GPUs on a single node. Never do one GPU per node for multinode jobs.\\n\\nUse multiple CPU cores for data loading.\\n\\nFor hyperparameter tuning consider using a job array. This will allow you to run multiple jobs with one sbatch command.\\n\\nYou will likely want the code loading data to look like this: python train_dataset = datasets[\\'train\\'].map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE) .cache() .shuffle(SHUFFLE_SIZE) .batch(BATCH_SIZE) .prefetch(tf.data.AUTOTUNE)\\n\\nQuestions or Need more help?\\n\\nOffice Hours via Zoom:\\n\\nTuesdays: 3 pm - 5 pm\\n\\nThursdays: 10 am - noon\\n\\nZoom Links are available at https://www.rc.virginia.edu/support/#office-hours * Website: https://rc.virginia.edu')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1296 of 1477]\n",
      "Found 1295 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Distributed Deep Learning date: \"2024-06-06T00:00:00\" authors: [uvarc,as,jmh] type: docs weight: 1\\n\\nauthors: [as,jmh]\\n\\nJacalyn Huband Senior Computational ScientistE: jmh5d@virginia.edu\\n\\nAhmad Sheikhzada Computational Scientist jus2yw@virginia.edu\\n\\nmenu: deep-learning-distributed: parent: Distributed Deep Learning\\n\\nDeep Learning (DL) is a powerful tool transforming scientific workflows. Because DL training is computationally intensive, it is well suited to HPC systems. Effective use of UVA HPC resources can greatly accelerate your DL workflows. In this tutorial, we will discuss: * When is it appropriate to use a GPU? * How to optimize single-GPU code? * How to convert single-GPU code to Multi-GPU code in different frameworks and run it on UVA HPC?\\n\\nThe following outline presents topics that will be discussed as well as when code will be provided: * Overview of Deep Learning * Example: Convolutional Neural Network * Introduction to GPUs and GPU Computing * Tensorflow/Keras * Single-GPU Code Example * PyTorch * Single-GPU Code Example * Distributed Training * TF Multi-GPU Code Example * PT Multi-GPU Code Example * PT Lightning Multi-GPU Code Example * Effective Use/Remarks\\n\\nPrior experience with the Python programming language and some familiarity with machine learning concepts are helpful for this tutorial.\\n\\nIf you have not already done so, please download the example code here:\\n\\n{{< file-download file=\"/notes/deep-learning-distributed/code/distributed_dl.zip\" text=\"distributed_dl.zip\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1297 of 1477]\n",
      "Found 1296 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPU Overview date: \"2024-06-06T00:00:00\" type: docs weight: 750 toc: true menu: deep-learning-distributed: parent: GPU Overview\\n\\nGraphics Processing Units (GPUs), originally developed for accelerating graphics rendering, can dramatically speed up any simple but highly parallel computational processes. GPGPU is a shorthand often used for \"General-Purpose Computing on Graphics Processing Devices.\"\\n\\nCPU versus GPU\\n\\n{{< table >}} | CPU | GPU | | ----------- | ----------- | | Several Cores (100-1) | Many Cores (103-4) | | Generic Workload (Complex & Serial Processing) | Specific Workload (Simple & Highly Parallel) | | Up to 1.5 TB / node on UVA HPC | Up to 80 GB /device on UVA HPC | {{< /table >}}\\n\\nIntegrated GPU vs Discrete GPUs:\\n\\nIntegrated GPUs are used mostly for graphics rendering and gaming\\n\\nDedicated GPUs are designed for intensive computations\\n\\n{{< figure src=/notes/deep-learning-distributed/img/cpu_gpu.png caption=\"CPU Optimized for Serial Tasks and GPU Accelerator optimized for Parallel Tasks; Credit: NVIDIA\" width=50% height=50% >}}\\n\\nLike a CPU, a GPU has a hierarchical structure with respect to both the execution units and memory. A warp is a unit of 32 threads. NVIDIA GPUs impose a limit of 1024 threads per block. Some integral number of warps are grouped into a streaming multiprocessor (SM) and there are tens of SMs per GPU. Each thread has its own memory and there is limited shared memory between a block of threads. Finally, there is also the global memory which is accessible to each grid or collection of blocks.\\n\\nVendors and Types\\n\\nNVIDIA, AMD, Intel\\n\\nDatacenter : K80, P100, V100, A100, H100 (NVIDIA); MI300A, MI300X (AMD)\\n\\nWorkstations: A6000, Quadro (NVIDIA)\\n\\nGaming: GeForce RTX 20xx, 30xx, 40xx (NVIDA), Radeon (AMD)\\n\\nLaptops and desktops: GeForce (NVIDIA), Radeon (AMD), Iris (Intel)\\n\\nProgramming GPUs\\n\\nSeveral libraries and programming models have been developed to program GPUs.\\n\\nCUDA\\n\\nCUDA is a parallel computation platform, developed by NVIDIA, for general-purpose programming on NVIDIA hardware.\\n\\nHIP\\n\\nHIP is a programming interface from AMD that allows developers to target either NVIDIA or AMD hardware.\\n\\nOpenCL\\n\\nOpenCL is a more general parallel computing platform, developed by Apple. It allows software to access CPUs, GPUs, FPGAs, and other devices.\\n\\nSYCL\\n\\nSYCL started as an outgrowth of OpenCL but is now independent of it.\\n\\nKokkos\\n\\nKokkos is another programming model that attempts to be device-independent. It can target multicore programming (OpenMP), CUDA, HIP, and SYCL.\\n\\nMost of these programming paradigms can be used from Python, but nearly all machine learning/deep learning packages are based on CUDA and will only work with NVIDIA GPUs.\\n\\nGPU Computing\\n\\nFor certain workloads like image processing, training artificial neural networks and solving differential equations, a GPU-enabled code can vastly outperform a CPU code. Algorithms that require lots of logic such as \"if\" statements tend to perform better on the CPU.\\n\\nSteps required to execute a function (kernel) on a GPU:\\n\\ncopy the input data from the CPU memory to the GPU memory\\n\\nload and execute the GPU kernel on the GPU\\n\\ncopy the results from the GPU memory to CPU memory\\n\\nDepending on the DL framework, some of these steps may be automatically done.\\n\\nRecently, manufacturers have incorporated specialized units on the GPU called Tensor Cores (NVIDIA) or Matrix Cores (AMD) to perform certain operations in less than single precision.\\n\\nNote: This is particularly beneficial to researchers training artificial neural networks or, more generally, cases where matrix-matrix multiplications and related operations dominate the computation time. Modern GPUs, with or without these specialized units, can be used in conjunction with a CPU to accelerate scientific codes. https://github.com/PrincetonUniversity/gpu_programming_intro/ GPU accelerated libraries. https://developer.nvidia.com/gpu-accelerated-libraries As with the CPU, a GPU can perform calculations in single precision (32-bit) faster than in double precision (64-bit)\\n\\nComputational Graphs\\n\\nComputational graphs help to break down computations. For example, the graph for $y=(x1+x2) \\\\times (x2 - 5)$ is\\n\\n{{< figure src=/notes/deep-learning-distributed/img/computational_graph.png caption=\"The beauty of computational graphs is that they show where computations can be done in parallel.\" width=50% height=50% >}}\\n\\nWhy Use GPUs in DL?\\n\\nData flows in neural networks can be efficiently implemented by computational graphs . This is the case with popular frameworks like TensorFlow and PyTorch.\\n\\nWith deep learning models, you can have hundreds of thousands of computational graphs.\\n\\nA GPU can perform a thousand or more of the computational graphs simultaneously. This will speed up your program significantly.\\n\\nNew GPUs have been developed and optimized specifically for deep learning.\\n\\nAll the major deep learning Python libraries (Tensorflow, PyTorch, Keras, Caffe,...) support the use of GPUs and allow users to distribute their code over multiple GPUs.\\n\\nGPUs in DL\\n\\nScikit-learn does not support GPU processing.\\n\\nDeep learning acceleration is furthered with Tensor Cores in NVIDIA GPUs.\\n\\nTensor Cores accelerate large matrix operations by performing mixed-precision computing.\\n\\nTensor Cores accelerate math and reduce the memory traffic and consumption.\\n\\nIf you\\'re not using a neural network as your machine learning model you may find that a GPU doesn\\'t improve the computation time.\\n\\nIf you are using a neural network but it is very small then a GPU will not be any faster than a CPU - in fact, it might even be slower.\\n\\nGPU Profiling\\n\\njupyterlab-nvdashboard (GPU Dashboards)\\n\\nnvidia-smi\\n\\nonly a measure of the fraction of the time that a GPU kernel is running on the GPU. Nothing about how many CUDA cores are being used or how efficiently the GPU kernels have been written.\\n\\nLine_profiler for any python code (PyTorch and TensorFlow).\\n\\nNsight Systems(nsys) for profiling GPU codes. It produces a timeline and can handle MPI but produces a different set of profiling data for each MPI process.\\n\\nNsight Compute(ncu) to look closely at the behavior of specific GPU kernels.\\n\\nNsys and ncu are more accurate measures of GPU utilization.\\n\\nAdditional information can be found: https://researchcomputing.princeton.edu/support/knowledge-base/gpu-computing\\n\\nFor codes used by large communities, one can generally associate GPU utilization with overall GPU efficiency.\\n\\nGPU Utilization\\n\\nIf there is zero GPU utilization...\\n\\nIs code GPU enabled?\\n\\nIs software environment properly configured?\\n\\nDoes code spend a long time transferring data between CPU and GPU?(e.g. during interactive jobs)\\n\\nIf there is low GPU utilization...\\n\\nThere may be misconfigured application scripts.\\n\\nYou may be using high end GPU for codes that do not have enough work to keep the GPU busy. Using an A100 GPU for a job that could be handled sufficiently by a P100 GPU might lead to underutilization.\\n\\nYou may be training deep learning models while only using a single CPU core. Frameworks like PyTorch and TensorFlow often show significant performance benefits when multiple CPU cores are utilized for data loading.\\n\\nYou may be using too many GPUs for a job. You can find the optimal number of GPUs and CPU-cores by performing a scaling analysis.\\n\\nYou may be running a code written to work for a single GPU on multiple GPUs.\\n\\nWriting output files to slow storage systems instead of scratch or GPFS, can also reduce GPU utilization.\\n\\nMake sure the software environment is configured properly. For hyperparameter tuning, consider using a job array. This will allow you to run multiple jobs with one sbatch command. Each job within the array trains the network using a different set of parameters.\\n\\nUVA-NVIDIA DGX BasePOD\\n\\n10 DGX A100 nodes\\n\\n8 NVIDIA A100 GPUs.\\n\\n80 GB GPU memory options.\\n\\nDual AMD EPYC:tm:; nodes: Series 7742 CPUs, 128 total cores, 2.25 GHz (base), 3.4 GHz (max boost).\\n\\n2 TB of system memory.\\n\\nTwo 1.92 TB M.2 NVMe drives for DGX OS, eight 3.84 TB U.2 NVMe drives forstorage/cache.\\n\\nAdvanced Features:\\n\\nNVLink for fast multi-GPU communication\\n\\nGPUDirect RDMA Peer Memory for fast multi-node multi-GPU communication\\n\\nGPUDirect Storage with 200 TB IBM ESS3200 (NVMe) SpectrumScale storage array\\n\\nIdeal Scenarios:\\n\\nJob needs multiple GPUs on a single node or multi node\\n\\nJob (single or multi-GPU) is I/O intensive\\n\\nJob (single or multi-GPU) requires more than 40GB of GPU memory\\n\\nAlways try to use the CUDA Toolkit 11.x and cuDNN 8.x since they are needed to take full advantage of the A100.\\n\\nGPU Access on UVA HPC\\n\\nGeneral\\n\\nGPUs available in both interactive and gpu partition, GPU type and number can be specified.\\n\\nPOD nodes\\n\\nPOD nodes are contained in the gpu partition with a specific Slurm constraint.\\n\\nSlurm script: ```bash\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:a100:X # X number of GPUs\\n\\nSBATCH -C gpupod\\n\\nOpen OnDemandnohighlight --constraint=gpupod ```')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1298 of 1477]\n",
      "Found 1297 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/tensorflow.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: TensorFlow date: \"2024-06-06T00:00:00\" type: docs weight: 1100 toc: true menu: deep-learning-distributed:\\n\\nTensorflow is a software library, developed by the Google Brain Team.\\n\\nTensorFlow already has the code to assign the data to the GPUs and do the heavy computational work; we simply have to give it the specifics for our data and model.\\n\\nTensorflow is an example of deep learning (a neural network that has many layers).\\n\\nKeras is an open-source deep-learning library in Python that provides an easy-to-use interface to TensorFlow.\\n\\ntf.keras is the Keras API integrated into TensorFlow 2\\n\\nMore information can be found: https://www.tensorflow.org/guide/mixed_precision\\n\\nTeminology: Tensors\\n\\nTensor: A multi-dimensional array\\n\\nExample: A sequence of images can be represented as a 4-D array: [image_num, row, col, color_channel]\\n\\nTensors can be used on a GPU\\n\\n{{< figure src=/notes/deep-learning-distributed/img/tensors.png caption=\"\" width=60% height=60% >}}\\n\\nInstall Tensorflow\\n\\nConda\\n\\nconda create -n tf2-gpu tensorflow-gpu -c conda-forge\\n\\nContainer (available as module and OOD)\\n\\napptainer exec --nv $CONTAINERDIR/tensorflow-2.13.0.sif python mycode.py\\n\\nBuild from source\\n\\nhttps://www.tensorflow.org/install/source\\n\\nTensorFlow will run GPU-enabled operations on the GPU by default. However, more than one GPU requires appropriate changes within the TensorFlow script.\\n\\nPerformance and Profiling\\n\\nMultithreading should give a substantial speed-up for large input pipelines via tf.data where the ETL takes place on the (multicore) CPU only. Use multiple CPU-cores to prepare the data and keep the GPU busy. python train_dataset = datasets[\\'train\\'].map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\\\\ .cache()\\\\ .shuffle(SHUFFLE_SIZE)\\\\ .batch(BATCH_SIZE)\\\\ .prefetch(tf.data.AUTOTUNE)\\n\\nTensorBoard:\\n\\nIt can be used to view your graph, monitor training progress and more. Included in a Conda installation of TensorFlow.\\n\\nInstructions available on the RC site: Tensorflow and UVA HPC\\n\\nProfiling\\n\\nline_profiler\\n\\nAn excellent starting point for profiling any Python script is line_profiler. This will provide high-level profiling data such as the amount of time spent on each line of your script.\\n\\nTensorflow Profiler and debugger embedded within tensorboard (GPU required).\\n\\nAdditional information can be found: https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras\\n\\nNsys and ncu\\n\\nTensorRT is an SDK for high-performance deep learning inference. You can either use the container from NVIDIA with Singularity or build from source.\\n\\nA Guide to Tensorflow Performance Optimization\\n\\nCoding a Tensorflow Model: General Steps\\n\\nImport Modules\\n\\nRead in the data\\n\\nDivide the data into a training set and a test set.\\n\\nPreprocess the data\\n\\nDesign the Network Model\\n\\nTrain the model: Compile, Checkpointing, EarlyStopping and Fitting\\n\\nApply the model to the test data and display the results\\n\\nLoading a checkpointed model\\n\\nMake sure that you can run the CNN code: * TF_CNN_SingleGPU.ipynb')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1299 of 1477]\n",
      "Found 1298 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-distributed/distributed-training.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Distributed Training date: \"2024-06-06T00:00:00\" type: docs weight: 3750 toc: true menu: deep-learning-distributed: parent: Distributed Training\\n\\nMost models can be trained in a reasonable amount of time using a single GPU. Minimizing the \"time to finish\" is minimizing both the time the job spends running on the compute node and the time spend waiting in the queue.\\n\\nDistributed training is imperative for larger and more complex models/datasets. Data parallelism is a relatively simple and effective way to accelerate training.\\n\\nHowever, if you are effectively using the GPU then you may consider running on multiple GPUs. For more, look into how to conduct a scaling analysis.\\n\\nData vs Model Parallelism\\n\\nThere are two ways to distribution computation across multiple devices.\\n\\n{{< rawhtml >}}\\n\\n{{< figure src=/notes/deep-learning-distributed/img/data_parallelism.png width=60% height=60% >}} {{< figure src=/notes/deep-learning-distributed/img/model_parallelism.png width=60% height=60% >}}\\n\\n{{< /rawhtml >}}\\n\\nData parallelism: A single model gets replicated on multiple devices. Each processes different batches of data, then they merge their results. * The single-program, multiple data (SPMD) paradigm is used. That is, the model is copied to each of the GPUs. The input data is divided between the GPUs evenly. After the gradients have been computed they are averaged across all the GPUs. This is done in a way that all replicas have numerically identical values for the average gradients. The weights are then updated and once again they are identical by construction. The process then repeats with new mini-batches sent to the GPUs. * For additional information: https://www.telesens.co/wp-content/uploads/2019/04/img_5ca570946ee1c.png * There exists many variants, and they differ in how the different model replicas merge results, in whether they stay in sync at every batch or whether they are more loosely coupled, etc.\\n\\nModel parallelism: Different parts of a single model run on different devices, processing a single batch of data together. * This works best with models that have a naturally-parallel architecture, such as models that feature multiple branches.\\n\\n{{< table >}} | Data Parallelism | Model Parallelism | | ----------- | ----------- | |Allows to speed up training | All workers train on different data | |All workers have the same copy of the model | Neural network gradients (weight changes) are exchanged| |Allows for a bigger model | All workers train on the same data| | Parts of the model are distributed across GPUs | Neural network activations are exchanged | {{< /table >}}\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dp_pcie.png caption=\"Datal loading and gradient averaging share communication resources  congestion\" width=60% height=60% >}}\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dp_nvlink.png caption= \"Datal loading on PCIe, gradient averaging on NVLINK  no congestion\" width=60% height=60% >}}\\n\\nTensorflow Example: Synchronous Data Parallelism\\n\\nThis guide focuses on data parallelism, in particular synchronous data parallelism, where the different replicas of the model stay in sync after each batch they process. Synchronicity keeps the model convergence behavior identical to what you would see for single-device training.\\n\\nIn TensorFlow we use the tf.distribute API to train Keras models on multiple GPUs. There are two setups:\\n\\nSingle host, multi-device training. This is the most common setup for researchers and small-scale industry workflows.\\n\\nMulti-worker distributed training. This is a setup for large-scale industry workflows, e.g. training high-resolution image classification models on tens of millions of images using 20-100 GPUs.\\n\\nSingle Host, Multi GPUs\\n\\nEach device will run a copy of your model (called a replica ).\\n\\nAt each step of training: * The current batch of data (called global batch ) is split into e.g., 4 different sub-batches (called local batches ). * Each of the 4 replicas independently processes a local batch; forward pass, backward pass, outputting the gradient of the weights. * The weight updates from local gradients are merged across the 4 replicas.\\n\\nIn practice, the process of synchronously updating the weights of the model replicas is handled at the level of each individual weight variable. This is done through a mirrored variable object.\\n\\nCoding: General Steps\\n\\nDesign the Model\\n\\nRead in the data (recommended to use tf.data)\\n\\nCreate a Mirrored Strategy\\n\\nOpen a Strategy Scope\\n\\nTrain the Model\\n\\nEvaluate the Model\\n\\nDisplay the results\\n\\nActivity: Distributed TensorFlow Program\\n\\nMake sure that you can run the TF code: * TF_CNN_MultiGPU.ipynb\\n\\nPytorch Example: Data Parallel\\n\\nhttps://pytorch.org/tutorials/intermediate/ddp_tutorial.html\\n\\nMulti-GPU, Distributed Data Parallel (DDP)\\n\\n{{< figure src=/notes/deep-learning-distributed/img/dpp.png caption=\"Source: https://www.telesens.co/wp-content/uploads/2019/04/img_5ca570946ee1c.png\" width=75% height=75% >}}\\n\\nDo not use DataParallel (increased overhead, runs on threads) in PyTorch for anything since it gives poor performance relative to DistributedDataParallel (runs on processes).\\n\\nPytorch\\'s Model Parallel Best Practices: https://pytorch.org/tutorials/intermediate/model_parallel_tutorial.html\\n\\nDistributed Data Parallel video in pytorch: https://www.youtube.com/watch?v=TibQO_xv1zc\\n\\nDDP is only applied when training, no effect during validation or evaluation\\n\\nDataParallel is very easy to use and handles * everything for you, but not optimized DDP involves more coding and adjustments, but more code optimized and hence significant speedup, more salable to multiple machines and flexibility.\\n\\nCoding: General Steps\\n\\nDesign the Model\\n\\nSet up the Ranks\\n\\nRead in the Data\\n\\nTrain the Model\\n\\nEvaluate the Model\\n\\nActivity: Distributed PT Program\\n\\nMake sure that you can run the PT code:\\n\\nPT_CNN_MultiGPU.py\\n\\nPT_CNN_MultiGPU.slurm\\n\\nPytorch Lightning Example: Data parallel\\n\\nhttps://pytorch.org/tutorials/intermediate/ddp_tutorial.html\\n\\nPyTorch Lightning\\n\\nPyTorch Lightning wraps PyTorch to provide easy, distributed training done in your choice of numerical precision.\\n\\nTo convert from PT to PTL: * Restructure the code by moving the network definition, optimizer and other code to a subclass of L.LightningModule. * Remove .cuda() and .to() calls since Lightning code is hardware agnostic\\n\\nOnce these changes have been made one can simply choose how many nodes or GPUs to use and Lightning will take care of the rest. One can also use different numerical precisions (fp16, bf16). There is tensorboard support and model-parallel training.\\n\\nActivity: Distributed PT-Lightning Program\\n\\nMake sure that you can run the PyTorch-Lightning code:\\n\\nPTL_multiGPU.slurm\\n\\nPTL_multiGPU.py')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1300 of 1477]\n",
      "Found 1299 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/slurm-from-cli/section2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: II - Working with Slurm Scripts date: 2023-12-11-14T00:11:14Z type: docs toc : true weight: 20 menu: slurm-from-cli:\\n\\nWriting Batch Scripts\\n\\nBatch scripts should be written on a cluster login node. Please do not use your local computer to write them, as they may not work. You must also use a text editor and not a word-processing program.\\n\\nSeveral options are available to prepare batch scripts.\\n\\nGraphical Editors\\n\\nYou can log in to a FastX, which provides a MATE desktop environment. One of the tools is a graphical editor very similar to Notepad. It is called pluma by MATE, but we have made it available as gedit if started from a terminal. If you wish to start it from a menu, it is available from ApplicationsAccessories.\\n\\nYou can also use Open OnDemand\\'s built-in file manager and editor. Create a new file from the Files menu. Select the file and choose Edit from the three-dot dropdown menu to the right of the file name. This will open a very basic text editor.\\n\\nCommand-Line Editors\\n\\nEditors available at the command line are nano, vim, and emacs. Nano is a simple text-only editor. Vim is also available text-only from a command line, but a graphical version called gvim can be invoked from a MATE Desktop through the ApplicationsAccessories menu. Emacs can also be started from the Accessories menu but, if a graphical environment, will start a graphical user interface. If invoked within a text-only environment, it will fall back to a text interface.\\n\\nOpen OnDemand Tool\\n\\nFor a user-friendly introduction to creating Slurm scripts on-demand, we have implemented a Slurm script generator on Open OnDemand. To access the generator, go through UtilitiesSlurm Script Generator on the top bar. This will present you with a fillable web form that generates a text file in real time with the details of your resource requests. You can then download the script created by the generator to your local workstation once completed. You can upload it to the cluster using any file transfer method you prefer.\\n\\nOur First Slurm Script\\n\\nThis example illustrates the main parts of a Slurm script.\\n\\nIn a bash script, any text beyond the # is ignored.\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/hello.slurm\" lang=\"bash\" >}}\\n\\nThis script runs the Python code\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/hello.py\" lang=\"python\" >}}\\n\\nThe Hello.slurm Script\\n\\nThe first line says that this script should be run by the bash interpreter. ```bash\\n\\n!/bin/bash\\n\\n```\\n\\nThe lines starting with #SBATCH are the resource requests. They are called \"pseudocomments\" since they have meaning to Slurm. There must be no space between # and SBATCH and the string must start in the first column of the line.\\n\\n```bash\\n\\nSBATCH --nodes=1\\n\\nSBATCH --ntasks=1\\n\\nSBATCH --cpus-per-task=1 # total cores per task\\n\\nSBATCH --mem=32000 # mb total memory\\n\\nSBATCH --time=2:00:00\\n\\nSBATCH --partition=interactive\\n\\nSBATCH --account=hpc_training\\n\\n`` Here we are requesting * 1 node, 1 task, 1 core * 32GB of memory (measured in MB). Strictly speaking this will be \"Gibibyes.\" * 2 hours of running time. * The interactive partition (queue). A partition must be specified. * The account (allocation) grouphpc_training`\\n\\nThe next lines set up the environment to run our job. bash module purge module load miniforge\\n\\nIt is good practice to purge all modules first, since Slurm \"remembers\" any modules set in the environment where the script is launched. Next we load the module we need to run our program, the Python distribution Miniforge.\\n\\nFinally, we execute our job. bash python hello.py\\n\\nWe have chosen to name this script hello.slurm, but it can have any name.\\n\\nExercise 1\\n\\nUsing the Open OnDemand Slurm Script Generator, create a slurm script with the following resource requests: * 1 node, 1 task, 1 core. * 32GB of memory. * 2 hours of running time. * The interactive partition (queue). * The account (allocation) group hpc_training.\\n\\nUsing the displayed text file, compare your slurm script with our example hello.slurm. The requested resources should be the same. Once completed, download your slurm script and transfer it to the cluster by whatever means you wish. Also, download hello.py and transfer it to the cluster as it will be needed later.\\n\\nCommon Slurm Directives\\n\\nThe most commonly used Slurm directives are listed in the table below. Many options have two versions, one with a single hyphen - followed by one letter, or two hyphens -- followed by a word and an equals sign =. Some commands have no single-letter equivalent.\\n\\nAngle brackets < > indicate a value to be specified, and are not typed.\\n\\n{{< table >}} | Single-hyphen Option | Double-Hyphen Option| Action | | ----- | -----| ---- | | -a \\\\<list> | --array=\\\\<list> | This is a job array with parameters in \\\\<list> | | -c \\\\<ncpus> | --cpus-per-task=\\\\<ncpus> | Number of cpus (cores) to be assigned to each task. For threaded code. Ensures all cores are on the same node.| | -C \\\\<list> | --constraint=\\\\<list> | Specify certain resource constraints | | -D \\\\<directory> | --chdir=\\\\<directory> | Change to \\\\<directory> before starting the job. Default is directory from which job is started. | | -e \\\\<name> | --error=\\\\<filename> | Separate standard error from standard output and print to file \\\\<name> | | None | --export=\\\\<vars> | Specify which environment variables are to be exported. Other options are ALL (the default) or NONE | | | --gres=\\\\<list> | Specify \"generic consumable resources.\" For example --gres=gpu:2 | |-J \\\\<jobname> | --job-name=\\\\<jobname> | Specify a name of your choosing for the job rather than the default script name. | | None | --mail-type=\\\\<type> | Notify me by email upon certain events. Options are NONE (default) BEGIN (job begins), END (job ends), FAIL (job fails) , REQUEUE (job is requeued), or ALL | | None | --mail-user=\\\\<email> | Specify the email for notifications. | | None | --mem=\\\\<size[units]> | Specify the total memory request per node, over the entire node. The default unit is megabytes. | | None | --mem-per-cpu=\\\\<size[units]> | Memory request per allocated core. Default unit is megabytes. | | -n \\\\<number> | --ntasks=\\\\<number> | Request a total number of tasks over all nodes allocated. | | None | --ntasks-per-node=\\\\<ntasks> | Request that a minimum of ntasks be assigned to each node. | -N \\\\<nnodes> | --nodes=\\\\<nnodes> | Request nnodes nodes. Should be used only with MPI or other protocols able to use them. | | -o \\\\<filename> | --output=\\\\<filename> | Specify a name of your choosing for the standard output file rather than the default of slurm\\\\<jobid>.out. | | -p \\\\<name>| --partition=\\\\<names> | Specify the partition to run the job. | | -t \\\\<time> | --time=\\\\<time> | Set the upper limit of the runtime. Format can be M (a number of minutes), MM:SS (minutes:seconds), HH:MM:SS (hours:minutes:seconds), D-H (days-hours), D-HH:MM (days-hours:minutes), or D-HH:MM:SS (days-hours:minutes:seconds). | {{< /table >}}\\n\\nSee also our documentation for many more examples.\\n\\nModules\\n\\nAny application software that you want to use will need to be loaded with the module load command.\\n\\nFor example:\\n\\n$ module load matlab $ module load miniforge $ module load goolf R Modules need to be loaded any time that a new shell is created to set up the same working environment. This includes every time that you log out and back in, and every time that you run a batch job on a compute node.\\n\\nModule Details\\n\\nmodule avail  Lists all available modules and versions.\\n\\nmodule spider  Shows all available modules\\n\\nmodule key keyword  Shows modules with the keyword in the description\\n\\nmodule list  Lists modules loaded in your environment.\\n\\nmodule load mymod  Loads the default module to set up the environment for some software.\\n\\nmodule load mymod/N.M  Loads a specific version N.M of software mymod. module load compiler mpi mymod  For compiler- and MPI- specific modules, loads the modules in the appropriate order and, optionally, the version.\\n\\nmodule purge  Clears all modules.\\n\\nLearning more about a Module\\n\\nTo locate a python module, try the following:\\n\\n$ module avail python $ module spider python $ module key python\\n\\nTo find bioinformatics software packages, try this:\\n\\n$ module key bio\\n\\nThe available software is also listed on our website\\n\\nExercise 2\\n\\nTry typing the command python in a terminal window. Why was it unable to find the executable? Now, load a module of your choosing that has python. Try the python command again. Purge your current modules and try python again.\\n\\nUse module spider R to show the available R modules and how to load them. Using this information, why does the command module load R give an error?\\n\\nOpen hello.slurm using any text editor you prefer and add the lines needed to purge existing modules, load a module that provides python, and execute the hello.py script. For reference, check our example hello.slurm.\\n\\nWorking with Files and Folders\\n\\nWhen using Slurm in terminal mode, you will probably want to create your own folders to organize your Slurm scripts, any input files, and the output. You will need to be able to move around from one folder to another at the terminal.\\n\\nBy default, Slurm will start your job from the folder in which it was launched. You can change that with the -D option (directory) but many users simply navigate to the folder and type commands.\\n\\nCreating Files and Folders\\n\\nThere are several options to create, rename, and move your files and folders. Note that folders are usually called \"directories\" in Unix.\\n\\nFastX\\n\\nUse the Caja file manager. This shows up as a filing-cabinet icon in the upper-left corner of the ribbon of the MATE Desktop. It can also be started from the menu ApplicationsSystem ToolsCaja. Caja\\'s layout is very similar in appearance and behavior to Windows Explorer and similar tools.\\n\\nOpen OnDemand\\n\\nUse the File Manager to create, rename, or move your folders.\\n\\nCommand Line\\n\\nIf you are familiar with the command line, you can use that. If you wish to learn it, you can go through our Unix Tutorials for Beginners, especially Tutorials 1--3. You can also go through our HPC from the Terminal tutorial if you have not already done so.\\n\\nChanging into a Directory\\n\\nIf you do not wish to learn the full command-line navigation, you will need to learn the cd command to get to your folder for launching your job.\\n\\nLog into a terminal in FastX, or open a terminal through the Clusters tab in Open OnDemand.\\n\\nThe cd command stands for \"change directory.\" It is followed by a path to that directory. In the examples below, mst3k is a generic user ID. Substitute your own.\\n\\nbash $cd myworkdir $cd /scratch/mstk3/myprojectdir $cd The cd command with no options returns you to the top level of your home directory.\\n\\nYou may also wish to learn pwd for \"print working directory\" so you can find out where you are.\\n\\nbash $cd shakespeare $pwd /home/mst3k/shakespeare\\n\\nExercise 3\\n\\nUse FastX or Open OnDemand or the command line to create a new folder under your scratch directory. Practice changing into and out of it. Move hello.slurm and hello.py into the newly created folder.\\n\\nUse FastX and Caja to navigate to your /scratch directory. To get there, click Go in the Caja menu. A textbox will open. Be sure that search for files is unchecked. Erase whatever is in the textbox and type /scratch/mst3k (substituting your own user ID). Still in FastX, open a terminal (the black box, or in the System Tools menu) and navigate to your new scratch folder.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1301 of 1477]\n",
      "Found 1300 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/slurm-from-cli/section4.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: IV - Specialized Jobs date: 2023-12-11-14T00:11:14Z type: docs toc: true weight: 40 menu: slurm-from-cli:\\n\\nEnvironment Variables\\n\\nAn environment variable describes something about your working environment. Some of them you can set or modify; others are set by the system. To see what is currently set in your terminal, run bash $printenv\\n\\nTo set an environment variable yourself, use the export command. bash $export VAR=value\\n\\nWhen your job starts, SLURM will initialize several environment variables. Many of them correspond to options you have set in your SBATCH preamble. Do not attempt to assign to any variable beginning with SLURM_\\n\\nSome variables that you may wish to examine or use in your scripts:\\n\\n{{< table >}} | Variable | Value | | --------- | ----- | | SLURM_SUBMIT_DIR | Directory from which the job was submitted | | SLURM_JOB_NODELIST | List of the nodes on which the job is running | | SLURM_JOB_ID | The numerical ID of the job | | SLURM_NUM_TASKS | The number of tasks (obtained from --ntasks) | | SLURM_NTASKS_PER_NODE | The number of tasks per node | | SLURM_CPUS_PER_TASK | The number of cpus (cores) assigned to each task | {{< /table >}}\\n\\nInteractive Jobs\\n\\nMost HPC sites, including UVa\\'s, restrict the memory and time allowed to processes on the login nodes. Most jobs can be submitted through the batch system we have been discussing, but sometimes more interactive work is required. For example 1. Jobs that must be or are best run through a graphical interface, 2. Short development jobs, 3. \"Computational steering\" in which a program runs for an interval, then the output is examined and parameters may be adjusted.\\n\\nFor most of these cases, we strongly recommend the use of the Open OnDemand Interactive Applications. Jupyterlab is available to run notebooks. Rstudio and Matlab Desktop are also available to run through this interface. For more general work, including command-line options, the Desktop is usually the best option. It provides a basic terminal, but also access to other applications should they be needed.\\n\\nFor general-purpose interactive work with graphics, please use the Open OnDemand Desktop. The X11 service that Linux uses for graphics is very slow over a network. Even with a fast connection between two systems, the Desktop will perform better since the X11 server process and the programs that use it are running on the same computer.\\n\\nIf you must use a basic terminal for an interactive job, you must first use the command salloc. This is the general Slurm command to request resources. This would be followed by srun to launch the processes. However, this is complex and requires knowledge of the options, so we have provided a local \"wrapper\" script called ijob.\\n\\nijob takes options similar to those used with SBATCH, most of which are actually arguments to salloc.\\n\\nbash $ijob c 1 A myalloc -t <time> --mem <memory in MB> -p <partition> -J <jobname>\\n\\nWhen the job starts you will be logged in to a bash shell in a terminal on the compute node.\\n\\n{{< warning >}} Never issue an sbatch command from within an interactive job (including OOD jobs). The sbatch command must be used only to submit jobs from a login node. {{< /warning >}}\\n\\nMulticore and Multinode Jobs\\n\\nOne of the advantages of using a high-performance cluster is the ability to use many cores and/or nodes at once. This is called parallelism. There are three main types of parallelism.\\n\\nYou should understand whether your program can make use of more than one core or node before you request multiple cores and/or nodes. Special programming is required to enable these capabilities. Asking for multiple cores or nodes that your program cannot use will result in idle cores and wasted SUs, since you are charged for each core-hour. The seff command can help with this.\\n\\nHigh Throughput Serial Parallelism\\n\\nHigh throughput parallelism is when many identical jobs are run at once, each on a single core. Examples can include Monte-Carlo methods, parameter searches, image processing on many related images, some areas of bioinformatics, and many others. For most cases of this type of parallelism, the best Slurm option is a job array.\\n\\nWhen planning a high-throughput project, it is important to keep in mind that if the individual jobs are very short, less than roughly 15-30 minutes each, it is very inefficient to run each one separately, whether you do this manually or through an array. In this case you should group your jobs and run multiple instances within the same job script. Please contact us if you would like assistance setting this up.\\n\\nMulticore (Threaded)\\n\\nShared-memory programs can use multiple cores but they must be physically located on the same node. The appropriate Slurm option in this case is -c (equivalent to cpus-per-task). Shared memory programs use threading of one form or another.\\n\\nExample Slurm script for a threaded program: {{< code-download file=\"/notes/slurm-from-cli/scripts/multicore.slurm\" lang=\"bash\" >}}\\n\\nMultinode (MPI)\\n\\nIn this type of parallelism, each process runs independently and communicates with others through a library, the most widely-used of which is MPI. Distributed memory programs can run on single or multiple nodes and often can run on hundreds or even thousands of cores. For distributed-memory programs you can use the -N option to request a number of nodes, along with ntasks-per-node to schedule a number of processes on each of those nodes.\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/multinode.slurm\" lang=\"bash\" >}}\\n\\nHybrid MPI plus Threading\\n\\nSome codes can run with distributed-memory processes, each of which can run in threaded mode. For this, request --ntasks-per-node=NT and cpus-per-task=NC, keeping in mind that the total number of cores requested on each node is then $NT \\\\times NC$.\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/hybrid.slurm\" lang=\"bash\" >}}\\n\\nGPU Jobs\\n\\nWe have a dedicated partition with nodes that are equipped with Graphical Processing Units (GPUs). Code must be built to take advantage of GPU resources. If the packages and your code are not written to use GPU resources, the GPUs will remain idle and you will be charged the SUs for them. Some popular Python packages that you could use are Pytorch or TensorFlow. We have some material on how to get started with using them in a Deep Learning setting.\\n\\nGPU job scripts are similar to CPU scripts, but do require the addition of the --gres=gpu option. Example Slurm script requesting 1 GPU:\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/gpu.slurm\" lang=\"bash\" >}}\\n\\nThe script uses the command nvidia-smi which detects GPU activity.\\n\\nWe have several different GPU types equipped on our nodes each offering varying amounts of memory. See our website for Hardware Specifications. In the example above, Slurm will choose whatever GPU is available. If you are working with larger models you may find that you need a GPU with more memory. To request a specific GPU, you add it to the gres Slurm option. If a GPU type has multiple options (for instance, we offer 40GB and 80GB A100 GPUs), there will be a constraint you can use to specify even further. Example Slurm script requesting 1 80GB A100 GPU node:\\n\\n{{< code-download file=\"/notes/slurm-from-cli/scripts/gpua100.slurm\" lang=\"bash\" >}}\\n\\nNote that the more specific your request is, the longer you will likely have to wait for the resource to be available.\\n\\nJob Arrays\\n\\nMany similar jobs can be submitted simultaneously through job arrays. There are some restrictions:\\n\\nIt must be a batch job.\\n\\nJob arrays should be explicitly named with -J\\n\\nIt is generally prudent to separate stdout and stderror with -o and -e\\n\\nA job array is submitted with sbatch --array=<range>, where range is two digits separated by a hyphen. bash $sbatch --array=0-30 myjobs.sh An increment can be provided bash $sbatch --array=1-7:2 myjobs.sh This will number them 1, 3, 5, 7\\n\\nIt is also possible to provide a list bash $sbatch --array=1,3,4,5,7,9 myjobs.sh\\n\\nEach job will be provided an environment variable SLURM_ARRAY_JOB_ID and each task will be assigned a SLURM_ARRAY_TASK_ID. The ARRAY_JOB_ID is the overall jobid, whereas the ARRAY_TASK_ID will take on the values of the numbers in the specified range or list.\\n\\nSlurm also provides two variables %A (global array ID) and %a (array task ID) which can be used in the -o and -e options. If they are not used, then the different tasks will attempt to write to the same file, which can result in garbled output or file corruption, so please use them if you wish to redirect streams with those options.\\n\\nTo prepare a job array, set up any input files using appropriate names that will correspond to the numbers in your range or list, e.g. myinput.0.in myinput.1.in ... myinput.30.in You would submit a job for the above files with bash $sbatch --array=0-30 In your Slurm script you would use a command such as bash python myscript.py myinput.${SLURM_ARRAY_TASK_ID}.in\\n\\nThe script should be prepared to request resources for one instance of your program.\\n\\nComplete example array job script: {{< code-download file=\"/notes/slurm-from-cli/scripts/array.slurm\" lang=\"bash\" >}}\\n\\nTo cancel an entire array, cancel the global ID bash scancel 1283839 You can also cancel individual tasks bash scancel 1283839_11\\n\\nUseful Commands\\n\\nWhen you submit a job and it doesn\\'t start or fails for an unknown reason it could be due to restraints in your account. This could include running out of storage space or SUs on your allocation. Additionally, it\\'s useful to see how busy the queue is. The following subsections highlight how to identify these problems.\\n\\nAllocations\\n\\nSometimes its useful to check how many SUs are still available on your allocation. The allocations command displays information on your allocations and how many SUs are associated with them:\\n\\n$ allocations Account Balance Reserved Available ----------------- --------- --------- --------- hpc_training 1000000 0 999882\\n\\nrunning allocations -a <allocation_name> provides even more detail on when the allocation was last renewed and its members. E.g.\\n\\n``` $ allocations -a hpc_training Description StartTime EndTime Allocated Remaining PercentUsed Active\\n\\nnew 2024-05-29 17:33:13 2025-05-29 1000000.000 999881.524 0.01 True\\n\\nName Active CommonName EmailAddress DefaultAccount\\n\\n. . . ```\\n\\nStorage Quota\\n\\nOne way to check your storage utilization is with the hdquota command. This command will show you how much of your home, scratch, and leased (if applicable) storage are being utilized. Below is the sample output for hdquota:\\n\\n$ hdquota Type Location Name Size Used Avail Use% ==================================================================================================== home /home mst3k 50G 16G 35G 32% Scratch /scratch mst3k 12T 2.0T 11T 17%\\n\\nThis is a useful command to check whether youre running out of storage space or to see where files need to be cleaned up. For more detailed information on disk utilization you may also use the du command to investigate specific directories.\\n\\nQueue limits and Usage\\n\\nTo gain information on the different queues you can use the qlist command. This will show the list of partitions, their usage, and the SU charge rate. You can use qlimits for information on each queues limits.\\n\\nThe sinfo command will provide some more detailed information on the health of each queue and the number of active nodes available. These commands can be useful in diagnosing why a job may not be running, or to better understand the queue usage for more efficient job throughput. More information on hardware specifications and queue information can be found here on our website.\\n\\nNeed Help\\n\\nResearch Computing is ready to help you learn to use our systems efficiently. You can submit a ticket. For in-person help, please attend one of our weekly sessions of office hours.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1302 of 1477]\n",
      "Found 1301 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/slurm-from-cli/section1.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: I - HPC and Resource Management date: 2023-12-11-14T00:11:14Z type: docs weight: 10 toc: true menu: slurm-from-cli:\\n\\nResources and Partitions\\n\\nAn HPC job is a description of the resources required, any preparatory steps such as loading modules or otherwise setting up an environment, and the commands to run the software, along with any postprocessing that may be appropriate.\\n\\nThe job is specified through a special form of script often called a batch script. Usually it is written in bash.\\n\\nResources include the quantity of time requested, the amount of memory, the number of cores per node, and if appropriate the number of nodes or the number and/or architecture of GPU.\\n\\nIn the abstract, a queue is a sequence of jobs to be prioritized and handled. In a cluster, a queue, which Slurm calls a partition, is implemented with a group of compute nodes that provide a particular set of resources.\\n\\nSlurm is a software package that manages the resources of the cluster and balances the demands of many competing job requests. It consists of a workload manager, often called a scheduler, and a slurmd \"daemon\" which runs on each node and handles the execution and monitoring of the jobs.\\n\\nCores, Nodes, and Tasks\\n\\nHardware\\n\\nThe Slurm model is a cluster consisting of a number of nodes. Each node is a separate server. These servers are similar to an ordinary desktop computer, but are more reliable and usually provide more memory and cores that an ordinary desktop.\\n\\nA core is a computing unit. It is part of a cpu.\\n\\n{{< alert >}} Slurm began when cpus had only one core each. Beginning around 2005, cpus began to be divided into multiple cores. But Slurm still refers to cores as \"cpus.\" {{< /alert >}}\\n\\nMemory refers to random-access memory. It is not the same thing as storage. If a process reports running out of memory, it means RAM memory. Running out of disk space will result in a different error.\\n\\nFor more details about the structure of a computational cluster, see our introduction.\\n\\nProcesses and Tasks\\n\\nA process can be envisioned an instance of an executable that is running on a particular computer. Most executables run only a single process. Some executables run threads within the root process.\\n\\nSlurm refers to the root process as a task. By default, each task is assigned to one core.\\n\\nSlurm Resource Requests\\n\\nSLURM refers to queues as partitions . We do not have a default partition; each job must request one explicitly.\\n\\n{{< table >}} | Queue Name | Purpose | Job Time Limit | Max Memory / Node / Job | Max Cores / Node | | :-: | :-: | :-: | :-: | :-: | | standard | For jobs on a single compute node | 7 days | 1462 GB | 96 | | gpu | For jobs that can use general purpose GPUs (A40,A100,A6000,V100,RTX3090) | 3 days | 1953 GB | 128 | | parallel | For large parallel jobs on up to 50 nodes (<= 1500 CPU cores) | 3 days | 750 GB | 96 | | interactive | For quick interactive sessions (up to two RTX2080 GPUs) | 12 hours | 216 GB | 96 | {{< /table >}}\\n\\nTo see an online list of available partitions, from a command line type bash $qlist\\n\\nA more detailed view of the partitions and their limits is available through the command bash $qlimits\\n\\nBatch Scripts\\n\\nJobs are described to the resource manager in the form of a script. Typically this is written in the bash scripting language. Bash is the default shell on most Linux-based systems, which includes the majority of HPC systems, so it is expected to be available to interpret the script. However, Slurm accepts scripts in other languages if the interpreter is available. We will consider only bash scripts in this tutorial.\\n\\nTo prepare a job, the user writes a script. The top of the script is a preamble that describes the resource requests. The rest of the script contains the instructions to execute the job. The script is then submitted to the Slurm system. The Slurm workload manager examines the preamble to determine the resources needed, while ignoring the rest of the script. It uses the resource request along with a fair share algorithm to set the priority of the job. The job is then placed into the requested partition to wait for the resources to become available.\\n\\nOnce the job starts, the slurmd daemon runs the script as an ordinary shell script. The preamble consists of comments (code that is not executed by the interpreter) so they are ignored. The rest of the script must be a valid bash shell script.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1303 of 1477]\n",
      "Found 1302 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/slurm-from-cli/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The Slurm Resource Manager date: \"2023-12-11-14T00:00:00\" type: docs weight: 1 menu: slurm-from-cli:\\n\\n{{< figure src=\"/notes/slurm-from-cli/img/slurm_logo.png\" width=30% >}}\\n\\nSlurm is a resource manager (RM), also known as a queueing system.\\n\\nResource managers are used to submit jobs on a computing cluster to compute nodes from an access point generally called a login node.\\n\\nLogin nodes are intended for editing, compiling, and very short test runs. Production jobs go to compute nodes through the queueing system.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1304 of 1477]\n",
      "Found 1303 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/slurm-from-cli/section3.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: III - Jobs on the Cluster date: 2023-12-11-14T00:11:14Z type: docs toc : true weight: 30 menu: slurm-from-cli:\\n\\nRunning Jobs from Scratch\\n\\nWe recommend that you run your jobs out of your /scratch directory. * Your personal /scratch/mst3k folder has much more storage space than your home directory. * /scratch is on a Weka filesystem, a storage system designed specifically for fast access. * /scratch is connected to the compute nodes with Infiniband, a very fast network connection.\\n\\n{{< alert >}} The scratch system is not permanent storage, and files older than 90 days will be marked for deleting (purging). You should keep copies of your programs and data in more permanent locations such as your home directory, leased storage such as /project or /standard, or on your lab workstation. After your jobs finish, copy the results to permanent storage. {{< /alert >}}\\n\\nSubmitting a Job\\n\\nOnce we have navigated to the desired working directory in a terminal window, we use the sbatch command to submit the job. This assumes that your Slurm script is located in the current working directory.\\n\\nbash sbatch myjob.slurm The system returns a JOBID.\\n\\nWe do not make the script executable. The system handles that.\\n\\nbash $sbatch myjob.slurm Submitted batch job 36805 Always remember that you submit your job script and not your executable or interpreter script.\\n\\nExercise\\n\\nFrom your working directory where hello.slurm is, submit the job.\\n\\nMonitoring a Job\\n\\nOnce submitted, we can monitor our jobs.\\n\\nGraphical Interface\\n\\nThe Open OnDemand Job Viewer (Jobs tabActive Jobs) shows a Web-based view of jobs. You can switch the dropdown between \"All Jobs\" and \"Your Jobs.\" You can also use the Filter textbox to select jobs by partition or another criterion. In the Filter textbox you can enter multiple strings, which acts as \"and.\"\\n\\nClicking the right-pointing arrow on the left side will cause a dropdown box to appear that will show the job status (Pending, Running, Completed) along with much other useful information.\\n\\nRemember that this is a Web page and you will need to reload it in order to see changes in status.\\n\\nCommand Line\\n\\nWe use the squeue command to check on jobs from the terminal.\\n\\nbash $squeue This shows all jobs. To narrow that down we can use the -u (user) option or the -p (partition) option.\\n\\nbash $squeue -u mst3k $squeue -p gpu\\n\\nJob status is indicated by * PD pending * R running * CG exiting\\n\\n```no-highlight JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)\\n\\n36805 standard myjob.sl mst3k R 1:45 1 udc-aw38-34-l ```\\n\\nJobs should rarely be observed in the CG state. If they are caught in that state they cannot be canceled by the user. Exiting jobs will not charge for the time spent in that state.\\n\\nFor more information on a running job, similar to what you can see from the OOD Job Viewer, use the scontrol command. bash scontrol show job <jobid>\\n\\nDeleting a Job\\n\\nOpen OnDemand\\n\\nFrom the Job Viewer find your jobs. If the job is pending or running, a red trash-can icon will appear under the \"Actions\" header. Click the icon. A dialog box will appear asking you to confirm the cancellation.\\n\\nCommand Line\\n\\nTo cancel a job use the scancel with the job ID. You can use squeue -u $USER to obtain your job IDs, but you must know the JID of the specific job you wish to cancel.\\n\\nbash $scancel 36805 #jobID\\n\\nBe aware that if a job fails due to a system failure the time will not be charged, but if you cancel your job, or it fails due to inadequate resource request, your allocation will be charged for the time expended.\\n\\nExercise 4\\n\\nWrite a Slurm script that requests 30 minutes of time. Submit a job that will run for at least 30 minutes. It can be some software you use; if you do not have anything set up yet, write the preamble and then add the line bash sleep 30m as the command. You won\\'t need to request a specific amount of memory. Submit this script and monitor your jobs status in the queue with squeue or the Active Jobs tab. Once it starts, get information about your job with scontrol, let it run for a minute, then cancel it with scancel. Practice with the terminal commands or the OOD GUI. Note that you will need your jobs ID for the last two commands.\\n\\n{{< spoiler text=\"Example script\" >}} {{< code-download file=\"/notes/slurm-from-cli/scripts/slow.slurm\" lang=\"bash\" >}} {{< /spoiler >}}\\n\\nExamining Your Utilization\\n\\nWhen your jobs have finished, you may wish to find out how much of the resource you utilized. Two commands can be used for this purpose, sacct and seff.\\n\\nsacct\\n\\nAs the name suggests, sacct will return accounting information about your job. It is built-in to Slurm and does not know about local policies such as SU charges, but it will show you information about the job. It only works for jobs that have ended.\\n\\nWith no options it will show output for jobs run on the current date. ```bash JobID JobName Partition Account AllocCPUS State ExitCode\\n\\n56220974 mpi.slurm parallel hpc_build 10 FAILED 9:0 56220974.ba+ batch hpc_build 5 FAILED 9:0 56220974.0 mpiheated+ hpc_build 10 FAILED 1:0 56220992 mpi.slurm standard hpc_build 10 COMPLETED 0:0 56220992.ba+ batch hpc_build 10 COMPLETED 0:0 56220992.0 mpiheated+ hpc_build 10 COMPLETED 0:0 56221184 mpi.slurm standard hpc_build 10 COMPLETED 0:0 56221184.ba+ batch hpc_build 10 COMPLETED 0:0 56221184.0 mpiheated+ hpc_build 10 COMPLETED 0:0 56221192 mpi.slurm standard hpc_build 10 COMPLETED 0:0 56221192.ba+ batch hpc_build 10 COMPLETED 0:0 56221192.0 mpiheated+ hpc_build 10 COMPLETED 0:0 ```\\n\\nFor a particular job, use the -j option.\\n\\n```bash $sacct -j 56221192 JobID JobName Partition Account AllocCPUS State ExitCode\\n\\n56221192 mpi.slurm standard hpc_build 10 COMPLETED 0:0 56221192.ba+ batch hpc_build 10 COMPLETED 0:0 56221192.0 mpiheated+ hpc_build 10 COMPLETED 0:0 ```\\n\\nFor more detail, specify the -o option and a list of fields. The list of available fields is returned by sacct -e and is lengthy. For example, if I use only one allocation I may not be interested in that field. ```bash $sacct -o jobname,jobid,ncpus,nnodes,maxrss,state,elapsed -j 56221192 JobName JobID NCPUS NNodes MaxRSS State Elapsed\\n\\nmpi.slurm 56221192 10 1 COMPLETED 00:00:34 batch 56221192.ba+ 10 1 4824K COMPLETED 00:00:34 mpiheated+ 56221192.0 10 1 108800K COMPLETED 00:00:33 ```\\n\\nThe output from sacct can be heavily customized. For more information see the documentation.\\n\\nRunning sacct puts a load on the system and can be very slow, so please use it judiciously.\\n\\nseff\\n\\nThe seff command returns information about the utilization (called the \"efficiency\") of core and memory. The output of seff will be returned in an email if you use END in Slurm\\'s emailing feature.\\n\\nbash $seff 56221192 Job ID: 56221192 Cluster: shen User/Group: mst3k/users State: COMPLETED (exit code 0) Nodes: 1 Cores per node: 10 CPU Utilized: 00:05:17 CPU Efficiency: 93.24% of 00:05:40 core-walltime Job Wall-clock time: 00:00:34 Memory Utilized: 1.04 GB (estimated maximum) Memory Efficiency: 1.18% of 87.89 GB (8.79 GB/core)\\n\\nUnder most circumstances, for a cpu-only job the \"CPU\" (core) efficiency should be around 90% or better. Please contact us if it is significantly lower than that. Note that seff may be relatively inaccurate for very short jobs.\\n\\nCore efficiency is more problematic for GPU jobs, since the key to efficient GPU utilization is maximizing the GPU computations and minimizing CPU work. Seff does not provide a GPU utilization metric at this time, but we may be able to help you if you are concerned about GPU utilization.\\n\\nIf your memory utilization is low and you have requested a specified amount, use sacct -o with at least the MaxRSS field to double-check. If you do not need as much memory as you thought, you may be able to save SUs and have a shorter queue wait time if you decrease it.\\n\\nStream Output in Slurm\\n\\nWhen running a program interactively, any output to the Unix standard streams will be printed directly to the user\\'s console window. However, programs running under the control of Slurm will not have a console attached.\\n\\nBy default, SLURM redirects both standard output and standard error to a file called slurm-<jobid>.out.\\n\\nYou can change the name of this file with the -o or --output option in your script.\\n\\n```bash\\n\\nSBATCH --output=\\n\\norbash\\n\\nSBATCH -o\\n\\n```\\n\\nYou can also separate standard-error output. Even if your program does not use standard error (not many do), Slurm uses it, so you may wish to keep that output distinct. ```bash\\n\\nSBATCH --error=\\n\\norbash\\n\\nSBATCH -e\\n\\n```\\n\\nText from standard input must be redirected from a file in your command line in the script. bash ./myexec < myinput.txt\\n\\nAs an alternative to the Slurm options, you can also redirect standard output in the usual Unix manner if you prefer. bash ./myexec < myinput.txt > myoutput.dat')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1305 of 1477]\n",
      "Found 1304 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/matlab-data-visualization/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"MATLAB Data Processing and Visualization\" type: article highlight_style: \"github\" toc: true date: 2023-12-11T00:00:00-05:00 menu: matlab-data-viz: name: MATLAB Data Processing and Visualization weight: 1\\n\\nMATLAB is mathematical computing software that combines an easy-to-use desktop environment with a powerful programming language. MATLAB can be used for data cleansing and processing, as well as data visualization. This tutorial will cover 1. importing data from a variety of file types and formats, 2. data cleansing and manipulation, and 3. data visualization techniques.\\n\\nDownloading the Data\\n\\nThroughout the tutorial we will be working with data from the National Health and Nutrition Examination Survey (NHANES). Download nhanes_matlab.xlsx.\\n\\nData Import\\n\\nImporting Tabular Data\\n\\nreadtable\\n\\nCreates a table by reading column oriented data from a file\\n\\nT = readtable(filename)\\n\\nreadtable creates one variable in the table T for each column in the file filename.\\n\\nWholly numeric columns will be converted to a numeric array; a cell array will be generated from a column containing any non-numeric values.\\n\\nReadable File Formats File Extensions Delimited text files .txt, .dat, .csv Spreadsheet files .xls, .xlsb, .xlsx\\n\\nExample\\n\\ndata = readtable(\\'nhanes_matlab.xlsx\\');\\n\\nWhile readtable is capable of reading Excel files, you will need to use readmatrix if you need to specify sheet names or a range of data. Both of these functions output a table.\\n\\nImporting Data from Multiple Files\\n\\ndatastore\\n\\nRead large collections of data\\n\\nA datastore is simply a reference to a file or set of files. You tell MATLAB where to look for files with the datastore command.\\n\\nSingle File ds = datastore(filename)\\n\\nMultiple Files ds = datastore(directory)\\n\\nThe datastore ds has many properties that you can modify so that MATLAB reads your data correctly (e.g. treating -999 as a missing value instead of a numeric data point).\\n\\nDatastores are also useful if you are working with such a large amount of data that you wouldn\\'t be able to load it all into memory. With a datastore you can tell MATLAB to read in the data incrementally, whether it\\'s file by file or in 100-line chunks (MATLAB reads data in 20,000 line chunks by default).\\n\\nTo read in data using a datastore, use the read or readall commands.\\n\\nRead data incrementally data = read(ds);\\n\\nRead all data referenced by datastore ds data = readall(ds);\\n\\nSee the MATLAB documentation on datastores to learn more about customizing your data import.\\n\\nExample\\n\\n```matlab % Create datastore ds = datastore(\\'nhanes_matlab.xlsx\\');\\n\\n% Set ReadSize property in ds to 50 so we only read in 50 lines at a time ds.ReadSize = 50;\\n\\n% Read in first 50 lines data50 = read(ds);\\n\\n% Read in next 50 lines data100 = read(ds);\\n\\n% Read in all data data_all = readall(ds); ```\\n\\nImporting Unstructured Data\\n\\nSuppose you have an unstructured data file like the one below.\\n\\n{{< figure src=\"/notes/matlab-data-visualization/matlab-dataviz-1.png\" >}}\\n\\nMATLAB is unable to read data automatically if each line doesn\\'t have the same number of columns. We can use MATLAB\\'s lower-level file import functions to read irregular data.\\n\\nUsing low-level file import requires three steps:\\n\\nOpen file (fid = fopen(filename), fid stands for file ID)\\n\\nRead data\\n\\nClose file (fclose(fid))\\n\\nThe first and last steps are pretty straightforward, so the rest of this section will focus on step 2. There are a couple ways we can read in the data.\\n\\nfgetl Read line from file\\n\\nmyLine = fgetl(fid) Using in succession will allow you to continue reading the file line by line. Regardless of whether the data is numeric, the output of fgetl will be a string. This means you may have to parse and convert the data to the proper data type after import. You can learn more about this process from MATLAB\\'s documentation on string manipulation.\\n\\ntextscan Read formatted data from file\\n\\nmyData = textscan(fid, formatSpec)\\n\\ntextscan allows you to specify the format of a line of data up-front so that you don\\'t have to manipulate strings unnecessarily. textscan also allows you to read multiple lines and to skip any columns you don\\'t need.\\n\\nThe output of textscan is a cell array (myData) where each cell contains the values from a single column. Each cell will contain a column vector (for numeric data) or column cell array (for non-numeric or mixed data).\\n\\ntextscan requires you to specify the format of your data in the variable formatSpec. Below is a formatSpec for some example data.\\n\\n{{< figure src=\"/notes/matlab-data-visualization/matlab-dataviz-2.png\" >}}\\n\\n```matlab % This dataset is part of your installation of MATLAB!\\n\\n% fullfile retrieves the full file path to the dataset. filename = fullfile(matlabroot, \\'examples\\', \\'matlab\\', \\'scan1.dat\\');\\n\\n% Open the file fid = fopen(filename);\\n\\n% Format spec: it\\'s a string formatSpec = \\'%{MM/dd/uuuu}D %s %f32 %d8 %u %f %f %s %f\\';\\n\\n% Read the data into using textscan myData = textscan(fid, formatSpec);\\n\\n% Close the file fclose(fid); ```\\n\\nMore information about MATLAB\\'s low-level file I/O can be found here: https://www.mathworks.com/help/matlab/low-level-file-i-o.html.\\n\\nData Cleansing\\n\\nWorking with Missing Data\\n\\nWhen MATLAB imports data that has missing values for numeric variables, it replaces that instance with NaN, or Not-a-Number. This section discusses multiple ways you can handle missing data and NaNs.\\n\\nOmitting NaNs\\n\\nCalculating statistics on arrays that contain NaN results in another NaN. If we want to omit NaNs from our calculation, we can use the \\'omitnan\\' option.\\n\\nExample: Calculating mean ``` avgIncome = mean(data.Income, \\'omitnan\\');\\n\\n```\\n\\nOther functions that can use the \\'omitnan\\' option:\\n\\nFunction Name What It Does cov Covariance mean Mean median Median std Standard Deviation var Variance\\n\\nHowever, max and min omit NaNs by default, and adding the \\'omitnan\\' flag will yield unexpected results.\\n\\nLocating Missing Data and Deleting Incomplete Rows\\n\\nismissing Find missing values in a table\\n\\nTF = ismissing(A) ismissing returns a logical array TF that is the same size as the table A. Values of 1 in TF correspond to missing values in A at the same location.\\n\\nany Find non-zero elements in an array\\n\\nmissingRows = any(TF, 2) any returns a logical array missingRows that is the same length as the input array TF. Values of 1 in missingRows correspond to rows in TF that contain a 1. Because 1s in TF correspond to missing values in our original table A, values of 1 in missingRows also correspond to rows with missing data in A.\\n\\nWe have the number 2 as the second input in any. This is because by default any looks for non-zero elements in a column. Since we want to look for non-zero elements in rows, we need to specify that with the 2.\\n\\nLogical Indexing\\n\\nRemove rows with missing data\\n\\nA(missingRows,:) = [];\\n\\nUsing our logical array missingRows, we can index into our table A and select all the rows in A that have missing data. With the colon operator :, we can also select the data from all the columns in those rows. If we select that data in A and set it equal to empty brackets, that will remove all those rows from A.\\n\\nExample ``` % Read in data as table data = readtable(\\'nhanes_matlab.xlsx\\');\\n\\n% Find missing data missing = ismissing(data);\\n\\n% Find rows that have missing data missingRows = any(missing, 2);\\n\\n% Remove rows with missing data from table data(missingRows,:) = []; ```\\n\\nCategorical Data and Set Operations\\n\\ncategorical\\n\\nAssigns a value to each of a finite set of discrete categories\\n\\nConsider the cell array below. mySet = {\\'low\\', \\'medium\\', \\'low\\', \\'low\\', \\'high\\', \\'medium\\', \\'low\\'}; As humans, we understand that the array contains values that fall into 3 distinct categories: \\'low\\', \\'medium\\', and \\'high\\'. MATLAB doesn\\'t necessarily know this and will treat all seven items in the array as individual values. With the categorical function, we can tell MATLAB to treat values with the same string as part of a single category. The output of the categorical function is a categorical array the same size as the input array.\\n\\n``` mySet = categorical(mySet);\\n\\ncategories(mySet) ```\\n\\nWith the categories command, we can find out the different categories in our categorical array. As expected, our three categories are \\'low\\', \\'medium\\', and \\'high\\'.\\n\\nWe can convert the text variables in our table to categorical arrays one at a time with the categorical command.\\n\\n```matlab % Reading the data into a table data = readtable(\\'nhanes_matlab.xlsx\\');\\n\\n% Convert Gender variable to categorical array data.Gender = categorical(data.Gender); ```\\n\\nconvertvars Batch convert table variables to categorical arrays\\n\\nT2 = convertvars(T1, vars, datatype)\\n\\nWe can use convertvars to create a new table T2 that converts all the variables in our table T1 to our desired data type, in this case categorical arrays. We list the names of the variables we want to convert in the cell array vars.\\n\\nExample ```matlab % Reading the data into a table data = readtable(\\'nhanes_matlab.xlsx\\');\\n\\n% Convert text variables to categorical arrays vars = {\\'Gender\\', \\'Race\\'};\\n\\nnewdata = convertvars(data, vars, \\'categorical\\'); ```\\n\\nWe can replace vars with @iscell if we know we want to convert all cell arrays to in our table to categorical arrays.\\n\\nnewdata = convertvars(data, @iscell, \\'categorical\\');\\n\\nWhy Use Categorical Arrays?\\n\\nSeveral discrete data plot types require input data be categorical\\n\\nUse less memory\\n\\nismissing is able to determine missing data in categorical arrays but not cell arrays\\n\\nAnalyzing Groups within Data\\n\\nMATLAB Academy Exercises\\n\\nData Visualization\\n\\nWe will be looking at different examples of data visualization in MATLAB using a live script. Please download the script from this link.\\n\\nplot and Modifying Plot Line Properties\\n\\nFunctions for Customizing Appearance\\n\\nFigure Formatting GUI\\n\\nExporting and Saving Figures\\n\\nLog-Scaled Axes\\n\\nBar Plots, Box Plots, and Histograms\\n\\nScatter Plots\\n\\nScatter Plot Matrix\\n\\n3-D Surface Plots\\n\\nAnimation\\n\\nExtra Exercises\\n\\nNHANES\\n\\nCreate a scatter plot of Height vs Weight. Include labels on both axes and a title for your graph.\\n\\nCreate a new table in which all rows containing missing data, categorical or numerical, have been removed.\\n\\nCreate a scatter plot matrix to compare Weight, Height, and BPSys.\\n\\nCreate stacked bar plots showing the proportions of the Highest Level of Education reached at each Income.\\n\\nDiscretizing Continuous Data\\n\\nReview Project: Fuel Efficiency\\n\\n3D Data Visualization\\n\\nThe Graphics Objects Hierarchy')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1306 of 1477]\n",
      "Found 1305 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/cpu_resource_usage.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: CPU Resource Usage date: 2024-06-28-01:51:43Z type: docs weight: 550 toc: true menu: deep-learning-hpc: parent: Resource Allocation and Helpful Tools\\n\\nCPU Resource Usage For Running Jobs\\n\\nFor a running job, the sstat command will report on CPU and memory usage.\\n\\nIn this example, the job has been running on 20 cores for about 4 days. {{< figure src=/notes/deep-learning-hpc/img/sstat.png caption=\"\" width=70% height=70% >}}\\n\\nCPU Resource Usage For Completed Jobs\\n\\nFor a completed job , the seff command will return an efficiency report.\\n\\n{{< figure src=/notes/deep-learning-hpc/img/CPU_Resource_Usage.png width=60% height=60% >}}\\n\\nCPU Efficiency: This is good usage for the number of cores.\\n\\nMemory Efficiency: Only about 4 GB of (CPU) memory was needed.\\n\\nVisit our documentation about CPU and Memory Usage for more information.\\n\\nCPU Efficiency\\n\\nIt may be the case that even if CPU Efficiency is a low percentage, you need all of the requested CPU cores for a specific part of the code, e.g., data preprocessing. In this case, request the number of CPU cores that you need for the compute intensive part of the code.\\n\\nPrevious Job Numbers\\n\\nThe sacct command will return a list of previous Slurm jobs on the current day. * To get jobs run on previous days, use the -S flag and provide a start date * Ex: to display all Slurm jobs submitted after 2/1/2024 bash $ sacct -X -S2024-02-01 (the -X flag is optional, but tells sacct to skip the output of intermediate steps):\\n\\nCheck Your Knowledge\\n\\nFind your most recent job number using sacct.\\n\\nPrint out the resource usage using seff for the job number you found in step 2.\\n\\nHow efficient was your CPU and memory usage?')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1307 of 1477]\n",
      "Found 1306 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/gpu_resource_usage.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPU Resource Usage date: 2024-06-28-01:51:43Z type: docs weight: 650 toc: true menu: deep-learning-hpc: parent: Resource Allocation and Helpful Tools\\n\\nNVIDIA GPU Resource Usage\\n\\nnvidia-smi will report GPU utilization and memory usage for NVIDIA GPUs. * GPU Utilization refers to the percentage of time that at least one kernel was running on the GPU.\\n\\nwatch -n 1 nvidia-smi will update the display every second.\\n\\n{{< figure src=/notes/deep-learning-hpc/img/nvidia.png caption=\"Source: https://medium.com/analytics-vidhya/explained-output-of-nvidia-smi-utility-fc4fbee3b124 and https://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf\" width=80% height=80% >}}\\n\\nGPU Resource Usage\\n\\ngpustat will report GPU utilization and memory usage. ```bash\\n\\nmodule load gpustat gpustat ```\\n\\n{{< figure src=/notes/deep-learning-hpc/img/gpustat.png caption=\"Source: https://github.com/wookayin/gpustat\" width=90% height=90% >}}\\n\\nPyTorch\\n\\nCorrect GPU memory usage will be reported by the previous tools.\\n\\nTensorFlow/Keras\\n\\nBy default, TensorFlow automatically allocates ALL of the GPU memory so the previous tools will show that all (or almost all) of the GPU memory is being used.\\n\\nTo track the amount of GPU memory actually used, you can add these lines to your python script: python import os os.environ[\\'TF_FORCE_GPU_ALLOW_GROWTH\\'] = \\'true\\'\\n\\nVisit the Tensorflow website for additional information.\\n\\nCheck Your Knowledge\\n\\nFind the name of the GPU that you have access to.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1308 of 1477]\n",
      "Found 1307 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/choose_gpu.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Choose a GPU date: 2024-06-28-01:51:43Z type: docs weight: 850 toc: true menu: deep-learning-hpc:\\n\\nGPUs on HPC\\n\\n{{< table >}} | GPU | Full Name | Year Launched | Memory | # of Tensor Cores | | --- | --- | --- | --- | --- | | A100 | NVIDIA A100 | 2020 | 40GB or 80GB | 432 (3rd gen) | | A6000 | NVIDIA RTX A6000 | 2020 | 48GB | 336 (3rd gen) | | A40 | NVIDIA A40 | 2020 | 48GB | 336 (3rd gen) | | RTX3090 | NVIDIA GeForce RTX 3090 | 2020 | 24GB | 328 (3rd gen) | | RTX2080Ti | NVIDIA GeForce RTX 2080 Ti | 2018 | 11GB | 544 (2nd gen) | | V100 | NVIDIA V100 | 2018 | 32GB | 640 (1st gen) | {{< /table >}}\\n\\nWait Time in the Queue\\n\\nYou may not need to request an A100 GPU!\\n\\nRequesting an A100 may mean you wait in the queue for a much longer time than using another GPU,\\n\\nThis could give you a slower overall time (wait time + execution time) than if you had used another GPU.\\n\\n{{< figure src=/notes/deep-learning-hpc/img/queue_wait_graph.png caption=\"Photo Source: https://researchcomputing.princeton.edu/support/knowledge-base/scaling-analysis\" width=80% height=80% >}}\\n\\nMemory Required to Train a DL Model\\n\\nGenerally, you will choose a GPU based on how much GPU memory you need. But, it is a hard problem to determine how much GPU memory a DL model will need for training before training the model. * In addition to storing the DL model, training also requires additional storage space such as: * Optimizer states * Gradients * Data (how much is determined by the batch size) * Training can also use automatic mixed precision which lowers the amount of memory needed\\n\\nVisit https://blog.eleuther.ai/transformer-math/ for more information on math related to computation and memory usage for transformers.\\n\\nGeneral Advice\\n\\nIf you are learning about DL and doing tutorials, the GPUs in the Interactive partition are probably fine.\\n\\nYou can leave the GPU choice as default on the GPU partition and work on whichever GPU you get or choose a GPU with a smaller amount of memory first.\\n\\nTrain your model for one epoch and monitor the GPU memory usage.\\n\\nUse this information to choose a GPU to do the complete training on.\\n\\nYou can calculate the size of your DL model (the number of parameters) to compute the memory needed to store the model. See here for details.\\n\\nThere is a tool on Hugging Face that can calculate memory needs for a transformers or timm model (using a batch size of 1): https://huggingface.co/spaces/hf-accelerate/model-memory-usage\\n\\nProviding more information to users on how to choose a GPU for DL is currently being worked on.\\n\\nInformation will be updated on our website as it becomes available.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1309 of 1477]\n",
      "Found 1308 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/gpu_hpc.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: GPUs on HPC date: 2024-06-28-01:51:43Z type: docs weight: 350 toc: true menu: deep-learning-hpc: parent: Hardware Overview\\n\\n{{< table >}} | GPU | Full Name | Year Launched | Memory | # of Tensor Cores | | --- | --- | --- | --- | ---- | | A100 | NVIDIA A100 | 2020 | 40GB or 80GB | 432 (3rd gen) | | A6000 | NVIDIA RTX A6000 | 2020 | 48GB | 336 (3rd gen) | | A40 | NVIDIA A40 | 2020 | 48GB | 336 (3rd gen) | | RTX3090 | NVIDIA GeForce RTX 3090 | 2020 | 24GB | 328 (3rd gen) | | RTX2080Ti | NVIDIA GeForce RTX 2080 Ti | 2018 | 11GB | 544 (2nd gen) | | V100 | NVIDIA V100 | 2018 | 32GB | 640 (1st gen) | {{< /table >}}\\n\\nUVA-NVIDIA DGX BasePOD\\n\\n10 DGX A100 nodes\\n\\n8 NVIDIA A100 GPUs.\\n\\n80 GB GPU memory options.\\n\\nDual AMD EPYC:tm:; nodes: Series 7742 CPUs, 128 total cores, 2.25 GHz (base), 3.4 GHz (max boost).\\n\\n2 TB of system memory.\\n\\nTwo 1.92 TB M.2 NVMe drives for DGX OS, eight 3.84 TB U.2 NVMe drives forstorage/cache.\\n\\nAdvanced Features:\\n\\nNVLink for fast multi-GPU communication\\n\\nGPUDirect RDMA Peer Memory for fast multi-node multi-GPU communication\\n\\nGPUDirect Storage with 200 TB IBM ESS3200 (NVMe) SpectrumScale storage array\\n\\nIdeal Scenarios:\\n\\nJob needs multiple GPUs on a single node or multi node\\n\\nJob (single or multi-GPU) is I/O intensive\\n\\nJob (single or multi-GPU) requires more than 40GB of GPU memory\\n\\nNote: The POD is good if you need multiple GPUs and very fast computation.\\n\\nGPU access on UVA HPC\\n\\nWhen you request memory for UVA HPC, that is CPU memory.\\n\\nIf you request a GPU, you will receive all of the GPU memory.\\n\\nChoose \"GPU\" or \"Interactive\" as the HPC Partition in OOD\\n\\nOptionally, choose GPU type and number of GPUs\\n\\nPOD nodes are contained in the gpu partition with a specific Slurm constraint.\\n\\nSlurm script: ```bash\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:a100:X # X number of GPUs\\n\\nSBATCH -C gpupod\\n\\nOpen OnDemandnohighlight --constraint=gpupod ```\\n\\nNote: Only one person can be using a GPU at a time.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1310 of 1477]\n",
      "Found 1309 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/code_profiling.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Code Profiling date: 2024-06-28-01:51:43Z type: docs weight: 750 toc: true menu: deep-learning-hpc: parent: Resource Allocation and Helpful Tools\\n\\nA code profiler provides information about how much time each line of a program takes to run. * This information is helpful for effectively speeding up code execution time. * There are various profilers available for Python. A recommendation is line_profiler (https://github.com/pyutils/line_profiler).\\n\\nInstall line_profiler\\n\\nUse the PyTorch container: bash module load apptainer pytorch apptainer exec $CONTAINERDIR/pytorch-2.0.1.sif pip install line_profiler Use the TensorFlow container: bash module load apptainer tensorflow apptainer exec $CONTAINERDIR/tensorflow-2.13.0.sif pip install line_profiler Outside of a container: bash pip install --user line_profiler\\n\\nRun line_profiler\\n\\nIn the code file, include the import statement as below and use @profile to decorate the functions you would like to profile: python from line_profiler import profile ... @profile def fcn_to_profile(arg1, arg2, ...): ...\\n\\nRun line_profiler, use the --nv flag for GPU use\\n\\nPytorch: bash LINE_PROFILE=1 apptainer run --nv $CONTAINERDIR/pytorch-2.0.1.sif file_name.py\\n\\nTensorflow: bash LINE_PROFILE=1 apptainer run --nv $CONTAINERDIR/tensorflow-2.13.0.sif file_name.py\\n\\nProfiler results will be printed out into two text files (the files are the same): profile_output.txt and profile_output_[TIMESTAMP].txt.\\n\\nVisit the Line Profiler documentation for more information.\\n\\nNotes: - Running the command without LINE_PROFILE=1 will just run file_name.py but not profile it. - line_profiler has a very slight overhead (for code run on GPU). Some notive more of a slow down on strictly CPU code (~40 more seconds for code that should run in ~160 seconds).\\n\\nCheck Your Knowledge\\n\\nInstall line_profiler.\\n\\nUse line_profiler to profile the function \"train\" in example1.py.\\n\\nWhile the code is running, open a terminal and watch the nvidia-smi output.\\n\\nHow was the GPU utilization?\\n\\nWhich line takes the longest to run? Does this surprise you?\\n\\nWhat would you suggest we do to increase the efficiency of the code?')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1311 of 1477]\n",
      "Found 1310 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/cpu_memory_cores.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content=\"title: CPU Memory and Cores date: 2024-06-28-01:51:43Z type: docs weight: 500 toc: true menu: deep-learning-hpc: parent: Resource Allocation and Helpful Tools\\n\\nRequest CPU Memory\\n\\nStandard Partition (no GPU): you will get 9GB RAM per core\\n\\nInteractive Partition: you will get 6GB RAM per core\\n\\nGPU Partition: you can specify how much RAM you want\\n\\nYou should have enough RAM to comfortably work with your GPU. In other words, request at least as much RAM as the GPU you select. * If you select multiple GPUs, request as much RAM as the GPU you selected with the largest memory. * If you are using a large dataset and/or want to do extensive preprocessing, more RAM is probably helpful. * How much more? Depends! You can experiment and check your memory efficiency.\\n\\nVisit this Deep Learning Hardware Guide for more information.\\n\\nRequest CPU Cores\\n\\nIt depends how many CPU Cores to request! Generally, make your best guess to start. Then check the CPU and GPU efficiency of your script and adjust from there. * Are you are doing any data preprocessing on the CPU prior to training the network on the GPU? * Is the preprocessing code serial or parallel? * NOTE: Even if your code is written as a serial program, NumPy automatically uses multiple cores for linear algebra operations! * Are you using a single core or multiple cores for the data loading from the CPU to the GPU for the training process? * Use enough CPU cores to keep the GPU busy\\n\\nPyTorch\\n\\nPyTorch's DataLoader has a num_workers parameter, which is the number of CPU cores to use for the data loading.\\n\\nThe default is num_workers=1, but this may not load data fast enough to keep the GPU busy.\\n\\nTry increasing num_workers to improve GPU efficiency and speed up DL code.\\n\\nKeras\\n\\nKeras will use multiple cores for data loading automatically\")]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1312 of 1477]\n",
      "Found 1311 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/resource_allocation_tools.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Resource Allocation and Helpful Tools date: 2024-06-28-01:51:43Z type: docs weight: 400 toc: true menu: deep-learning-hpc:\\n\\nComputations on the CPU or GPU\\n\\n{{< table >}} | Task | CPU or GPU | | --- | --- | | Data Preprocessing | Either, but probably CPU | | Deep Learning Training | GPU | | Deep Learning Inference | Either, but probably GPU | {{< /table >}}\\n\\nWhen you request memory for Rivanna, that is CPU memory. If you request a GPU, you will receive all of the GPU memory.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1313 of 1477]\n",
      "Found 1312 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Introduction to Deep Learning Using HPC date: 2024-06-28-01:51:43Z authors: [abd] type: docs weight: 1 date: 2024-06-28-01:51:43Z\\n\\nmenu: deep-learning-hpc:\\n\\nIn this tutorial, we will be discussing the following topics: * Accessing Deep Learning containers * Hardware Overview * Resource allocation and helpful tools * How to choose a GPU * DL Slurm scripts')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1314 of 1477]\n",
      "Found 1313 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/hardware_overview.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Hardware Overview date: 2024-06-28-01:51:43Z type: docs weight: 250 toc: true menu: deep-learning-hpc:\\n\\nHPC Overview\\n\\n{{< figure src=/notes/deep-learning-hpc/img/RC_HPC.png caption=\"Source: https://www.rc.virginia.edu/userinfo/hpc/#hardware-configuration\" width=55% height=55% >}}\\n\\nPartitions:\\n\\nStandard (no GPUs)\\n\\nLargemem (no GPUs)\\n\\nGPU (compute node with NVIDIA GPU(s))\\n\\nInteractive (compute node with NVIDIA GPU(s))\\n\\nVisit our documentation on HPC hardware configuration for more information.\\n\\nGPU General Overview\\n\\nGraphics Processing Units (GPUs), originally developed for accelerating graphics rendering, can dramatically speed up any simple but highly parallel computational processes (General Purpose GPU).\\n\\nCPU vs. GPU:\\n\\n{{< table >}} | CPU | GPU | | --- | --- | | Several Cores (100-1) | Several Cores (103-4) | | Low Latency | High Throughput | | Generic Workload (Complex & Serial Processing) | Specific Workload (Simple & Highly Parallel) | | Up to 1.5 TB / node on Rivanna | Up to 80 GB /device on Rivanna | {{< /table >}}\\n\\nIntegrated GPU vs Discrete GPUs:\\n\\nIntegrated GPUs are used mostly for graphics rendering and gaming\\n\\nDedicated GPUs are designed for intensive computations\\n\\nVendors and Types:\\n\\nNVIDIA, AMD, Intel\\n\\nDatacenter : K80, P100, V100, A100, H100 (NVIDIA); MI300A, MI300X (AMD)\\n\\nWorkstations: A6000, Quadro (NVIDIA)\\n\\nGaming: GeForce RTX 20xx, 30xx, 40xx (NVIDA), Radeon (AMD)\\n\\nLaptops and desktops: GeForce (NVIDIA), Radeon (AMD), Iris (Intel)\\n\\nProgramming GPUs\\n\\nSeveral libraries and programming models have been developed to program GPUs.\\n\\nCUDA\\n\\nCUDA is a parallel computation platform, developed by NVIDIA, for general-purpose programming on NVIDIA hardware.\\n\\nHIP\\n\\nHIP is a programming interface from AMD that allows developers to target either NVIDIA or AMD hardware.\\n\\nOpenCL\\n\\nOpenCL is a more general parallel computing platform, developed by Apple. It allows software to access CPUs, GPUs, FPGAs, and other devices.\\n\\nSYCL\\n\\nSYCL started as an outgrowth of OpenCL but is now independent of it.\\n\\nKokkos\\n\\nKokkos is another programming model that attempts to be device-independent. It can target multicore programming (OpenMP), CUDA, HIP, and SYCL.\\n\\nMost of these programming paradigms can be used from Python, but nearly all machine learning/deep learning packages are based on CUDA and will only work with NVIDIA GPUs.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1315 of 1477]\n",
      "Found 1314 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/access_dl_containers.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Accessing Deep Learning Containers date: 2024-06-28-01:51:43Z type: docs weight: 100 menu: deep-learning-hpc: toc: true\\n\\nSoftware on HPC is accessed via environment modules or containers.\\n\\nSoftware Module:\\n\\nExamples: R, Rstudio, JupyterLab, TensorFlow, PyTorch\\n\\nFull list of software available on HPC: https://www.rc.virginia.edu/userinfo/hpc/software/complete-list/\\n\\nContainer:\\n\\nContainers bundle an application, the libraries and other executables it may need, and even the data used with the application into portable, self-contained files called images.\\n\\nContainers simplify installation and management of software with complex dependencies and can also be used to package workflows.\\n\\nVisit our documentation on HPC software modules and containers for more information.\\n\\nAccess through Open OnDemand\\n\\n{{< figure src=/notes/deep-learning-hpc/img/OOD_jypnb.png width=70% height=70% >}}\\n\\nClick on the kernel to open a Jupyter Notebook.\\n\\nPackages from the selected kernel will be available for use in the notebook.\\n\\nRun DL Script on the Command Line\\n\\nUse the PyTorch container: bash module load apptainer pytorch apptainer run --nv $CONTAINERDIR/pytorch-2.0.1.sif file_name.py Use the TensorFlow/Keras container: bash module load apptainer tensorflow apptainer run --nv $CONTAINERDIR/tensorflow-2.13.0.sif file_name.py\\n\\nThe --nv flag tells the command to use the GPU\\n\\nThe default command defined in each container is python so using run basically executes python file_name.py\\n\\nCheck Your Knowledge\\n\\nLog in to Rivanna using the Interactive partition using the following parameters.\\n\\n2 hours\\n\\n8 cores\\n\\nAllocation: hpc_training\\n\\nGPU: yes, 1\\n\\nCopy the folder project/hpc_training/dl_with_hpc to your home or scratch account using one of the following: ```bash cp -r /project/hpc_training/dl_with_hpc ~/<...>\\n\\nOR\\n\\ncp -r /project/hpc_training/dl_with_hpc /scratch/')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1316 of 1477]\n",
      "Found 1315 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/gpu_dl.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content=\"title: GPUs for Deep Learning date: 2024-06-28-01:51:43Z type: docs weight: 300 toc: true menu: deep-learning-hpc: parent: Hardware Overview\\n\\nBecause the training process involves hundreds of thousands of computations, we need a form of parallelization to speed up the process.\\n\\nFor instance, ChatGPT's free version (based on GPT-3.5) uses a model with 175 billion parameters,\\n\\nwhereas ChatGPT's paid version (based on GPT-4) uses a model with over 1 trillion parameters\\n\\nAlthough Neural Network calculations are very simple, there are a lot of them!\\n\\nGPUs (graphics processing units) provide the needed parallelization and speed up.\\n\\nDeep Learning using GPUs\\n\\nAll the major deep learning Python libraries (Tensorflow, PyTorch, Keras, etc.) support the use of GPUs and allow users to distribute their code over multiple GPUs.\\n\\nNew GPUs have been developed and optimized specifically for deep learning.\\n\\nScikit-learn does not support GPU processing.\\n\\nDeep learning acceleration is furthered with Tensor Cores in NVIDIA GPUs.\\n\\nTensor Cores accelerate large matrix operations by performing mixed-precision computing. It accelerates math and reduces the memory traffic and consumption.\\n\\nNeural Networks\\n\\nIf you're not using a neural network as your machine learning model you may find that a GPU doesn't improve the computation time.\\n\\nIf you are using a neural network but it is very small then a GPU will not be any faster than a CPU - in fact, it might even be slower.\\n\\nGeneral GPU Workflow\\n\\nThe following is a high-level summary of the general GPU workflow, skipping memory allocations:\\n\\nCreate data on the CPU\\n\\nSend data from the CPU to the GPU (for DL this is done in batches)\\n\\nCompute result on the GPU\\n\\nSend the result back to the CPU\\n\\nDepending on the Deep Learning framework you are using, some of these steps may be automatically done for you.\")]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1317 of 1477]\n",
      "Found 1316 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/need_help.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Need More Help? date: 2024-06-28-01:51:43Z type: docs weight: 1200 toc: true menu: deep-learning-hpc:\\n\\nCheck out the website: https://www.rc.virginia.edu/\\n\\nOffice Hours via Zoom\\n\\nTuesdays: 3 pm - 5 pm\\n\\nThursdays: 10 am - noon\\n\\nZoom Links are available at https://www.rc.virginia.edu/support/\\n\\nVisit the Research Computing Data Analytics Center\\n\\n{{< figure src=/notes/deep-learning-hpc/img/RCDA_Center.png caption=\"https://www.rc.virginia.edu/service/dac/\">}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1318 of 1477]\n",
      "Found 1317 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/deep-learning-hpc/dl_slurm_scripts.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content=\"title: DL Slurm Scripts date: 2024-06-28-01:51:43Z type: docs weight: 900 toc: true menu: deep-learning-hpc:\\n\\nIntroduction to Slurm Scripts\\n\\nHPC environments are generally shared resources among a group of users. In order to manage user jobs, we use Slurm, a resource manager for Linux clusters. This includes deciding which jobs run, when those jobs run, and which node(s) they run on. * A Slurm script gives Slurm the information it needs to run a job (i.e computational resources, necessary software, and command(s) to execute the code file)\\n\\nJobs are submitted to the Slurm controller, which queues them until the system is ready to run them. The controller selects which jobs to run, when to run them, and how to place them on the compute node or nodes, according to a predetermined site policy meant to balance competing user needs and to maximize efficient use of cluster resources\\n\\nMore information about UVA's Slurm Job Manager can be found here.\\n\\nExample Pytorch Slurm Script\\n\\n```bash\\n\\n!/bin/bash\\n\\nSet Up Resources\\n\\nSBATCH -A mygroup # -A: allocation\\n\\nSBATCH -p gpu # -p: partition\\n\\nSBATCH --gres=gpu:1 # --gres=gpu:1 :use 1 gpu\\n\\nSBATCH -c 1 # -c: number of cores\\n\\nSBATCH -t 00:01:00 # -t: time limit\\n\\nSBATCH -J pytorchtest # -J: job name\\n\\nSBATCH -o pytorchtest-%A.out # -o: standard output file (%A is the job #)\\n\\nSBATCH -e pytorchtest-%A.err # -e: standard error file (%A is the job #)\\n\\nmodule purge # Load Software module load apptainer pytorch/2.0.1\\n\\napptainer run --nv $CONTAINERDIR/pytorch-2.0.1.sif pytorch_example.py # Run Code ```\\n\\nExample TensorFlow/Keras Slurm Script\\n\\n```bash\\n\\n!/bin/bash\\n\\nSBATCH -A mygroup\\n\\nSBATCH -p gpu\\n\\nSBATCH --gres=gpu:1\\n\\nSBATCH -c 1\\n\\nSBATCH -t 01:00:00\\n\\nSBATCH -J tftest\\n\\nSBATCH -o tftest-%A.out\\n\\nSBATCH -e tftest-%A.err\\n\\nmodule purge module load apptainer tensorflow/2.13.0\\n\\napptainer run --nv $CONTAINERDIR/tensorflow-2.13.0.sif tf_example.py ```\\n\\nMore Slurm Options\\n\\nTo request a specific amount of memory per node:\\n\\nFor example, --mem=64G\\n\\nUnits are given with a suffix (K, M, G, or T). If no unit is given, megabytes is assumed.\\n\\nOther options available at https://slurm.schedmd.com/sbatch.html\")]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1319 of 1477]\n",
      "Found 1318 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/matlab-optimization/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title : \"Optimization Techniques in MATLAB\" date: 2020-03-03T21:13:14-05:00 type: article\\n\\nThe Optimization Toolbox\\n\\nDefining Optimizations Problems\\n\\nSolving Optimizations Problems\\n\\nNonlinear Programming\\n\\nLinear and Quadratic Programming\\n\\nMixed-Integer Linear Programming\\n\\nMultiobjective Optimization\\n\\nLeast Squares and Equation Solving\\n\\nDocumentations and Resources\\n\\nGlobal Optimization Toolbox\\n\\nSolving Optimizations Problems\\n\\nGlobalSearch and MultiStart\\n\\nSurrogate Optimization\\n\\nPattern Search\\n\\nGenetic Algorithm\\n\\nParticle Swarm\\n\\nSimulated Annealing\\n\\nMultiobjective Optimization\\n\\nDocumentations and Resources\\n\\nParallel Computing and Optimization')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1320 of 1477]\n",
      "Found 1319 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/git-intro/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Version Control with Git\" type: article toc: true date: \"2023-05-01T00:00:00Z\"\\n\\nIntroduction\\n\\nVersion control software provides a systematic way to keep track of changes made to files. There are a number of version control software (VCS) systems ... Git is one of them. It\\'s a powerful tool for tracking and reconciling changes to text files from individual or multiple contributors. The basic unit of Git is the repository. Unlike some other VCS, Git tracks changes by storing snapshots of entire repository at different points in time. This is internally different from \"delta-based\" system that just keeps track of changes to the files. While Git can be used as a standalone piece of software, many people leverage web hosting platforms that expand the VCS functionality and have project management and collaborative features built in. Several examples of these services include Bitbucket, GitLab and GitHub.\\n\\nGitHub\\n\\nAs we mentioned in the introduction, GitHub is a web-based platform for hosting Git repositories. The platform includes a web interface to explore files and perform version control operations, as well as a number of collaboration tools for commenting, opening requests for new features, using project management methods, social networking, creating versions of software releases, and many more. GitHub is an extremely popular service, particularly among software developers and scientists who want to share code as part of \"open source\" projects.\\n\\n1. Log into github.com\\n\\nTo begin with we\\'ll log into github.com\\n\\nIf you haven\\'t already created an account, make sure you follow the steps create one.\\n\\n2. Click the + icon and select \"New repository\"\\n\\n\\n\\n3. Give the repository a name\\n\\nLike the prompt suggests, repository names should be short and memorable. And they must be unique to your account ... i.e. you can\\'t have two repositories in your account with the same name.\\n\\n\\n\\n4. Check the box to \"Initialize this repository with a README\"\\n\\nNew repositories on GitHub require contents to initialize. To get started, we can initialize with a README file, which are typically included in repositories to provide a description of content, usage and / or any necessary software setup.\\n\\n\\n\\n5. Create a new file\\n\\nGitHub provides a file editor in the browser. We\\'re going to make use of that here to demonstrate some basic concepts of version control ... but nb that editing files this way is not a typical workflow, especially if you\\'re storing versions of your code locally (on your computer) and remotely (on GitHub). More on that later ...\\n\\n``` smpl <- rnorm(1000)\\n\\nxbar <- mean(x) s <- sd(x)\\n\\nhist(smpl) ```\\n\\n6. Edit the file\\n\\n``` smpl <- rnorm(1000)\\n\\nxbar <- mean(x) s <- sd(x)\\n\\nhist(smpl) abline(v = xbar, lwd = 2, col = \"red\") abline(v = xbar + 2s, lwd = 2, col = \"red\", lty = 3) abline(v = xbar - 2s, lwd = 2, col = \"red\", lty = 3) ```\\n\\n7. Take a look at the commit history and branch explorer\\n\\n\\n\\nEach change to the repository (or commit) is recorded and tracked separately via a unique combination of characters. This hash is abbreviated in the commit history view, which provides an interface to explore the file(s) and line(s) that were changed as part of the commit.\\n\\nGitHub also provides a view of branches, which you can think of as a collection of commits that can represent an entirely different version of the repository. Ultimately, you can perform a merge operation to combine changes across branches. This can be particularly helpful for collaborations between multiple individuals or for a single developer who would like to keep the \"experimental\" features separate from stable code.\\n\\nAs mentioned above, the fundamental unit of Git is the repository. The steps we\\'ve completed up until now have introduced the basics of creating, committing and tracking changes within a single repository. However, GitHub allows its users to have multiple repositories. In some cases, rather than creating a repository from scratch you might need to fork another user\\'s repository. This workflow can be useful for collaborative projects, as it essentially copies the contents and complete version control history at a single point in time.\\n\\n8. Fork a repository\\n\\nTo illustrate the idea of forking, we\\'ll need to start with an existing repository. For this exercise, we\\'ve created a repository that will include a comma separated value (.csv) file with data on our favorite foods.\\n\\nEach of us will fork this original repository ... and in doing so create new repositories with all the files and previous changes in our accounts.\\n\\nNavigate to https://github.com/uvasomrc/foods and click the Fork button in the upper right-hand corner of the page.\\n\\n\\n\\n9. Make a unique change to an existing file\\n\\nFind the line with your initials in foods.csv, and after the comma enter your favorite food. If you don\\'t find your initials in the list, feel free to add a new line with your initials and favorite food separated by a comma.\\n\\n10. Submit a Pull Request\\n\\nThe pull request mechanism allows contributors to propose changes to the owner of the upstream repository. That owner can review these changes, and conditionally accept or reject them. This process may involve ongoing dialogue and review, during which time the proposed changes can be updated by editing the forked repository.\\n\\nGit (Command Line Interface)\\n\\nThus far we\\'ve managed our version control activities using the GitHub platform, which has a Graphical User Interface (GUI). Git as a program also has a command line interface (CLI), which can be extremely useful whether you\\'re managing repositories locally or remotely. In this part of the workshop we\\'ll cover some common workflows using the Git CLI.\\n\\n1. Fork the quality/ repository\\n\\nTo motivate the Git CLI material, we\\'ve created a repository with an example python script that creates diagnostic plots of read quality scores for sequence data.\\n\\nStart by forking this repository on GitHub:\\n\\nhttps://github.com/uvasomrc/quality\\n\\n2. Confirm that git is installed and configured on your computer\\n\\nNow that you have the repository forked to your GitHub account, we\\'ll clone it locally. To work with Git on your computer, you\\'ll need it installed:\\n\\nhttps://git-scm.com/downloads\\n\\nMac has the Terminal app, and Windows has Git BASH.\\n\\nFrom the command line, confirm that Git is installed by calling it by name followed by the --version flag.\\n\\ngit --version\\n\\nIf the command above returns the version without error, then you have Git successfully installed.\\n\\nThere\\'s one more step to configure the program post-installation. Each commit is associated with an author and email address. To check if you have a globally configured username and email address use the following command:\\n\\ngit config -l\\n\\nIf you don\\'t see anything returned, then you\\'ll need to do the configuration:\\n\\ngit config --global user.name \"{YOUR_NAME_HERE}\"\\n\\ngit config --global user.email {YOUR_EMAIL_ADDRESS_HERE}\\n\\n3. Clone the repository\\n\\nWith Git installed and configured you are now ready to clone the repository contents and commit history to your computer.\\n\\nCloning the repository will create a new folder as a subdirectory of your current working directory. If you\\'re not sure where that is, in your terminal you can print the working directory:\\n\\npwd\\n\\nNavigate back to your repository on GitHub and find the Clone or download button, and click it to expand. Copy and paste the Clone with HTTPS link:\\n\\nhttps://github.com/{YOUR_ACCOUNT_NAME_HERE}/quality\\n\\n\\n\\nUse git clone followed by the link (above):\\n\\ngit clone {CLONE_WITH_HTTPS_LINK_HERE}\\n\\n4. View the log of commits\\n\\nAfter cloning to your computer, you now have a new folder with all the files and version control history from the remote repository. You can navigate to this directory and list all the contents:\\n\\ncd quality\\n\\nls -la\\n\\nAs you can see, on your computer you now have all the files from the remote and something called .git, which is a hidden folder that includes the information that Git uses to track versions of the code.\\n\\nTo access the history of commits (starting at the point in time when you cloned the repository) use the following:\\n\\ngit log\\n\\n5. Check the status\\n\\nAs you work with the code it\\'s good practice to keep an eye on the status of your code base:\\n\\ngit status\\n\\n6. Run qcheck.py\\n\\nAs described above this repository contains code written in python (qcheck.py) ... this script loads sequence data stored in .fastq format and produces some simple diagnostic plots. The data/ folder includes some example files so you can run the script. Keep in mind you\\'ll need python, as well as the biopython and matplotlib modules installed (see README of the quality).\\n\\nWith those requirements satisfied you can execute the script as follows:\\n\\npython qcheck.py data/SRR622461_2.fastq data/SRR622461_2.fastq\\n\\n7. Edit the script and re-run it\\n\\nNow let\\'s edit the script. One parameter we might want to adjust is the number of reads plotted (see line 19 of qcheck.py) ... let\\'s try changing that from 50 to 60:\\n\\nvim qcheck.py\\n\\nRe-run the script:\\n\\npython qcheck.py data/SRR622461_2.fastq data/SRR622461_2.fastq\\n\\n8. Check the status and view the diff\\n\\nThe status of the repo will show us that we have made changes:\\n\\ngit status\\n\\nThe diff command is very useful in seeing the actual changes we\\'ve made:\\n\\ngit diff\\n\\nThe output from diff includes line-by-line additions and subtractions. For more information, refer to the resources\\n\\n9. Stage and commit the change made to qcheck.py\\n\\nLet\\'s presume we want to keep track of the edits to qcheck.py. Before we commit the changes, we need to first add (or stage) them to be committed:\\n\\ngit add qcheck.py\\n\\nCheck the status again and confirm that the edits are staged:\\n\\ngit status\\n\\nNow try using git commit followed by the file name:\\n\\ngit commit qcheck.py\\n\\nOops. That didn\\'t work ... why not?\\n\\nEvery commit requires a message specifying what and why a change was made. You must include a message passed in quotes after the -m flag. While this is technically just a \"subject line\" for the commit (you can write more descriptive message \"bodies\"), in most cases this is sufficient to annotate the changes:\\n\\ngit commit -m \"increased number of reads to be plotted and changed plot file name\"\\n\\nIt is worth noting here that Git users have varied philosophies and practices regarding writing commit messages. For more information, refer to the resources.\\n\\nThe commit we just made is associated with a unique hash, which is an alphanumeric reference for the code at the exact point time when we committed the change(s). You can refer to this hash (or an abbreviation) of it with other Git commands, and you\\'ll see it in the log:\\n\\ngit log\\n\\n10. Synchronize these changes with the repo on GitHub.com\\n\\nGiven that the repository we are working with was originally cloned from GitHub, there is a remote URL associated with the repository:\\n\\ngit remote -v\\n\\nWe can send our changes to the remote repository with a push command followed by the name of the remote (default is origin) and name of branch (default is master):\\n\\ngit push origin master\\n\\nNote that sending the commit(s) we\\'ve made up to the remote GitHub repository requires:\\n\\nAn internet connection\\n\\nAuthentication to GitHub (you need to essentially \"log in\" through the command line)\\n\\nVerification that the GitHub account you are using has permissions to update the remote repository\\n\\nIf you have a SSH (Secure Shell) key set up, you\\'ll see a message saying that the changes have been synchronized on GitHub. If not you\\'ll need to enter your GitHub username and password.\\n\\nYou can persistently associate your computer with your GitHub account (so you don\\'t have to enter your username and password every time) you can set up an SSH key:\\n\\nhttps://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/\\n\\nIf you visit the remote URL, you should see the changes you made to qcheck.py, along with the hash / message associated with your commit.\\n\\nYou may have noticed that not all the files in your quality/ folder on your computer appear on GitHub. For example, the if you look in the plots/ folder on GitHub you won\\'t see the .png files ... and that\\'s intentional.\\n\\nOne of the files we\\'ve included in our repository is a .gitignore file, which serves as a relay to Git regarding what not to track. You can use wildcards (*) to exclude all files that exist in a certain subdirectory, end in a certain suffix, start with a certain prefix, etc.\\n\\nLet\\'s change gear a bit ... we\\'ll still be working with the Git CLI, but rather than starting by cloning a remote repository we\\'re going to instead initialize a new one locally.\\n\\n11. Create and initialize a new Git repository\\n\\nTo create a Git repository we first need a new directory (or folder):\\n\\ncd ..\\n\\nmkdir clock\\n\\ncd clock\\n\\nOnce we\\'ve created the clock/ folder and have changed down into it, we can run git init to initialize the folder as a Git repository:\\n\\ngit init\\n\\nFrom now on, Git will know to look for changes to files inside of clock/.\\n\\n12. Create, add and commit files for the clock\\n\\nWith the repository initialized, we will create two files (README.md and clock.sh) ... start by making empty files using touch:\\n\\ntouch README.md\\n\\ntouch clock.sh\\n\\nIs Git keeping track?\\n\\ngit status\\n\\nNow stage and commit both at once (the . stages all the files that have been changed):\\n\\ngit add .\\n\\ngit commit -m \"adding skeleton of scripts\"\\n\\ngit status\\n\\n13. Edit, add and commit the README file\\n\\nWe have two empty files that we\\'ve committed ... now let\\'s add some content.\\n\\nStart with the README:\\n\\nvim README.md\\n\\n```\\n\\nClock\\n\\nThis repository contains a script that returns the time when executed.\\n\\nUsage\\n\\nbash clock.sh ```\\n\\nNow stage the changes to README.md:\\n\\ngit add README.md\\n\\nAnd commit them:\\n\\ngit commit -m \"adding README with description and instructions\"\\n\\n14. Edit, add and commit the clock script\\n\\nclock.sh will have the actual code for our BASH program:\\n\\nvim clock.sh\\n\\n```\\n\\n!/bin/bash\\n\\nd=$(date \\'+%H:%M:%S\\'); printf \"the time is ...\\\\n$d\\\\n\" ```\\n\\ngit add clock.sh\\n\\ngit commit -m \"added the bash clock script\"\\n\\n15. Sync the local repository with a GitHub remote\\n\\nThe local Git repository we\\'ve just created is entirely independent of GitHub:\\n\\ngit remote -v\\n\\nHowever, we can associate our local repository with GitHub.\\n\\nFirst, we\\'ll need to create a new repository on GitHub. It\\'s probably a good idea to use the same name as your local repo for this.\\n\\nMake sure none of the boxes to \"initialize\" are checked on GitHub\\n\\n\\n\\nNow from the command line, we can add connect the remote we just created to our local Git repository:\\n\\ngit remote add origin https://github.com/{YOURREPONAMEHERE}\\n\\ngit push -u origin master\\n\\nWhether your on a remote or local ... a fork or upstream ... you can further organize and track code in Git with a branch structure.\\n\\n16. Create a new branch\\n\\nA branch is essentially a detour from the code base at a particular commit in history. As it turns out, we\\'ve been actually using a branch already, albeit the default master:\\n\\ngit branch -v\\n\\nTo create a new branch use git checkout with the -b flag followed by the name for the branch:\\n\\ngit checkout -b feature\\n\\nNow if we look at the branches with the -v option, we see that there is now a branch called feature:\\n\\ngit branch -v\\n\\nThe * indicates that we are \"on\" the feature branch, and all of our subsequent commits will be applied until we switch branches again.\\n\\n17. Edit, add and commit the file on the new branch\\n\\nLet\\'s modify our clock program, and add and commit those changes to this branch:\\n\\nvim clock.sh\\n\\n```\\n\\n!/bin/bash\\n\\nd=$(date \\'+%H:%M:%S\\'); printf \"the time is ...\\\\n$d\\\\nhave a nice day\\\\n\" ```\\n\\ngit add clock.sh\\n\\ngit commit -m \"adding new feature to the clock script\"\\n\\n18. Checkoutmaster again\\n\\nChange back to your original branch (master) with the following:\\n\\ngit checkout master\\n\\n19. Make a new edit, then add and commit that change\\n\\nTry modifying the same line on master as we did on feature:\\n\\nvim clock.sh\\n\\n```\\n\\n!/bin/bash\\n\\nd=$(date \\'+%H:%M:%S\\'); printf \"the time is ...\\\\n$d\\\\nhave a nice day!\\\\n\" ```\\n\\nAdd and commit the changes:\\n\\ngit add clock.sh\\n\\ngit commit -m \"adding \\'have a nice day!\\' to the clock\"\\n\\n20. Attempt to merge the changes from the feature branch\\n\\nBranching is helpful in that ultimately you can merge changes from multiple branches into one.\\n\\nBecause we are currently on the master branch, the following will attempt to merge changes from feature into master:\\n\\ngit merge feature\\n\\nHowever, as you see there is a conflict between the two branches. Using a text editor we can view and resolve this conflict:\\n\\nvim clock.sh\\n\\nExercises\\n\\nThe exercises are intended to give you a chance to explore and use the tools discussed in the morning lecture. These exercises introduce new concepts as well, and in doing so point towards various tools and documentation. Feel free to spend as much or as little time with each prompt.\\n\\n1. Learn Git Branching\\n\\nGit branching is an important and sometimes difficult concept to learn. A group of developers has created a very helpful tool for exploring how branches behave.\\n\\nGo through the Learn Git Branching exercises:\\n\\nhttps://learngitbranching.js.org/\\n\\nAlternatively, visit the sandbox to interactively make commits, create branches, merge branches, etc.:\\n\\nhttps://learngitbranching.js.org/?NODEMO\\n\\n2. Good Commit Messages\\n\\nEvery git commit requires an accompanying message. At minimum this should be a single \"subject line\" briefly describing the changes made. However, the commit message can include a \"body\" with more thorough and descriptive notes about how / why the edits were implemented. These comments are particularly useful for a future maintainer or contributor ... and that person might be you! So you can do yourself a huge favor by creating good commit messages.\\n\\nTake some time to read a blog post by developer Chris Beams titled \"How to Write a Git Commit Message\":\\n\\nhttps://chris.beams.io/posts/git-commit/\\n\\nTry making a new commit locally to your quality/ repository. Use a commit message with a body.\\n\\n3. Syncing a Fork\\n\\nWhen you fork a repository, you bring along all the files, commits and associated version control information ... starting from the point in time when it was forked.\\n\\nAs you continue to work on your fork, the upstream repository (from which you originally forked) may or may not be static. The owner or other contributors might modify the contents, creating commits that depart from the tree structure that you are tracking.\\n\\nTo keep up with these changes you must sync the fork:\\n\\nhttps://help.github.com/articles/syncing-a-fork/\\n\\nUse the documentation above to sync your fork of the foods/ repository with the upstream:\\n\\nhttps://github.com/uvasomrc/foods\\n\\n4. Create a conflict\\n\\nThe basic unit of Git is the repository. However, GitHub slightly extends to this concept in its Gist service, which essentially allows users to upload snippets of code without having to track an entire repository.\\n\\nFor this exercise, you\\'ll be working from code hosted in a GitHub Gist:\\n\\nhttps://gist.github.com/JonathanMH/397fc427842614dd4803\\n\\nStart by cloning the Gist:\\n\\nhttps://help.github.com/articles/forking-and-cloning-gists/\\n\\ncreate_conflict.sh is a shell script that demonstrates what happens when there is a conflict in git commits. Try running it on your computer ... and if you\\'re not sure how to do that, Google it!\\n\\nMake sure you are running this script relative to a directory location (folder) that you are comfortable making a new folder called git-repo/ ... feel free to delete this folder after the exercise.\\n\\n5. GitHub Pages\\n\\nIn addition to hosting free public repositories, GitHub also provides a service to host static websites called GitHub Pages:\\n\\nhttps://pages.github.com/\\n\\nFollow the 5 steps on the GitHub Pages website to get started.\\n\\nIf you would like a more advanced example, try forking the following repo:\\n\\nhttps://github.com/onlywei/explain-git-with-d3\\n\\nForking remotely copies an upstream repository from one account to another. Because it is operating on the repository level, the fork inherits all commits and branches. In this case the explain-git-with-d3 repo includes branch named gh-pages. As a service, GitHub.com will host anything that is stored in a gh-pages branch. To access the hosted version of the contents, you can go to https://{USERNAME}.github.io/{REPOSITORYNAME}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1321 of 1477]\n",
      "Found 1320 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/matlab-deep-learning/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Deep Learning with MATLAB\" type: article toc: true date: 2023-12-11T00:00:00-05:00\\n\\n{{< figure library=true src=matlab-logo.png width=30% height=30% >}}\\n\\nIf you are using MATLAB on your desktop computer, make sure you have the Deep Learning Toolbox and Deep Learning Toolbox Model for AlexNet Network installed. You can go to the Add-On Explorer to install these packages.\\n\\nUsing the Sample Dataset\\n\\nTo use the images in the sample dataset, first unzip the folder and add the folder and subfolders to your path. This will make the files visible to MATLAB.\\n\\nYou can then change directory into the DeepLearning folder. This is where we will be working for the remainder of this tutorial.\\n\\n```matlab unzip(\\'DeepLearning.zip\\') addpath(genpath(\\'DeepLearning\\'))\\n\\ncd DeepLearning ```\\n\\nExample 1. Using a Pretrained Network\\n\\nAlexNet\\n\\nAlexNet is a neural network that was developed by Alex Krizhevsky at the University of Toronto in 2012. AlexNet was trained for a week on one million images from 1000 different categories.\\n\\nIn this example we will load AlexNet into MATLAB and use it to classify some images.\\n\\n1. Load AlexNet\\n\\nLoad the pretrained network AlexNet into your MATLAB workspace as a variable net.\\n\\nmatlab net = alexnet;\\n\\n2. Load the image\\n\\nLoad the first sample image into the workspace as a variable img.\\n\\nmatlab img = imread(\\'file1.jpg\\'); Optionally, you can also view the image.\\n\\nmatlab imshow(img)\\n\\n{{< figure src=/notes/matlab-deep-learning/matlab-schnauzer.png >}}\\n\\n3. Resize the image\\n\\nAlexNet was trained on images that are 227 x 227 pixels in size. This means any images we want to classify with AlexNet must also be this size.\\n\\n```matlab % See the size of the image\\n\\nimgSize = size(img)\\n\\n% Resize the image\\n\\nimg = imresize(\\'img\\', [227 227]); imshow(img) ``` {{< figure src=/notes/matlab-deep-learning/matlab-schnauzer-resized.png >}}\\n\\n4. Classify the image\\n\\nThe classify function takes a neural net and an image as inputs and returns a categorical prediction as an output.\\n\\nmatlab pred = classify(net, img);\\n\\nTry classifying the other images in the SampleImages folder. What results do you get?\\n\\nExample 2. Perform Transfer Learning\\n\\nTransfer Learning\\n\\nTransfer Learning is the process of modifying a pretrained neural network to\\n\\nDatastores\\n\\nDatastores are repositories for collections of data that are too large to fit in memory. Instead of storing all the pixel data in memory, datastores allow us to store just the filepaths and to read the image data into memory as needed.\\n\\n1. Create an image datastore\\n\\nCreate an image datastore. We can label these images based on the folders in which they are organized.\\n\\nmatlab imds = imageDatastore(\\'flowers\\', \\'IncludeSubfolders\\', true, \\'LabelSource\\', \\'foldernames\\');\\n\\nWe can preview the first image in our datastore imds.\\n\\nmatlab imshow(preview(imds))\\n\\n{{< figure src=/notes/matlab-deep-learning/matlab-flower.png >}}\\n\\nWe can also inspect the labels of our images by extracting the Labels.\\n\\nmatlab imds.Labels\\n\\n2. Split the data\\n\\nWhen training on new data, we generally want to reserve some of the data for testing. These data will not be used in training so that we don\\'t overfit the network -- that is, so that the network isn\\'t just good at classifying images it\\'s already seen before. The test images will be used to evaluate the network\\'s performance.\\n\\nTypically we want to split our dataset into two subsets: train and test. Usually we use 80% of the data for training and use the remaining 20% for testing.\\n\\nThe splitEachLabel function allows us to divide the data proportionally within each folder/label. By default, splitEachLabel will split the images based on alphabetical order, so we can use the \\'randomized\\' option to randomly assign images to the training and test sets.\\n\\nmatlab [train, test] = splitEachLabel(imds, 0.8, \\'randomized\\');\\n\\n3. Modify layers of AlexNet\\n\\nAlexNet is made of 25 distinct layers. We can inspect these layers by looking at the Layers attribute of net (the variable in which we loaded AlexNet).\\n\\nmatlab layers = net.Layers\\n\\nLayer 1 is the input layer, which is where we feed our images.\\n\\nLayers 2-22 are mostly Convolution, Rectified Linear Unit (ReLU), and Max Pooling layers. This is where feature extraction occurs.\\n\\nLayer 23 is a Fully Connected Layer containing 1000 neurons. This maps the extracted features to each of the 1000 output classes.\\n\\nLayer 24 is a Softmax Layer. This is where a probability is assigned to the input image for each output class.\\n\\nLayer 25 returns the most likely output class of the input image.\\n\\nWhen starting with a pretrained network, we typically want to modify just the last few layers to suit our particular problem. The feature extraction layers will adjust themselves based on the images we are training on -- no need to modify them ourselves!\\n\\nFirst, we want to create a new Fully Connected layer fc with 5 neurons -- one for each of our flower labels. We will then replace the Fully Connected layer in layers with fc.\\n\\nmatlab fc = fullyConnectedLayer(5); layers(23) = fc;\\n\\nWe also want to replace the last layer with a new classification layer.\\n\\nmatlab layers(end) = classificationLayer;\\n\\n4. Set the training options\\n\\nNow we want to train the network with our training data and new layers. Before we begin training, we want to set our training options, or hyperparameters.\\n\\nMore documentation about the different options can be found here.\\n\\nTraining Option Description Solver Name The solver for the training network. MATLAB allows us to use different optimizers: Stochastic Gradient Descent with Momentum sdgm , RMSProp rmsprop , and Adam adam . MiniBatchSize Size of the mini-batch used for each training iteration. Rather than train the network on the whole training set for each iteration, we can train on mini-batches, or subsets of the data. MaxEpochs Number of times the training algorithm passes over the entire training set. Shuffle Optional shuffling of the training data. Shuffling the training data allows you to train over different mini-batches for each epoch. InitialLearnRate This controls how we quickly the network adapts. Larger learning rates mean the network makes bigger adjustments after each iteration. A rate that is too large can cause the network to converge at a suboptimal solution, while a rate that is too small can make the network learn too slowly. Verbose Set to true if you want progress printed to the Command Window. Plots Display training progress plots with the training-progress option.\\n\\nWe can set our desired training options in a variable called options using the trainingOptions function.\\n\\n```matlab options = trainingOptions(\\'sgdm\\', ... \\'MiniBatchSize\\', 10, ... \\'MaxEpochs\\', 2, ... \\'InitialLearnRate\\', 3e-4, ... \\'Shuffle\\', \\'every-epoch\\', ... \\'Verbose\\', false, ... \\'Plots\\', \\'training-progress\\');\\n\\n```\\n\\n5. Train the network\\n\\nNow that we have our options set we can begin training the network on our new dataset. We will call our new neural network flwrnet.\\n\\nWe will use the trainNetwork function to train the network. As inputs, we will use our training dataset train, our modified layers layers, and our training options options.\\n\\nmatlab flwrnet = trainNetwork(train, layers, options);\\n\\nIt will take several minutes to train the network.\\n\\n{{< figure src=/notes/matlab-deep-learning/matlab-training-progress.png >}}\\n\\n6. Evaluating performance\\n\\nAfter training has completed, we can evaluate the performance of the network flwrnet using the reserved test dataset test.\\n\\n```matlab % Classify our test dataset\\n\\npreds = classify(flwrnet, test);\\n\\n% Extract the actual labels of the test dataset\\n\\nactual = test.Labels;\\n\\n% Count the number of predictions that match the actual label\\n\\nnumCorrect = nnz(preds == actual);\\n\\n% Determine the fraction of correct predictions\\n\\nfracCorrect = numCorrect/length(actual) ```\\n\\nWe can also create a Confusion Matrix Chart, which shows us the number of correct predictions for each output class. The confusion matrix also shows us the breakdown of how incorrect predictions were classified.\\n\\nmatlab confusionchart(actual,preds)\\n\\n{{< figure src=/notes/matlab-deep-learning/matlab-confusion-matrix.png >}}\\n\\n7. Improving Performance\\n\\nWith our initial training options, our resulting network has so-so performance. We can try improving the performance by adjusting the training options.\\n\\nMaxEpochs: We can increase the number of epochs over which we train the network. Generally, the longer we train the dataset, the more performance improves.\\n\\nInitialLearnRate: If we set our initial learning rate too high, we can cause the network to converge at a suboptimal solution. To improve performance, you can try dividing your initial learn rate by 10 and retrain the network.\\n\\nMiniBatchSize: You can try adjusting the mini-batch size. Smaller values typically mean faster convergence but more noise in the training process. Larger batch sizes mean more training time but generally less noise.\\n\\nThere are other training options that you can try adjusting that are dependent on the solver you chose. These options can be explored in the MATLAB documentation.\\n\\nYou can also improve performance by testing your network as you are training it; this process is called validation. In addition to setting aside some data for testing after training is complete, we also set aside a validation set. Every few iterations of training, we will classify the images of our validation set and assess the accuracy of the network. This allows us to see how prediction accuracy improves not only on our training data, but also on data the network hasn\\'t seen before. The validation data isn\\'t used to modify any of our network layers--it\\'s just a check to see how training is coming along.\\n\\nExample 3. Build a neural network\\n\\nIn some cases it may make more sense to train a network from scratch. This is particularly true if your dataset is very different from those that were used to train other networks.\\n\\nIn this example we will train a neural network to classify images of numerical digits. This uses images built into the MATLAB Deep Learning Toolbox.\\n\\n{{< figure src=/notes/matlab-deep-learning/matlab-digits.png >}}\\n\\n1. Create an image datastore\\n\\nFirst we will create a datastore containing our images.\\n\\n```matlab % Retrieve the path to the demo dataset\\n\\ndigitDatasetPath = fullfile(matlabroot, \\'toolbox\\',\\'nnet\\',\\'nndemos\\',\\'nndatasets\\',\\'DigitDataset\\');\\n\\n% Create image datastore\\n\\nimds = imageDatastore(digitDatasetPath, \\'IncludeSubfolders\\', true, \\'LabelSource\\', \\'foldernames\\'); ```\\n\\n2. Split the data into training and test datasets\\n\\nmatlabn [train, test] = splitEachLabel(imds, 0.8, \\'randomized\\');\\n\\n3. Define the layers of your network (the network architecture).\\n\\nmatlab layers = [... imageInputLayer([28 28 1]) convolution2dLayer(5,20) reluLayer maxPooling2dLayer(2,\\'Stride\\',2) fullyConnectedLayer(10) softmaxLayer classificationLayer];\\n\\n4. Set your training options.\\n\\nmatlab options = trainingOptions(\\'sgdm\\', ... \\'MaxEpochs\\', 20, ... \\'InitialLearnRate\\', 1e-4, ... \\'Verbose\\', false, ... \\'Plots\\', \\'training-progress\\');\\n\\n5. Train the network\\n\\nmatlab net = trainNetwork(train, layers, options);\\n\\n6. Evaluate performance\\n\\n```matlab preds = classify(net, test);\\n\\nactual = test.Labels;\\n\\nnumCorrect = nnz(preds == actual);\\n\\nfracCorrect = numCorrect/length(actual);\\n\\nconfusionchart(actual, preds) ```')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1322 of 1477]\n",
      "Found 1321 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/rapids/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"RAPIDS\" type: article toc: true date: 2021-11-07T00:00:00-05:00\\n\\nWhat is RAPIDS?\\n\\nRAPIDS is a suite of open source software libraries developed by NVIDIA to accelerate data science pipeline on GPUs. Each component is modeled after its CPU counterpart with minimal code change for the user.\\n\\nComponents\\n\\nComponent CPU API Note cupy NumPy, SciPy Technically not part of RAPIDS cuDF Pandas cuML Scikit-learn cuGraph NetworkX cuSignal SciPy Signal cuSpatial GeoPandas cuxfilter crossfilter\\n\\nWe will focus on the first three components in this introductory workshop. The others are more specialized.\\n\\nPrerequisites\\n\\nNVIDIA GPU with compute capability 6.0+ (Pascal)\\n\\nCUDA 11\\n\\nInstallation\\n\\nThe rapidsai module is available on Rivanna. It is backed by a container based on NVIDIA NGC.\\n\\nTo install on your own machine please visit https://rapids.ai/start.html.\\n\\nUsage\\n\\nJupyterLab\\n\\nSelect the \"RAPIDS x.y\" kernel.\\n\\nCommand line\\n\\nbash module load singularity rapidsai\\n\\nExercises\\n\\nClone https://github.com/rapidsai/notebooks. (The full size is near 1 GB.) We have also prepared a notebook cudf.ipynb under /project/apps_data/rapids.\\n\\nIn cudf.ipynb, compare the performance of pandas and cudf starting from N = 100. Explore the behavior by varying N. Beyond which order of magnitude does cudf outperform pandas?\\n\\nWhich method\\'s relative performance remains fairly constant? In other words, the ratio of the pandas execution time to the cudf execution time does not change much with respect to N.\\n\\nWhich method has the highest performance boost using cudf?\\n\\nRepeat all of the above for other data types.\\n\\nIn cuml/notebook/kmeans_demo.ipynb, compare the performance of scikit-learn and cuml by varying N. Beyond which order of magnitude does cuml outperform scikit-learn?\\n\\nThere is a cell that checks the accuracy of cuml versus scikit-learn. Is this necessary?\\n\\nFeel free to explore other notebooks.\\n\\nGeneral question: Why does the performance of RAPIDS depend on N? Why does the CPU API outperform RAPIDS when N is not big enough?\\n\\nRemark: JupyterLab vs batch job\\n\\nThe JupyterLab environment is interactive which is great for debugging and testing. However, if the queue is busy you may need to wait for a long time. If your code can be executed non-interactively, we recommend converting it into a Python script so that you can submit it as a batch job.\\n\\nConverting a notebook into a Python script\\n\\nThe following command will convert your notebook mynotebook.ipynb into mynotebook.py.\\n\\nbash module load anaconda jupyter nbconvert --to script mynotebook.ipynb\\n\\nYou may need to comment out Jupyter magic commands (e.g. %%time) before converting.\\n\\nBatch job\\n\\nPrepare a SLURM script job.slurm:\\n\\n```bash\\n\\n!/bin/bash\\n\\nSBATCH -A mygroup # your allocation account\\n\\nSBATCH -p gpu # partition\\n\\nSBATCH --gres=gpu:1 # number of GPUs\\n\\nSBATCH -N 1 # number of nodes\\n\\nSBATCH -c 1 # number of cores\\n\\nSBATCH -t 10:00:00 # time\\n\\nmodule purge module load apptainer rapidsai\\n\\nchange x.y to the actual version\\n\\napptainer run --nv $CONTAINERDIR/rapidsai-x.y.sif mynotebook.py ```\\n\\nSubmit the job via sbatch job.slurm.\\n\\nReferences and further reading\\n\\nOfficial documentation\\n\\nWorkshop: High Performance Programming in Python')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1323 of 1477]\n",
      "Found 1322 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/transfer_select_folders.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Getting Ready to Transfer\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3044 menu: globus\\n\\nWe are now ready to initialize our transfer.\\n\\nInstructions\\n\\nSelect the files or folders you want to transfer.\\n\\nSelect the destination for your files.\\n\\nClick the highlighted Start button.\\n\\nNavigate to the folder or files to be transferred on the source (here the personal collection). Chose the files or folders you wish to transfer.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_select_folder.png\" caption=\"Select files or folders to transfer\" width=50% >}}\\n\\nNavigate to the target folder on the destination (here the UVA Standard Security Collection). You may need to move through several levels to find your target folder.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1324 of 1477]\n",
      "Found 1323 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/terminology.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Globus Terminology\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3010\\n\\nmenu: globus:\\n\\nGlobus Terminology\\n\\nCollection: A set of data that is linked to one or more folders on your computer or a remote server.\\n\\nPersonal Collection: A group of folders on a PC or workstation where you installed Globus.\\n\\nPersonal Connector: A program that runs in the background on your computer and allows you to connect to Globus through the Web app.\\n\\nUVA Standard Security Storage: The collection for Research Project and Research Value storage.\\n\\nUVA IVY-DTN: The collection for Ivy Central Storage.\\n\\nShared Collection: A folder that you can share with other Globus users.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1325 of 1477]\n",
      "Found 1324 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/transfer_start.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Start the Transfer\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3048 menu: globus\\n\\nYou can optionally click the transfer options box to set specific parameters for your transfer.\\n\\nBy default, transfers on UVA DTNs are synced (option 1) and encrypted (option 5)  no need to select them.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_transfer_options.png\" width=50% >}}\\n\\nFiles with errors will cause the entire transfer to fail  skip files with errors instead (option 6).\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_transfer_option_skip_files_with_errors.png\" width=50% >}}\\n\\nYou can schedule one-time and regular transfers with Timer.\\n\\nWhen ready, click the blue Start button that points in the appropriate direction. When complete, the new folder will appear in the destination pane.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_completed_transfer.png\" width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1326 of 1477]\n",
      "Found 1325 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/transfer_setup_folders.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Setting Up Source and Destinations\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3043 menu: globus\\n\\nFirst we must assign the source and destination collections.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_search_for_collection.png\" caption=\"Searching for collections\" width=50% >}}\\n\\nStart typing into the Collection textbox. A search bar will appear. Type until you find your personal collection name in the dropdown. A green icon to the left of the name indicates an active collection. Red icons show inactive collections.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_finding_collection.png\" caption=\"Finding your collection\" width=50% >}}\\n\\nDo the same thing for the UVA collection you are targeting. Check again for the green \"stack\" icon for an active collection. In this case we also see a green \"columns\" icon. This indicates the collection is managed.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_uva_standard_security_collection.png\" caption=\"Find the managed collection\" width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1327 of 1477]\n",
      "Found 1326 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/logging_in.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Logging in to Globus\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3015\\n\\nmenu: globus\\n\\nMost activities with globus will require logging in at their Website.\\n\\nInstructions\\n\\nOpen the Globus Website and click Log In\\n\\nChoose \"Use your existing organizational login\"\\n\\nStart typing University of Virginia then select it in the dropdown.\\n\\nLog in using Netbadge\\n\\nStart from the Globus home page:\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_homepage.png\" width=50% >}}\\n\\nLog in with your organization login (Netbadge)\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_login.png\" width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1328 of 1477]\n",
      "Found 1327 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/troubleshooting.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Troubleshooting\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3070 menu: globus\\n\\nSome problems occur frequently. Here are a few tips to solve them:\\n\\n{{< table >}} | Common Issues | Solution | | --- | --- | | I have admin privileges on my Health System computer. Why isnt the Globus installation working? | Sometimes the Health System firewall prevents Globus software from connecting. Ask HIT to remote in and complete the installation. | | Why wont my transfer to Ivy storage start? | Globus doesnt work while connected to the High Security VPN. Disconnect while transferring data. | | Globus is transferring folders but theyre all empty. | There is probably a file with bad permissions or characters in the filename. Choose Skip files with errors in the Transfer options | | I cant connect to UVA Standard Security Storage. | When leaving UVA, your Eservices account can expire before your email  meaning no Globus access. | {{< /table >}}\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_transfer_option_skip_files_with_errors.png\" width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1329 of 1477]\n",
      "Found 1328 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/add_locations.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Adding Folders to the Globus Path\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3030 menu: globus\\n\\nWhen you first set up Globus, it only has access to certain folders of your local drive. You can add additional locations such as mapped network drives or external hard drives in the Globus Options/Preferences menu.\\n\\nInstructions\\n\\nRight-click Globus icon in toolbar\\n\\nClick Preferences (Mac) or Options (Windows)\\n\\nClick the Access tab\\n\\nClick the +\\n\\nSelect the drive location and click Open\\n\\nNavigate to the drive in the File Manager\\n\\n{{< figure src=/notes/globus-data-transfer/imgs/globus_connect_options.png caption=\"Select Options or Preferences from the Globus Connect menu.\" >}}\\n\\n{{< figure src=/notes/globus-data-transfer/imgs/globus_connect_add_location.png caption=\"After clicking the +, navigate to the folder you wish to add.\" >}}\\n\\nTips for Navigating to Mapped Drives\\n\\nClick the Up button in the File Manager to navigate to higher level directories\\n\\nOn a Mac, mapped network drives will typically be located at /Volumes/drive_name\\n\\nIn Windows, network drives will be mapped to a drive letter (e.g., C: or Z:)\\n\\nIn Globus, Z:\\\\Drive_Name\\\\my_files becomes /Z/Drive_Name/my_files')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1330 of 1477]\n",
      "Found 1329 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/installation.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Installing Globus on Your Computer\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3020\\n\\nmenu: globus\\n\\nTo transfer data to and from your computer, you will first need to install Globus Personal Connect. The following links provide instructions for installing Globus Personal Connect based on your machine\\'s operating system.\\n\\n{{< table >}} | Platform | Installation instructions | | --- | --- | | Mac | https://docs.globus.org/how-to/globus-connect-personal-mac | | Linux | https://docs.globus.org/how-to/globus-connect-personal-linux | | Windows | https://docs.globus.org/how-to/globus-connect-personal-windows | {{< /table >}}\\n\\nThe screenshots and set of instructions below show how to navigate to the installation links from the Globus homepage.\\n\\nInstructions\\n\\nGo to https://www.globus.org/\\n\\nClick I Want To > Enable Globus on my system\\n\\nScroll down to Globus Connect Personal (light blue box) and click the Get Globus Connect Personal link\\n\\nScroll down to Install Globus Connect Personal (light blue box)\\n\\nClick the link for your operating system and follow the installation instructions\\n\\nDownload the software for your operating system:\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_download_personal_connector.png\" caption=\"Find the link to download for your operating system\" width=700px >}}\\n\\nInstall the software:\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_install_personal_connector.png\" caption=\"Download the application\" width=700px >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1331 of 1477]\n",
      "Found 1330 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/overview.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Overview of Globus\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3005\\n\\nmenu: globus:\\n\\nGlobus is a non-profit service for secure, reliable research data management developed and operated by the University of Chicago and Argonne National Laboratory, supported by funding from the Department of Energy, NSF, and the NIH. With Globus, subscribers can move, share, & discover data via a single interface  whether your files live on a supercomputer, lab cluster, tape archive, public cloud or your laptop, you can manage this data from anywhere, using your existing identities, via just a web browser.\\n\\nGlobus started as a pure transfer tool with two strengths:\\n\\nFast transfers over good networks\\n\\nRobust transfers over flaky networks\\n\\nGlobus now has the add functionality of:\\n\\nData sharing and flexible access control\\n\\nIdentity management\\n\\nA web GUI, scriptable command line tool, and powerful API')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1332 of 1477]\n",
      "Found 1331 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/transferring_files.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Transferring Files with Globus\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3040 menu: globus\\n\\nFiles are transferred with the Globus File Manager Web App. There are three ways to access the app:\\n\\nGo straight to https://app.globus.org/file-manager\\n\\nGo to https://www.globus.org/ -> Log In (top right corner)\\n\\nClick Globus icon in Toolbar -> Web: Transfer Files\\n\\nThese instructions summarize the steps to set up and start a transfer.\\n\\nClick the Collection field.\\n\\nClick the Your Collections tab.\\n\\nSelect your Personal Collection.\\n\\nClick Transfer or Sync to in the gray menu.\\n\\nClick the second Collection field.\\n\\nSearch for and select UVA Standard Security Storage or UVA IVY-DTN.\\n\\nSelect the files or folders you want to transfer.\\n\\nSelect the destination for your files.\\n\\nClick the highlighted Start button.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1333 of 1477]\n",
      "Found 1332 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/setup.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Setting Up Globus on Your Computer\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3025\\n\\nmenu: globus\\n\\nSet up Globus once it is installed on your computer.\\n\\nInstructions\\n\\nStart the Globus Personal Connector application.\\n\\nChoose a label for consent and click Allow. (The label you choose doesn\\'t really matter.)\\n\\nChoose a name for your Personal Collection. This is the name that you will see in the Globus collections list, so choose something descriptive enough that you know what it is and can quickly find it by searching (e.g. Martinez-Lab-Workstation, Zhang-Personal-Laptop).\\n\\nDo NOT click the High Assurance checkbox! The UVA Ivy Data Transfer Node (UVA IVY-DTN) is already configured for sensitive data transfer. Checking the box is redundant conflicts with the default configuration. The checkbox is not required at all for the Standard Security Storage collection.\\n\\nClick \"Save\" then \"Exit Setup\".\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_setup_personal_connector.png\" caption=\"Setting up the Globus Personal Connector\" width=700px >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1334 of 1477]\n",
      "Found 1333 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Using Globus to Transfer Data\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3000\\n\\nmenu: globus:\\n\\n{{< figure library=\"true\" src=\"globus.png\" width=50% >}}\\n\\nThis tutorial will cover data transfer to and from UVA Research Computing storage systems using Globus software. Topics include: installing Globus, transferring files, monitoring large transfers, and sharing data with collaborators.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1335 of 1477]\n",
      "Found 1334 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/advantages.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Advantages of Using Globus\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3008\\n\\nmenu: globus:\\n\\nGlobus provides a secure, unified interface to your research data. Use Globus to \"fire and forget\" high-performance data transfers between systems within and across organizations.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_advantages.png\" width=50% >}}\\n\\nThere are many advantages to using Globus:\\n\\nThe Globus web app has an easy-to-use point-and-click interface.\\n\\nTransfers faster than SCP/SFTP (usually by a factor of two).\\n\\nGlobus continues interrupted transfers  no need to restart.\\n\\nGlobus allows you to schedule regular transfers.\\n\\nGet email notifications for successful or failed transfers.\\n\\nGlobus accounts are free! Collaborators dont need a sponsored UVA account to use Globus.\\n\\nVPN is not needed to transfer to and from UVA systems.\\n\\nApproved for transferring sensitive data (HIPAA, CUI).\\n\\nVPN or no VPN?\\n\\nUVA Anywhere/More Secure VPN is not necessary for Globus. With just the web app, you can control transfers between systems that have Globus Personal Connect or Server installed.\\n\\nThe VPN will slow down transfers between your computer and Rivanna.\\n\\nThe High Security VPN completely blocks transfers between your computer and secure Ivy storage.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1336 of 1477]\n",
      "Found 1335 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/share.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Sharing Data with Others\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3060\\n\\nmenu: globus\\n\\nGlobus users are able to share data with anyone with a Globus account. All UVA Rivanna and Ivy users have Globus accounts (authenticate with Netbadge).\\n\\nExternal collaborators dont need to be affiliated with an institution using Globus in order for you to share data with them. Anyone can create a personal Globus account using @globusid.org\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_collab.png\" width=50% >}}\\n\\nThe instructions below show how to create a shared endpoint, a folder in which collaborators can upload and download data. Shared endpoints may be public (visible to the world!) or accessible only to users with permission.\\n\\nInstructions\\n\\nSelect the file or folder you want to share.\\n\\nClick the Share button.\\n\\nClick \"Add a Guest Collection.\"\\n\\nEnter a name and description for the Shared Endpoint. This should be unique and easy to remember.\\n\\nClick \"Create Guest Collection\".\\n\\nClick \"Add Permissions Share With\".\\n\\nEnter the UVA or Globus ID of the user you want to share with. Your collaborators must have a Globus ID; email is not sufficient.\\n\\nClick \"Add\" and \"Add Permission\".\\n\\nOptional: Add write permissions so the user can upload data. Enter an email message to the recipient if you wish.\\n\\n{{< figure src=\"/notes/globus-data-transfer/imgs/globus_setup_guest_collection.png\" width=50% >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1337 of 1477]\n",
      "Found 1336 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/globus-data-transfer/monitor.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Monitoring Your Data Transfer\" type: docs toc: true date: 2023-02-02T00:00:00-05:00 weight: 3050\\n\\nmenu: globus\\n\\nBy clicking on the \"Activity\" tab, you can check on the progress of transfers, monitor the effective transfer speed, and look for any failures.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1338 of 1477]\n",
      "Found 1337 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/matlab-image-processing/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Image Processing with MATLAB\" date: 2020-03-03T21:13:14-05:00 type: article toc: True\\n\\n{{< figure library=\"true\" src=\"matlab-logo.png\" width=30% height=30% >}}\\n\\nAs our microscopes, cameras, and medical scanners become more powerful, many of us are acquiring images faster than we can analyze them. MATLAB\\'s Image Processing Toolbox provides interactive tools for performing common preprocessing techniques, as well as a suite of functions for automated batch processing and analysis.\\n\\nReading and Writing Images\\n\\nimread: Read image from a graphics file\\n\\nimwrite: Write image to file\\n\\nimfinfo: Retrieve image information\\n\\nSupported file types: BMP, GIF, JPEG, PNG, TIFF, and more\\n\\nExample 1: Image Read/Write\\n\\n``` clear; clf\\n\\n% Read in image I = imread(\\'peppers.png\\');\\n\\n% Display image and add a title imshow(I); title(\\'RGB Image\\')\\n\\n% Get info about the image imfinfo(\\'peppers.png\\')\\n\\n% Convert RGB image to grayscale gI = rgb2gray(I);\\n\\n% Display new grayscale inage imshow(gI); title(\\'Grayscale Image\\')\\n\\n% Write grayscale image to new file imwrite(gI, \\'peppers_gray.png\\') ```\\n\\nOther Image Types\\n\\nMATLAB can also read DICOM and Nifti files with the dicomread and niftiread functions.\\n\\nImage Tool\\n\\nThe Image Tool imtool allows us to interactively view and adjust images.\\n\\nFunctionality: * View image information\\n\\nInspect pixel values\\n\\nAdjust contrast\\n\\nCrop image\\n\\nMeasure pixel distance\\n\\nExample 2: Playing with the Image Tool\\n\\n``` clear; clf\\n\\nI = imread(\\'colon_cells_1.tif\\');\\n\\nimtool(I) ```\\n\\nDenoising and Filters\\n\\nExample 3: Removing Salt-and-Pepper Noise\\n\\n{{< figure src=\"intro-fiji-16.png\" >}}\\n\\nMean Filter\\n\\n``` clear; clf\\n\\n% Load and display image I = imread(\\'coins.tif\\'); imshow(I)\\n\\n% Apply a mean (or average) filter H = fspecial(\\'average\\', [3 3]); % H is our filter, we are creating a 3x3 mean filter I_mean = imfilter(I, H); % apply the filter imshow(I_mean)\\n\\n```\\n\\nMedian Filter\\n\\nI_median = medfilt2(I, [3 3]); % apply 3x3 median filter imshowpair(I_mean, I_median, \\'montage\\') % show images side-by-side\\n\\nExample 4: Removing Gaussian Noise\\n\\n{{< figure src=\"wiener-filter.png\" >}}\\n\\n``` clear; clf\\n\\n% Load and display image I = imread(\\'planet.png\\'); imshow(I)\\n\\n% Apply Wiener Filter I_wiener = wiener2(I, [5 5]);\\n\\n% Display the original and filtered images imshowpair(I, I_wiener, \\'montage\\') ```\\n\\nAdjusting Image Contrast\\n\\nExample 5: Adjusting Contrast Interactively\\n\\n``` clear; clf\\n\\n% Load the image I = imread(\\'colon_cells_1.tif\\');\\n\\n% View the image in the Image Tool imtool(I) ```\\n\\nUsing the Adjust Contrast Tool\\n\\nClick the Adjust Contrast button in the toolbar (black and white circle).\\n\\nClick and drag to change the bounds of the histogram.\\n\\nOnce satisfied with the contrast, click the \"Adjust Data\" button and close the Adjust Contrast Tool.\\n\\nExport the new image to the workspace. File > Export to Workspace > Enter new variable name (Optional) > OK\\n\\nExample 6: Automated Contrast Enhancement\\n\\nimadjust saturates the bottom 1% and top 1% of pixels.\\n\\n``` I_adj2 = imadjust(I);\\n\\nimshowpair(I, I_adj2, \\'montage\\') ```\\n\\nExample 7: Batch Contrast Enhancement\\n\\n``` clear; clf\\n\\n% A for loop allows us to perform the same operation iteratively for i = 1:6\\n\\n% Specify filename\\nfilename = strcat(\\'colon_cells_\\', num2str(i), \\'.tif\\');\\n\\n% Load file\\nI = imread(filename);\\n\\n% Adjust contrast\\nI_adj = imadjust(I);\\n\\n% Save adjusted image as new file\\nnew_filename = strcat(\\'a_\\', filename);\\nimwrite(I_adj, new_filename)\\n\\nend ```\\n\\nCorrecting Uneven Illumination\\n\\nExample 8: Gaussian Blur and Image Math\\n\\n``` clear; clf\\n\\n% Load the image I = imread(\\'rice.png\\');\\n\\n% Apply Gaussian blur to create background image bg = imgaussfilt(I, 60);\\n\\n% Show image and background imshowpair(I, bg, \\'montage\\')\\n\\n% Subtract background from image I_corr = I - bg;\\n\\n% Show original and corrected images imshowpair(I, I_corr, \\'montage\\')\\n\\n% Write out the corrected image (to be used later) imwrite(I_corr, \\'rice_corr.png\\') ```\\n\\nImage Segmentation\\n\\nExample 9: Detecting and Measuring Circular Objects\\n\\n``` clear; clf\\n\\n% Load the image I = imread(\\'colon_cells_1.tif\\');\\n\\n% Adjust the contrast I_adj = imadjust(I);\\n\\n% Binarize the image I_bw = imbinarize(I_adj);\\n\\n% Determine radius range with imdistline tool imshow(I_bw) d = imdistline; delete(d) % remove the imdistline tool\\n\\n% Find circle centers and radii [centers, radii] = imfindcircles(I_bw, [2 10], \\'ObjectPolarity\\', \\'bright\\');\\n\\n% Display detected circles on image imshow(I_adj) h = viscircles(centers, radii);\\n\\n% Try increasing sensitivity of circle detection [centers, radii] = imfindcircles(I_bw, [2 10], \\'ObjectPolarity\\', \\'bright\\', \\'Sensitivity\\', 0.9);\\n\\nfigure; % opens a new figure window imshow(I_adj) h = viscircles(centers, radii); ```\\n\\nExample 10: Analyzing Foreground Objects\\n\\n``` clear; clf\\n\\n% Load the corrected rice image I = imread(\\'rice_corr.png\\');\\n\\n% Adjust contrast I_adj = imadjust(I);\\n\\n% Binarize the image I_bw = imbinarize(I_adj);\\n\\n% Remove objects that are smaller than 50 pixels (not rice) I_bw = bwareaopen(I_bw, 50); imshow(I_bw)\\n\\n% Fill in holes I_bw = imfill(I_bw, \\'holes\\'); imshow(I_bw)\\n\\n% Identify objects (connected components) in the image cc = bwconncomp(I_bw, 8);\\n\\n% Extract areas of individual grains of rice A = regionprops(cc, \\'Area\\');\\n\\n% Extract mean intensity values meanInt = regionprops(cc, I, \\'MeanIntensity\\'); ```\\n\\nOther properties in regionprops:\\n\\nArea\\n\\nCentroid\\n\\nMajor/Minor Axis Length\\n\\nPerimeter\\n\\nMax/Mean/Min Intensity\\n\\nImage Registration\\n\\nExample 11: Geometric Image Registration\\n\\n``` clear; clf\\n\\n% Load the images and convert to grayscale im1 = rgb2gray(imread(\\'arc-de-triomphe1.jpg\\')); im2 = rgb2gray(imread(\\'arc-de-triomphe2.jpg\\'));\\n\\n% Display image differences figure; imshowpair(im1, im2, \\'falsecolor\\')\\n\\n% Detect features in both images pts1 = detectSURFFeatures(im1); pts2 = detectSURFFeatures(im2);\\n\\n% Extract feature descriptors [features1, validPts1] = extractFeatures(im1, pts1); [features2, validPts2] = extractFeatures(im2, pts2);\\n\\n% Match features using their descriptors indexPairs = matchFeatures(features1, features2);\\n\\n% Retrieve locations of matching points in each image matched1 = validPts1(indexPairs(:,1)); matched2 = validPts2(indexPairs(:,2));\\n\\n% Show point matches figure; showMatchedFeatures(im1, im2, matched1, matched2)\\n\\n% Estimate the transformation that will move Image 2 to Image 1 space [tform, inlier2, inlier1] = estimateGeometricTransform(matched2, matched1, \\'similarity\\');\\n\\n% Use the estimated transform to move Image 2 to Image 1 space outputview = imref2d(size(im1)); % sets world coordinates given # of rows and columns recovered = imwarp(im2, tform, \\'OutputView\\', outputview);\\n\\nfigure; imshowpair(im1, recovered, \\'falsecolor\\')\\n\\n```\\n\\nImage Data Management with OMERO\\n\\nWith the advent of high-throughput screening, the need for efficient image management tools is greater than ever. From the microscope to publication, OMERO is a database solution that handles all your images in a secure central repository. You can view, organize, analyze and share your data from anywhere you have internet access. Work with your images from a desktop app (Windows, Mac or Linux), on UVAs high performance computing platform (Rivanna), from the web, or through 3rd party software like Fiji and ImageJ, Python, and MATLAB. OMERO is able to read over 140 proprietary file formats, including all major microscope formats.\\n\\nExample 12: Image Processing and Analysis with OMERO\\n\\n``` %%%%%%%%%\\n\\n% Sample MATLAB Image Processing pipeline with OMERO\\n\\n%%%%%%%%%\\n\\n%% Log into OMERO\\n\\nmyUsername = \\'\\'; myPassword = \\'\\';\\n\\n%%%%% Don\\'t change anything in this section! %%%%%\\n\\nclient = loadOmero(\\'omero.hpc.virginia.edu\\',4064);\\n\\nsession = client.createSession(myUsername, myPassword);\\n\\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\\n\\n%% Specify the Project and Dataset containing raw data\\n\\nprojectID = 107;\\n\\ndatasetID = 163;\\n\\n%% Each image is processed and analyzed, then exported back to OMERO\\n\\n%%%%% Don\\'t change anything below this line! %%%%%\\n\\ndataset = getDatasets(session, datasetID, true); datasetName = char(dataset.getName().getValue()); imageList = dataset(1).linkedImageList; imageList = imageList.toArray.cell;\\n\\nnewdataset = createDataset(session, \\'binarized\\', ... getProjects(session,projectID));\\n\\nfor i = 1:length(imageList) pixels = imageList{i}.getPrimaryPixels(); name = char(imageList{i}.getName().getValue()); store = session.createRawPixelsStore(); store.setPixelsId(pixels.getId().getValue(),false); plane = store.getPlane(0,0,0); img = uint8(toMatrix(plane,pixels));\\n\\ntype = \\'uint8\\';\\n\\nnewimg = uint8(contrastIncrease(img));\\nnewimg = uint8(binarizeImage(newimg));\\nnewname = strcat(\\'b_\\',name);\\n\\npixelsService = session.getPixelsService();\\npixelTypes = toMatlabList(session.getTypesService().allEnumerations(\\'omero.model.PixelsType\\'));\\npixelTypeValues = arrayfun(@(x) char(x.getValue().getValue()),pixelTypes,\\'Unif\\',false);\\npixelType = pixelTypes(strcmp(pixelTypeValues, type));\\n\\ndescription = sprintf(\\'Dimensions: 512 x 512 x 1 x 1 x 1\\');\\n\\nidNew = pixelsService.createImage(512,512,1,1,toJavaList(0:0,\\'java.lang.Integer\\'),pixelType,newname,description);\\n\\nimageNew = getImages(session, idNew.getValue());\\n\\nlink = omero.model.DatasetImageLinkI;\\nlink.setChild(omero.model.ImageI(idNew,false));\\nlink.setParent(omero.model.DatasetI(newdataset.getId().getValue(),false));\\nsession.getUpdateService().saveAndReturnObject(link);\\n\\npixels = imageNew.getPrimaryPixels();\\nstore = session.createRawPixelsStore();\\nstore.setPixelsId(pixels.getId().getValue(),false);\\nbyteArray = toByteArray(newimg, pixels);\\n\\nstore.setPlane(byteArray,0,0,0);\\nstore.save();\\nstore.close();\\n\\ncc = bwconncomp(newimg,4);\\nnumCells = num2str(cc.NumObjects);\\n\\nmapAnnotation = writeMapAnnotation(session,\\'Count\\',numCells);\\n\\nlink = linkAnnotation(session, mapAnnotation, \\'image\\', idNew.getValue());\\n\\nend\\n\\nclient.closeSession();\\n\\nfunction I3 = contrastIncrease(image)\\n\\nI = image;\\nbackground = imopen(I,strel(\\'disk\\',15));\\n\\nI2 = I - background;\\n\\nI3 = imadjust(I2);\\n\\nend\\n\\nfunction bw = binarizeImage(image)\\n\\nbw = imbinarize(image);\\nbw = bwareaopen(bw, 10)*255;\\n\\nend\\n\\n```')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1339 of 1477]\n",
      "Found 1338 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/rio-intro/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Introduction to Rio\" date: \"2025-01-30T00:00:00\" authors: [as, pbo, Camden Duy]\\n\\n{{< slideshow folder=\"slides/rio-intro\" ext=\"jpg\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1340 of 1477]\n",
      "Found 1339 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/wrapup.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Getting Help date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 500\\n\\nmenu: hpc-intro: name: Getting Help\\n\\nIf you have questions you can visit one of our online office hours Zoom sessions. Click on the \"Join us via Zoom\" button when a session is open. Current hours are\\n\\nTuesdays: 3 pm  5 pm\\n\\nThursdays: 10 am  noon\\n\\nFor specific help you can submit a ticket (this may open Netbadge).\\n\\n')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1341 of 1477]\n",
      "Found 1340 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Course title, summary, and position.\\n\\nauthors: [jmh,kah,pbo]\\n\\nPage metadata.\\n\\ndate: \"2021-04-13T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 1\\n\\nAdd menu entry to sidebar.\\n\\nmenu: hpc-intro: name: Introduction to High Performance Computing\\n\\nUVA\\'s primary resource for high-performance computing provides a platform for computationally-intensive research across a variety of disciplines.\\n\\n{{< figure src=\"/notes/hpc-intro/img/rivanna_racks.png\" caption=\"UVA\\'s HPC cluster\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1342 of 1477]\n",
      "Found 1341 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_terminology.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Terminology date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 4\\n\\nmenu: hpc-intro: name: Overview of UVA HPC\\n\\nNode\\n\\nA node is the basic building block of a cluster.\\n\\nNodes are a type of computer called a server.\\n\\nThey generally have more power than a typical computer.\\n\\nThey may have specialty hardware like graphical processing units.\\n\\nTwo types of nodes\\n\\nHead Node  a server used for logging in and submitting jobs.\\n\\nCompute Node -- a server that carries out the computational work.\\n\\nCore  an individual processor on a computer\\n\\nThe cluster\\'s nodes have many cores (typically 40 each)\\n\\nMemory\\n\\nThe random-access memory on a node\\n\\nStorage\\n\\nDisk storage visible from a node')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1343 of 1477]\n",
      "Found 1342 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_allocations.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Allocations and Accounts date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 10\\n\\nmenu: hpc-intro: parent: Overview of UVA HPC\\n\\nTime on the HPC cluster is allocated.\\n\\nAn allocation refers to a block of CPU time that you can use to run your computations.\\n\\nOnly faculty may request an allocation. Research staff may apply for an exception.\\n\\nStudents must be sponsored by a faculty or research staff.\\n\\nAll individuals on a given allocation share the service units.\\n\\nAllocations may be requested at https://www.rc.virginia.edu/userinfo/rivanna/allocations/\\n\\nAllocations are measured in service units (SUs), where 1 SU = 1 core-hour in most cases. Nodes equipped with GPUs may charge more than one SU per core-hour.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1344 of 1477]\n",
      "Found 1343 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_storage.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Storage date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 50\\n\\nmenu: hpc-intro: parent: Overview of UVA HPC\\n\\nActive users can access free storage for active work. Research groups that need more permanent storage, or wish to share storage space, can also lease storage.\\n\\nNo-Cost Storage\\n\\nEach user has access to a home directory and a scratch directory.\\n\\nHome Directory\\n\\nWhen you log in, you will be in your home directory, e.g. /home/mst3k. Each home directory on has 200GB of storage capacity. The home directory is for individual use and is not shareable with other users.\\n\\nScratch Directory\\n\\nYou have access to 10 TB of temporary storage. It is located in a subdirectory under /scratch, followed by your userID, e.g., /scratch/mst3k\\n\\nThe /scratch directory is for individual use and is not shareable with other users.\\n\\n{{< warning >}} /scratch is NOT permanent storage and files that have not been accessed for more than 90 days will be marked for deletion. {{< /warning >}}\\n\\nLeased Storage\\n\\nWe offer two tiers of leased storage. For rates and offerings see our website.\\n\\nResearch Standard Storage\\n\\nStandard storage is inexpensive but is not backed up, and access can be slow.\\n\\nResearch Project Storage\\n\\nResearch project storage provides snapshots. Snapshots are not backups, but are a \"snapshot\" of the files over a time interval in the past, currently one week.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1345 of 1477]\n",
      "Found 1344 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_system_specs.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: System Specifications date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 40\\n\\nmenu: hpc-intro: parent: Overview of UVA HPC\\n\\nCurrently the supercomputer is made up of two systems, Rivanna and Afton, and between the two has 626 nodes with over 20448 cores and 8PB of various storage.\\n\\nSeveral queues (or partitions) are available to users for different types of jobs. One queue is restricted to single-node (serial or threaded) jobs; another for multi-node parallel programs, and others are for access to specialty hardware such as large-memory nodes or nodes offering GPUs.\\n\\nMore information on queueing policies and hardware configurations can be found on our website.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1346 of 1477]\n",
      "Found 1345 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_getting_allocation.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Getting an Allocation date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify.\\n\\nmenu: hpc-intro: parent: Overview of UVA HPC weight: 20\\n\\n{{< figure src=\"/notes/hpc-intro/img/allocation_schematic.png\" caption=\"Requesting an Allocation\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1347 of 1477]\n",
      "Found 1346 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/overview_of_uva_hpc/overview_accounts.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Login Accounts date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 30\\n\\nmenu: hpc-intro: parent: Overview of UVA HPC\\n\\nAllocations and Groups\\n\\nAn allocation is associated with a group. Currently this is a Grouper group.\\n\\nMembers (but not administrators) of the allocation group automatically receive an account on the system.\\n\\nRC staff do not manage allocation groups. The PI is responsible for adding and removing group members.\\n\\nThe PI may designate administrators and delegate the task of managing the group to them.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1348 of 1477]\n",
      "Found 1347 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Working with Files date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 400\\n\\nmenu: hpc-intro: name: Working with Files\\n\\nFiles are the foundation of working with an HPC cluster. We need to be able to\\n\\nTransfer files to and from the cluster\\n\\nEdit text files\\n\\nCreate files through the software we run\\n\\nEach user has a home location and a scratch location. When you log in you will be in the home location. For now we will assume you will work with files in your home folder. We will discuss the scratch folder later.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1349 of 1477]\n",
      "Found 1348 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_exercise3.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Exercise (Job Submission)\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 495\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nNow that we have covered the basics of OOD interactive apps, OOD functionality, and how to work with files, we will now put everything together to create a unique job submission script and run it through the job composer on OOD. In this example we will write a simple \\'Hello World!\\' python script and a submission script to be run with the OOD job composer.\\n\\nYou\\'ll need to create two files in your Desktop (/home/computingID/Desktop): hello.py and hello.slurm. You can use any text editor of your choice: FastX editors (pluma, gedit, etc.) or the OOD file editor. In hello.py add the following lines:\\n\\n```\\n\\nWrite hello 10 times\\n\\nfor i in range(10):\\n\\nprint (\"\\\\n {} Hello World!\".format(i+1))\\n\\nprint(\"\\\\n\\\\n\") ```\\n\\nNext, we will need a submission script to submit this code to run on a compute node. Open hello.slurm and add the following:\\n\\n```\\n\\n!/bin/bash\\n\\nSBATCH --cpus-per-task=1\\n\\nSBATCH --mem=6000\\n\\nSBATCH --time=00:05:00\\n\\nSBATCH --partition=standard\\n\\nSBATCH --account=your_allocation\\n\\nmodule purge module load miniforge python hello.py ```\\n\\nBe sure to replace your_allocation with the name of the allocation you have access to.\\n\\nOnce these two files are created, you can use the job composer on OOD to submit hello.slurm to a compute node to run the python code.\\n\\nOnce the job has completed, you should see a slurm-jobID.out file in your Desktop. View the file and make sure its contents are what you expect.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1350 of 1477]\n",
      "Found 1349 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_globus.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Transferring with Globus\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 460\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nGlobus\\n\\nGlobus is a non-profit service for secure, reliable research data management developed and operated by the University of Chicago and Argonne National Laboratory, supported by funding from the Department of Energy, NSF, and the NIH. With Globus, subscribers can move, share, & discover data via a single interface  whether your files live on a supercomputer, lab cluster, tape archive, public cloud or your laptop, you can manage this data from anywhere, using your existing identities, via just a web browser.\\n\\n{{< figure src=\"/notes/hpc-intro/img/globus.png\" >}}\\n\\nAdvantages of Using Globus\\n\\nGlobus provides a secure, unified interface to your research data. Use Globus to \"fire and forget\" high-performance data transfers between systems within and across organizations.\\n\\nInstalling Globus\\n\\nTo transfer data to and from your computer, you will first need to install Globus Personal Connect. The following links provide instructions for installing Globus Personal Connect based on your machine\\'s operating system.\\n\\nPlatform Installation instructions Mac https://docs.globus.org/how-to/globus-connect-personal-mac Linux https://docs.globus.org/how-to/globus-connect-personal-linux Windows https://docs.globus.org/how-to/globus-connect-personal-windows\\n\\nTransferring Files\\n\\nFiles are transferred with the Globus File Manager Web App. There are three ways to get to the app:\\n\\nGo straight to https://app.globus.org/file-manager\\n\\nGo to https://www.globus.org/ > Log In (top right corner)\\n\\nClick Globus icon in Toolbar > Web: Transfer Files\\n\\nOnce the app is open you can choose collections to transfer data between.\\n\\nSharing Data with Collaborators\\n\\nGlobus users are able to share data with anyone with a Globus account. All UVA HPC and Ivy users have Globus accounts (authenticate with Netbadge).\\n\\nExternal collaborators dont need to be affiliated with an institution using Globus in order to share data with them. Anyone can create a Globus account using @globusid.org\\n\\nMore information on using Globus can be found on our learning website and from our documentation.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1351 of 1477]\n",
      "Found 1350 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_paths.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: File Paths date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 420\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nEvery file has a full name called its path. The path provides the operating system with the exact location of the file, relative to some starting point.\\n\\nExamples: * Windows C:\\\\Users\\\\mst3k\\\\Desktop\\\\mystuff.txt * Mac OS /Users/mst3k/Desktop/mystuff.txt * Linux (usually) /home/mst3k/Desktop/mystuff.txt\\n\\nThese paths traverse through some folders, which in Linux are often called directories, to arrive at the file mystuff.txt')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1352 of 1477]\n",
      "Found 1351 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_actions_create_delete.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Creating and Deleting Files date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 470\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nThere are three quick ways to work with files.\\n\\nThe Open OnDemand File Explorer.\\n\\nIf logged in through FastX, you can use the \"Caja\" file manager. It can be accessed through the filing-cabinet icon in the ribbon at the top, or via the Applications->System Tools menu. Caja works very similarly to Windows Explorer and the Mac Finder, but is somewhat more limited. It should be simple to use. The Open OnDemand file manager shows only one location at a time, whereas Caja, like Explorer or Finder, can open multiple windows. Note: you will not be allowed to do anything as \"Administrator.\"\\n\\n{{< info >}} In Open OnDemand and Caja, rather than trying to navigate to your /scratch directory, use Go To (OOD) or Go->Location (Caja) and type the path /scratch/mst3k, using your own ID rather than mst3k. {{< /info >}}\\n\\nCreating Files and Folders\\n\\nOpen OnDemand: click the New File (file) or New Dir (folder) button and provide the name. You may also provide a path.\\n\\nIn FastX with Caja: For a new file go to the File->Create Document menu. For a folder use File->Create Folder.\\n\\nIn FastX you can use an editor such as pluma, which is accessible through the Applications->Accessories menu, using its File->New menu item. You can then use the editor to add content to the file.\\n\\nDeleting Files and Folders\\n\\nIn the Open OnDemand File Explorer, select the file or folder, then click the red Delete button. It will request confirmation.\\n\\nIn the \"Caja\" file manager on FastX, right-click and Delete. Since the space in your home directory is limited, we recommend not moving to Trash.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1353 of 1477]\n",
      "Found 1352 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_filezilla.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Transferring with Graphical Clients: macOS and Linux\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 440\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nFilezilla\\n\\nThis illustration is from a Linux computer. macOS is similar.\\n\\nFirst click the Site Manager icon in the upper left.\\n\\n{{< figure src=\"/notes/hpc-intro/img/Filezilla_ribbon.png\" caption=\"Site Manager\" >}}\\n\\nSelect New Site. Rename it. Fill in the text boxes and dropdown. Be sure to select SFTP in the Protocol box. As for MobaXTerm, we recommend using a specific host name such login.hpc.virginia.edu. Click OK to save and Connect to initiate the connection. A multiple-pane window similar to that of MobaXTerm will open.\\n\\n{{< figure src=\"/notes/hpc-intro/img/Filezilla_settings.png\" caption=\"Site Manager\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1354 of 1477]\n",
      "Found 1353 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_moba.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Transferring with Graphical Clients: Windows\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 450\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nMobaXterm\\n\\nStart an SFTP session in MobaXterm. Use one of the specific hosts login1.hpc.virginia.edu, login2.hpc.virginia.edu, login3.hpc.virginia.edu\\n\\n{{< figure src=\"/notes/hpc-intro/img/Moba_sftp_session.png\" caption=\"New SFTP session in MobaXTerm\" >}}\\n\\nA double-paned window will open. Drag and drop files between your local machine and the remote server.\\n\\n{{< figure src=\"/notes/hpc-intro/img/Moba_sftp_pane.png\" caption=\"Drag and drop\" width=1000px >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1355 of 1477]\n",
      "Found 1354 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_paths_linux.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Paths in Linux date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 410\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nUVA HPC runs the Linux operating system. File paths start from root, denoted with a forward slash (/). The layout of the folders/directories is like an upside-down tree.\\n\\n{{< figure src=\"/notes/hpc-intro/img/unix_tree.png\" caption=\"Schematic of folders on Rivanna. Only some files and folders shown.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1356 of 1477]\n",
      "Found 1355 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_editing.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Editing Files date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 490\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nOnce we have our files on the system, we may need to edit them. It is a good idea to edit your files directly on the system, rather than editing on your local computer and then transferring them back and forth.\\n\\nYou can create files by the same process as editing an existing one; just select New if there is a menu.\\n\\nYou can use: * The built-in editor in Open OnDemand. Click on Files on the Dashboard, highlight the file that you want to edit. From the dropdown menu next to the file name, select Edit. A simple editor will open. To create a file, navigate to the desired location, click the New File button, then edit that file. * If logged in through FastX, you can use the pluma editor, which is accessible through the Applications->Accessories menu. You can also start it from a terminal with either its name pluma or as gedit (those are the same program). * The MATE desktop in FastX also provides the semi-graphical editors Emacs and GVim in the same menu. * In FastX, you can also use a programmer\\'s interface such as VSCode, Spyder, or Rstudio. For extensive editing or running programs through environments such as VSCode, use the Open OnDemand interactive app.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1357 of 1477]\n",
      "Found 1356 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_actions_mv_cp.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Copy, Rename, and Move Files date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 480\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nRenaming Files and Folders\\n\\nIn the Open OnDemand File Explorer, click on Files on the Dashboard and click the file or folder you want to rename. Find the menu (three vertical dots) to the right of the file name. Click Rename.\\n\\nIn the \"Caja\" file manager on FastX, select the file or folder. The combination of clicking on the icon and hitting the F2 key, should work on most keyboards as it does for Windows. You can also right-click and choose Rename.\\n\\nMoving Files and Folders\\n\\nIn the Open OnDemand File Explorer, use the Copy/Move button in the upper right. Select the file or folder you wish to move. A dialog will open. In your navigation pane, go to the target folder. Click Copy in the dialog on the left.\\n\\nIn the \"Caja\" file manager on FastX, if moving within the same parent folder, just drag the file or folder to the new location. If moving between folders that do not share a parent, open another Caja window. Cut the file or folder and paste to its new location.\\n\\nCopying Files and Folders\\n\\nIn the Open OnDemand File Explorer, use the Copy/Move button, but click on Copy rather than Move.\\n\\nIn the \"Caja\" file manager on FastX, open another Caja window and drag the icon of the file or folder between them. Alternatively right-click and use the copy and paste menu items.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1358 of 1477]\n",
      "Found 1357 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/files/file_up_down.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Transferring Files date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 430\\n\\nmenu: hpc-intro: parent: Working with Files\\n\\nYou have several options for transferring data onto your home or scratch directories.\\n\\nUse a drag-and-drop option with MobaXterm (Windows) or Filezilla (Mac OS and Linux).\\n\\nFor small files, use the Upload and Download buttons in the Open OnDemand FileExplorer App.\\n\\nUse the scp command from a Terminal.\\n\\nUse the web browser in the FastX desktop to download data from UVA Box or other cloud locations.\\n\\nUse the git clone command to copy git repositories\\n\\nSet up a Globus endpoint on your laptop and use the Globus web interface to transfer files. See https://www.rc.virginia.edu/userinfo/globus/ for details.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1359 of 1477]\n",
      "Found 1358 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_job_viewer.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The OOD Job Viewer date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 240\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nOpen OnDemand allows you to check the status of your jobs easily. Open the Jobs tab and go to Active Jobs. The default view is All Jobs.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_squeue_viewer.png\" caption=\"Job status viewer in OOD.\" >}}\\n\\nYou can filter to select subsets of the jobs, for example you can view only jobs in the gpu partition.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_squeue_filter.png\" caption=\"Viewing only the GPU partition.\" >}}\\n\\nYou can also look at the status of only your own jobs by switching from All Jobs to My Jobs.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_squeue_myjobs.png\" caption=\"Viewing only my jobs.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1360 of 1477]\n",
      "Found 1359 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_jobs_tab.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Jobs on OOD date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 220\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nThe \"Jobs\" tab on the menu bar allows you to submit and search for jobs on the cluster.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_jobs_tab.png\" caption=\"OOD Jobs Menu\" >}}\\n\\nThe \"Active Jobs\" tab shows all jobs currently running or queues on all partitions for all users. The Filter search bar allows you to narrow jobs by either user, queue, job name, job ID, or job status (running, queued, completed, etc).')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1361 of 1477]\n",
      "Found 1360 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_shell_access.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: HPC Shell Access date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 260\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nThe \"Clusters\" tab on the menu bar open a new browser tab with a Linux command line interface for shell access:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_shell_access.png\" caption=\"Command line Shell Access\" >}}\\n\\nTo get a feel of how to use the command line, type the command allocations after the $ prompt to display information on your allocations.\\n\\nThis is a suitable method to access the cluster through command line without connecting to the UVA VPN.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1362 of 1477]\n",
      "Found 1361 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Features of Open OnDemand date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 200\\n\\nAdd menu entry to sidebar.\\n\\nmenu: hpc-intro: name: Features of Open OnDemand\\n\\nOpen OnDemand has many features accessible directly from the menu bar.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_File_Menu.png\" caption=\"Open OnDemand Menu Options\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1363 of 1477]\n",
      "Found 1362 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_exercise2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Exercise (Open OnDemand)\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 290\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nStart an Open OnDemand File Explorer tab. In your home directory, create a new file. Use the Editor to enter the following text:\\n\\nI came in with Halley\\'s Comet in 1835. It is coming again next year, and I expect to go out with it. It will be the greatest disappointment of my life if I don\\'t go out with Halley\\'s Comet. The Almighty has said, no doubt: \"Now here are these two unaccountable freaks; they came in together, they must go out together.\"\\n\\nMark Twain\\n\\nName the file whatever you wish. Make a new folder \"Quotes.\" Move the file to this directory.\\n\\nGo to the FastX desktop and open Caja (the filing-cabinet icon, or from the System Tools menu). Navigate to your new directory. Change the name of the file. Use whatever method you prefer (right-click or F2 key). Still in Caja, copy the file. Give the copy the original name you choose. Move it to your Desktop.\\n\\nReturn to your Desktop in OOD and delete the file there.\\n\\nOn FastX, return to the Quotes directory. Open the file with Pluma, and after \"Mark Twain\" add \", 1909\".')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1364 of 1477]\n",
      "Found 1363 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_job_composer.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Job Composer date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 230\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nThe job composer tab allows you to create and submit a job to run on the cluster.\\n\\n{{< figure src=\"/notes/hpc-intro/img/Features_job_composer.png\" caption=\"OOD Job Composer\" >}}\\n\\nSelecting the default template will automatically create a submission script called demo_hello_world.slurm located in /home/computingID/Rivanna/data/sys/myjobs/projects/default/1 on the file system:\\n\\n{{< figure src=\"/notes/hpc-intro/img/featues_template_job.png\" caption=\"Default Template Job\" >}}\\n\\nBefore submitting the job, your_allocation on the #SBATCH --account=your_allocation line must be replaced with the name of the allocation you\\'re a member of. We will review editing files later. Once the correct allocation name is edited in, you can click \"Submit\" to queue your job. It will be given a corresponding Job ID, and once it\\'s completed, the Folder contents will now contain a corresponding output file that contains the instructions from the submission script:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_job_output.png\" caption=\"Default Template Output\" >}}\\n\\nThere are several job templates that can be run in addition to the default hello world option under New Job > From Template:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_templates.png\" caption=\"Template Options\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1365 of 1477]\n",
      "Found 1364 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_interactive_sessions.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Interactive Sessions date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 270\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nThis tab will show you running, pending or completed interactive sessions from the OOD interface.\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_interactive.png\" caption=\"Interactive Sessions\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1366 of 1477]\n",
      "Found 1365 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_files_tab.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Accessing Files on OOD date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 210\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nThe \"Files\" tab on the menu bar gives access to all files in home, scratch, standard or project (if applicable) directories.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_files_tab.png\" caption=\"OOD Files Menu\" >}}\\n\\nHere, you can upload and download small files to and from the cluster from your local computer. You can also create and delete new files and directories in addition to copying or renaming them. The Filter search bar searches for files or directories in the file system.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1367 of 1477]\n",
      "Found 1366 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_useful_commands.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Useful Commands date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 280\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nSometimes it\\'s useful to check how many SUs are still available on your allocation. The allocations command displays information on your allocations and how many SUs are associated with them:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_allocations.png\" caption=\"Allocations\" >}}\\n\\nrunning allocations -a <allocation_name> provides even more detail on when the allocation was last renewed and its members.\\n\\nOne way to check your storage utilization is with the hdquota command. This command will show you how much of your home, scratch, and project (if applicable) storage are being utilized. Below is the sample output for hdquota:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_hdquota.png\" caption=\"Disk Usage\" >}}\\n\\nThis is a useful command to check whether you\\'re running out of storage space or to see where files need to be cleaned up. For more detailed information on disk utilization you may also use the du command to investigate specific directories.\\n\\nTo gain information on the different queues you can type qlist on the command line:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_qlist.png\" caption=\"Queues\" >}}\\n\\nThis will show the list of partitions, their occupancy, and the SU charge rate. You can type qlimits for information on each queue\\'s limits:\\n\\n{{< figure src=\"/notes/hpc-intro/img/features_qlimits.png\" caption=\"Queue Limits\" >}}\\n\\nFinally, the sinfo command will provide some more detailed information on the health of each queue and the number of active nodes available. These commands can be useful in diagnosing why a job may not be running, or in better understanding queue usage for more efficient job throughput. More information on hardware specifications and queue information can be found on our website.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1368 of 1477]\n",
      "Found 1367 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/features_of_ood/features_job_stats.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Getting Job Details date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 250\\n\\nmenu: hpc-intro: parent: Features of Open OnDemand\\n\\nIn the OOD Job Viewer, clicking on the right arrow for a particular job will show details of the job if it is queued or running. Completed jobs will have no information available. Be patient as it can take a few moments for the information to be loaded. In this illustration the selected job is PENDING. The reason given is Resources, which means that no resources are available yet for this job.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_job_status.png\" caption=\"Viewing only my jobs.\" >}}\\n\\nCompleted jobs will be visible only for a short while as they are wrapping up and exiting.\\n\\nIf an error occurs, try reloading the page.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1369 of 1477]\n",
      "Found 1368 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_apps.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The OOD Interactive Apps Menu date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 310\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nTo submit an interactive job, from the Open OnDemand dashboard click on the menu Interactive Apps for the dropdown list.\\n\\nWe will focus on JupyterLab, Rstudio Server, and the Desktop for now.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Interactive_Apps.png\" caption=\"OOD Interactive Apps menu\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1370 of 1477]\n",
      "Found 1369 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Interactive Apps with Open OnDemand date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 300\\n\\nmenu: hpc-intro: name: Interactive Apps with Open OnDemand\\n\\nOpen OnDemand\\'s File Explorer, the FastX Web interface, and various command-line interfaces, can be used to prepare work for the cluster. This includes transferring and editing files, looking at output, and so forth. However, all production work must be run on the compute nodes, not on the frontends.\\n\\nA large, multi-user system like UVA\\'s HPC cluster must be managed by some form of resource manager to ensure equitable access for all users. Research Computing uses the Slurm resource manager. Resource managers are also often called queueing systems. Users submit jobs to the queueing system. A process called a scheduler examines the resource requests in each job and assigns a priority. The job then waits in a queue, which Slurm calls a partition, until the requested resource becomes available. A partition is a set of compute nodes with a particular set of resources and limits. There are partitions for single-node jobs, multiple-node jobs, GPU jobs, and some other dedicated partitions. A list of the different queues and resources are listed here.\\n\\nOpen OnDemand offers an easy way to run interactive jobs. With an interactive job, you are logged in directly to a compute node and can work as if it were a frontend. Please keep in mind that an interactive job terminates when the time limit you specify expires, unless you explicitly end the session.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1371 of 1477]\n",
      "Found 1370 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_rstudio_session.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Rstudio Session date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 370\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nOnce you launch/submit your request, your job will wait in the queue until resources are available. You\\'ll then be able to connect to your session:\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Rstudio_session.png\" >}} {{< figure src=\"/notes/hpc-intro/img/OOD_Rstudio_session2.png\" caption=\"Starting an Rstudio session.\" >}}\\n\\nRstudio Server can continue running any active processes if your network is disconnected. Simply log back in to Open OnDemand, go to the \"My Interactive Sessions tab\", and click Launch again. It will reconnect, not launch another session.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1372 of 1477]\n",
      "Found 1371 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_other.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Other Interactive Apps date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 380\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nSome other widely-used interactive apps are MATLAB and the Desktop.\\n\\nDesktop\\n\\nThe most general OOD interactive app is the Desktop. It will start a desktop identical to the FastX desktop, but on a compute node rather than a frontend. From the desktop you can open a variety of applications from the menu, such as the Caja file manager. You can also open a terminal window and type any valid commands into it. In this illustration, the user has loaded a module to build a program for running. The OOD interactive desktop is the preferred method for interactive jobs.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Desktop_terminal.png\" caption=\"The OOD Desktop.\" >}}\\n\\nMATLAB\\n\\nThe MATLAB interactive app starts a MATLAB Desktop environment on a Desktop (VNC). Similar to Rstudio Server, in the form you can choose a version of MATLAB from a dropdown menu. Once there, you are in a less complete desktop environment. Your files may not be visible on the Desktop, but you can access them from the Places menu or from the Caja (filing cabinet) icon in the ribbon at the top of the screen. If you exit the MATLAB Desktop, it will also exit the session.\\n\\nReconnecting\\n\\nBoth MATLAB and the Desktop will persist if your network is disconnected. Log back in to Open OnDemand, find your session from the My Interactive Sessions tab, then click Launch again.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1373 of 1477]\n",
      "Found 1372 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_rstudio.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Rstudio Server date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 360\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nRstudio Server is a standalone app like JupyterLab. Starting a session is very similar to JupyterLab, but the form differs slightly. Instead of kernel tiles, you will select a version of R from a dropdown menu from those available. In this example, the version is R 4.4.1.\\n\\n{{< figure src=\"/notes/hpc-intro/img/Interactive-RStudio-form-2024.png\" caption=\"Starting an Rstudio session.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1374 of 1477]\n",
      "Found 1373 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_jupyter_terminal.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: JupyterLab Terminal date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 350\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nYou are also able to access the terminal through a JupyterLab session.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_JupyterLab_Terminal.png\" caption=\"JupyterLab Terminal\" >}}\\n\\nHere, you can execute Linux commands to create custom conda environments and JupyterLab kernels. Additionally, you can access and run singularity containers through this functionality.\\n\\nYour JupyterLab sessions will be saved in your /home/computingID/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_lab/output/ directory; however, you can navigate to any part of the filesystem in the JupyterLab terminal.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1375 of 1477]\n",
      "Found 1374 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_jupyter_exercise.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Exercise (JupyterLab)\" date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 395\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nStart a JupyterLab interactive session. Select the Python 3 kernel. If you are familiar with Python, you may write any code you wish. If you do not know Python, click on a cell and type the following\\n\\npython import numpy as np import matplotlib.pyplot as plt Hit [Shift][Enter] (hold both keys at once) to run the cell, or from the Run menu choose Run Selected Cell.\\n\\nIn the next cell type python x=np.linspace(-1.*np.pi,np.pi,100) y=np.sin(x) plt.plot(x,y)\\n\\nRun this cell.\\n\\nClose the tab, return to My Interactive Sessions in the OOD Dashboard, and delete the interactive job.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1376 of 1477]\n",
      "Found 1375 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_run_jupyter.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Using and Closing an Interactive Session date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 340\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nIf have not previously used the OOD JupyterLab interactive app, you must select a kernel before initiating the notebook. Once JupyterLab is set up, you can also start another notebook with a different kernel by selecting File->New Notebook. It will then show a dropdown with the kernels available to you.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Jupyter_nb.png\" caption=\"Starting a new notebook.\" >}}\\n\\nIf you are accidentally disconnected, you can go back to the OOD \"My Interactive Sessions\" tab and reconnect. However, anything left running in a cell may have been terminated. This is due to a limitation of Jupyter, not OOD or the HPC cluster, and does not apply to all interactive apps.\\n\\nRemember to delete your session if you finish early. Closing your browser tab does not end the session.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_delete_session.png\" caption=\"Ending a session.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1377 of 1477]\n",
      "Found 1376 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_resources.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Choosing Resource Requests date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 390\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\n{{< table >}} | Field | Description | | :-: | :-: | | Number of cores | Used in parallel processing. Your code must be modified to take advantage of using multiple cores. | | Memory Request in GB | When dealing with Big Data, you will need to increase the amount of memory. A good rule of thumb is to request 2 to 3 times the size of data that you are reading in or generating. | | Work Directory | Allows you to change the working directory of a Jupyter Notebook to your /scratch folder or a /standard or /project share if applicable. | | Optional: Slurm Option | Allows you to provide advanced features, like requesting specific nodes or providing a reservation | | Optional Group | Only needed if you are in more than 16 computing groups. You may need to force the system to see your allocation. | | Optional: GPU type for GPU partition & Optional: Number of GPUs | Only needed if you are running on a GPU node. The default for GPU type will put you on the first available GPU node. For now, the number of GPUS should be 1. | {{< /table >}}\\n\\nSome fields on the Web Forms are blank, while others are set to default values.\\n\\nThe most important request will usually be the Memory Request.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1378 of 1477]\n",
      "Found 1377 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_launch_jupyter.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Launching an Interactive Session date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 330\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nWhen you submit a request for an interactive app, it will be placed into the partition you specified, where it will wait until resources become available. Requests with higher resource requests (more cores, more memory, more time) may wait longer.\\n\\nOnce the job session begins, the screen will ask you to connect. In our example you will see a Connect to Jupyter button appear.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Jupyter_connect.png\" caption=\"Connecting to a session.\" >}}\\n\\nWhen you connect, you will see your files on the left sidebar and a collection of kernels from which to choose. You may not see all of these \"tiles\" because some accounts have customized tiles set up.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Jupyter_kernels.png\" caption=\"Start screen for JupyterLab\" >}}\\n\\nIf you have connected previously, it may start from your earlier status and you will not see the tiles.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1379 of 1477]\n",
      "Found 1378 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/interactive_apps/interactive_ood_jupyter.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Interactive JupyterLab Sessions date: \"2022-10-01T00:00:00Z\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 320\\n\\nmenu: hpc-intro: parent: Interactive Apps with Open OnDemand\\n\\nFrom the Interactive Apps menu, select JupyterLab.\\n\\nThe Jupyter Web Form gathers information about the computing resources that you need to run your Jupyter Notebook.\\n\\n{{< info >}} After you fill in the form, it will remember settings the next time that you connect to it, so watch out if you wish to change something. {{< /info >}}\\n\\n{{< figure src=\"/notes/hpc-intro/img/Interactive-Jupyter-form-2024.png\" caption=\"Setting up a job in JupyterLab through OOD\" >}}\\n\\nYou must choose a partition from the dropdown list. The partition limitations are explained below the dropdown box. Most of the time, you will select the Standard partition. If you are running a deep learning model, you will want to choose a GPU Partition. If you do not specify a GPU model, your job will be assigned to the first available.\\n\\nThe \"Number of hours\" is the time your job session will remain active.\\n\\n{{< warning >}} If you exceed the requested time limit, your session will be terminated without warning. {{< /warning >}}\\n\\nThe \"Allocation\" is the name of the allocation that should be charged. Your advisor should have told you what to use. You can be a member of more than one allocation. In that case one of them, not chosen by you, will be the default. It is best to always fill in the name of an allocation, but remember to change it if necessary.\\n\\nOnce you have completed the form, click on the Launch button to submit the request.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1380 of 1477]\n",
      "Found 1379 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx_desktop.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The FastX Desktop date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 160\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nA MATE desktop looks a little like an older Windows desktop. In the ribbon at the top are Caja, a file manager; a Terminal application, and the Firefox Web browser.\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_desktop.png\" caption=\"The MATE Desktop\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1381 of 1477]\n",
      "Found 1380 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx_logout.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Logging Out of FastX date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 170\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nIf you simply close your session browser tab, FastX suspends your session rather than terminates it. It is generally preferable to terminate rather than suspend so that you will not accidentally have multiple sessions running.\\n\\nOne way to terminate is to log out. Go to the System menu in the top ribbon and select Log Out mst3k (with your ID).\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_logout.png\" caption=\"Logging out of the desktop.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1382 of 1477]\n",
      "Found 1381 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx_kill_restart.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Terminating or Restarting FastX date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 180\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nYou can also terminate -- or restart -- a session from the \"My Sessions\" tab. To terminate, click the x in the upper right of the session, or use the menu.\\n\\nTo restart instead of terminating, click the arrow for \"run\".\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_kill_session.png\" caption=\"Terminating or restarting a session.\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1383 of 1477]\n",
      "Found 1382 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_ood_dashboard.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Open OnDemand Dashboard date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 120\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nThe Open OnDemand home page is the Dashboard.\\n\\n{{< figure src=\"/notes/hpc-intro/img/OOD_Dashboard.png\" caption=\"OOD Dashboard\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1384 of 1477]\n",
      "Found 1383 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_ssh.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Connecting with a Terminal (SSH) date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 190\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nSSH client provides direct access to the command line. Use the command\\n\\nssh -Y mst3k@login.hpc.virginia.edu\\n\\nOn a Mac or Linux system, simply open a terminal application and type the above command.\\n\\nOn a Windows system, open the Command Prompt app and type the above command.\\n\\nReplace the mst3k with your computing ID.\\n\\nYou must use the UVA VPN when off-grounds.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1385 of 1477]\n",
      "Found 1384 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx_session_page.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The FastX Session date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 140\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nFastX starts a session on a frontend. A new session is started by selecting either the MATE or Terminal icon under Applications on the right side of the page.\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_session_page.png\" caption=\"Starting a new session\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1386 of 1477]\n",
      "Found 1385 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx_session_launch.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Launching a FastX Session date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 150\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nMost users should choose the MATE session.\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_session_launch.png\" caption=\"Starting a MATE session\" >}}\\n\\nClick the icon, then click the play button on the MATE session under \"Disconnected Sessions\" on the page. This will open a new window with two options: Browser Client, and Desktop Client.\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_connect_options.png\" caption=\"Browser or Desktop Client\" >}}\\n\\nSelect the Browser Client to connect to your session.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1387 of 1477]\n",
      "Found 1386 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_fastx.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Connecting with FastX date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 130\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nFastX is a Web-based desktop environment for HPC. It is accessible either through the Open OnDemand Interactive Apps menu, or directly at fastx.hpc.virginia.edu.\\n\\nFastX requires the VPN. If the VPN is not active, the start page will not load.\\n\\nAlways use either the OOD link or the fastx URL. The underlying name of the host may change from time to time.\\n\\n{{< figure src=\"/notes/hpc-intro/img/FastX_splash_screen.png\" caption=\"Logging in to FastX\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1388 of 1477]\n",
      "Found 1387 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_ood.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Open OnDemand date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 110\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nTo connect to Open OnDemand, open your web browser and type\\n\\nhttps://ood.hpc.virginia.edu\\n\\nYou will need to authenticate with Netbadge (Netbadge in\")\\n\\nYou can connect to Open OnDemand from off-Grounds locations without a VPN connection.\\n\\nRemember that Open OnDemand is a Web application. If it freezes on you, click UVA Open OnDemand in the upper left. It will log you out eventually so you may need to log in again. You also may have to refresh pages to see changes.\\n\\nIt may also open many tabs. It is safe to close them if you aren\\'t using them; just make sure you first click \"Save\" for any files you are editing and want to save changes. You can even close all the tabs and log in again.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1389 of 1477]\n",
      "Found 1388 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_ssh 2.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Connecting with a Terminal (SSH) date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 190\\n\\nmenu: hpc-intro: parent: Connecting to Afton and Rivanna\\n\\nSSH client provides direct access to the command line. Use the command\\n\\nssh -Y mst3k@login.hpc.virginia.edu\\n\\nOn a Mac or Linux system, simply open a terminal application and type the above command.\\n\\nOn a Windows system, open the Command Prompt app and type the above command.\\n\\nReplace the mst3k with your computing ID.\\n\\nYou must use the UVA VPN when off-grounds.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1390 of 1477]\n",
      "Found 1389 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/hpc-intro/connecting_to_the_system/connecting_logging_on.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Connecting and Logging On To Rivanna date: \"2022-10-01T00:00:00\" draft: false # Is this a draft? true/false toc: false # Show table of contents? true/false type: docs # Do not modify. weight: 100\\n\\nmenu: hpc-intro: name: Connecting to Afton and Rivanna\\n\\nThere are three ways to connect to the HPC System:\\n\\nOpen OnDemand, a graphical user interface through a web browser\\n\\nyou can examine and manipulate files and submit jobs.\\n\\nyou can access applications such as Matlab, Jupyterlab, and R Studio Server.\\n\\nFastX Web, direct access to a desktop\\n\\nssh (Secure Shell) client, which provides direct access to the command line.\\n\\nFor Windows we recommend MobaXterm')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1391 of 1477]\n",
      "Found 1390 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/matlab-statistics/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='date : \"2019-06-23T08:37:46-05:00\" title : \"Statistical Methods with MATLAB\" type: article toc : true\\n\\nOverview\\n\\nMATLAB is an integrated technical computing environment from the MathWorks that combines array-based numeric computation, advanced graphics and visualization, and a high-level programming language. Separately licensed toolboxes provide additional domain-specific functionality.\\n\\nCourse Overview\\n\\nExploring Data\\n\\nVisualizing Data Sets\\n\\n{{< figure src=\"exploreData1.png\" >}}\\n\\n{{< figure src=\"exploreData2.png\" >}}\\n\\nMeasures of Centrality and Spread\\n\\n{{< figure src=\"centrality1.png\" >}} {{< figure src=\"centrality2.png\" >}} {{< figure src=\"centrality3.png\" >}}\\n\\n{{< figure src=\"spread1.png\" >}} {{< figure src=\"spread2.png\" >}} {{< figure src=\"spread3.png\" >}}\\n\\nDistributions\\n\\n{{< figure src=\"distribution3.png\" >}} {{< figure src=\"spread4.png\" >}}\\n\\n{{< figure src=\"distribution1.png\" >}} {{< figure src=\"distribution2.png\" >}}\\n\\nSummary\\n\\n{{< figure src=\"summary1.png\" >}}\\n\\n{{< figure src=\"summary2.png\" >}}\\n\\n{{< figure src=\"summary3.png\" >}}\\n\\nFitting a Curve to Data\\n\\nLinear Regression\\n\\n{{< figure src=\"regression1.png\" >}} {{< figure src=\"regression2.png\" >}} {{< figure src=\"regression4.png\" >}} {{< figure src=\"regression3.png\" >}}\\n\\nEvaluating Goodness of Fit\\n\\n{{< figure src=\"regression5.png\" >}} {{< figure src=\"regression6.png\" >}} {{< figure src=\"regression7.png\" >}}\\n\\nNonlinear Regression\\n\\n{{< figure src=\"regression8.png\" >}} {{< figure src=\"regression9.png\" >}} {{< figure src=\"regression10.png\" >}}\\n\\nSummary\\n\\n{{< figure src=\"summary4.png\" >}} {{< figure src=\"summary5.png\" >}} {{< figure src=\"summary6.png\" >}}\\n\\nInterpolating Data\\n\\nLinear Interpolation\\n\\n{{< figure src=\"interp1.png\" >}} {{< figure src=\"interp2.png\" >}} {{< figure src=\"interp3.png\" >}} {{< figure src=\"interp4.png\" >}} {{< figure src=\"interp5.png\" >}} {{< figure src=\"interp6.png\" >}}\\n\\nNonlinear Interpolation\\n\\n{{< figure src=\"interp7.png\" >}} {{< figure src=\"interp8.png\" >}} {{< figure src=\"interp9.png\" >}}\\n\\nSummary\\n\\n{{< figure src=\"summary7.png\" >}} {{< figure src=\"summary8.png\" >}}\\n\\nAdditional Resources\\n\\n{{< figure src=\"additionalRes1.png\" >}}\\n\\nMATLAB Central\\n\\nExercises\\n\\nVisualizing Data sets\\n\\nExercise: Visualize Height and Weight Data\\n\\nMeasure of Centrality and Spread\\n\\nExercise: Find the Mean and Median\\n\\nExercise: Find the Standard Deviation and IQR\\n\\nDistributions\\n\\nExercise: Fit and Plot a Normal Distribution\\n\\nExercise: Generating Random Numbers\\n\\nReview: Exploring Data\\n\\nExercise: Earthquakes\\n\\nLinear Regression\\n\\nExercise: Fit a Line to Data\\n\\nExercise: Fit a Polynomial to Data\\n\\nEvaluating the Goodness of Fit\\n\\nExercise: Evaluate and Improve the Fit\\n\\nNonlinear Regression\\n\\nExercise: Fit a Nonlinear Model\\n\\nReview: Fitting a Curve to Data\\n\\nExercise: Temperature Fluctuations\\n\\nLinear Interpolation\\n\\nExercise: Fill in Missing Data\\n\\nExercise: Resample Data\\n\\nNonlinear Interpolation\\n\\nExercise: Resample Data with Different Interpolation Methods\\n\\nReview: Interpolation\\n\\nExercise: Stock Prices')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1392 of 1477]\n",
      "Found 1391 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/bash-scripting/getting_started.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: \"Getting Started\" type: docs toc: true date: 2015-07-23T21:13:14-05:00 draft: false weight: 200\\n\\nmenu: bash-scripting:\\n\\nA shell script is a text file so should be created using a text editor. Do not use a word-processing program such as LibreOffice Write. Shell scripts should always be created on the operating system (Linux, macOS) on which they will run.\\n\\nThe first line should be ```bash\\n\\n!/bin/bash\\n\\n`` The#!` is often called a shebang.\\n\\nAfter the shebang, we can add some shell commands.\\n\\nExample\\n\\nHere is a simple example of a script that clears the screen, pauses for three seconds, then displays a quote from a Website.\\n\\n{{< code-download file=\"/notes/bash-scripting/scripts/qod.sh\" lang=\"bash\" >}}\\n\\nIf you have downloaded the file onto a Linux system, you can run it directly. Otherwise, either transfer it to your intended system or copy and paste it into a plain text file named qod.sh.\\n\\nLinux shells are indifferent to file suffixes. The sh is a convention, but other suffixes may be used; for example, when writing a shell script for a resource manager such as Slurm, we may wish to use a .slurm suffix.\\n\\nTo run the script, type bash bash qod.sh This invokes bash to execute your script. Alternatively, you can modify your script to make it executable and run it: bash chmod 755 myscript.sh ./quod.sh')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1393 of 1477]\n",
      "Found 1392 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/bash-scripting/out.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='\\n\\nIntroduction\\n\\nto Bash Scripting\\n\\n\\n\\nKatherine Holcomb\\n\\nOctober 18\\\\, 2017\\n\\nwww.arcs.virginia.edu\\n\\nOutline\\n\\nScripting Introduction\\n\\nBash Script Structure\\n\\nHands-on: * Executing a Script * Variables and Expressions * Conditionals * Comparisons (Integer Values and Strings) * Loops * Command Line Arguments * String Operations * Arrays * Dealing with Files\\n\\nMore Tutorials and Resources\\n\\nLinux Shell Scripting Tutorial:\\n\\nhttp://bash.cyberciti.biz/guide/Main_Page\\n\\nhttp://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO.html\\n\\nAdvanced Scripting Tutorial\\n\\nhttp://tldp.org/LDP/abs/html/\\n\\nRegex Tutorials\\n\\nhttp://www.regular-expressions.info/\\n\\nhttp://www.zytrax.com/tech/web/regex.htm\\n\\nSed and (g)awk tutorial\\n\\nhttp://www.grymoire.com/Unix/Sed.html\\n\\nhttp://www.grymoire.com/Unix/Awk.html\\n\\nWhat is a Script, What Can it be used for?\\n\\nA Bash script is a plain text file that contains instructions for the computer to execute.\\n\\nScripts are interpreted at runtime and executed line-by-line. Scripts are not standalone executables but must be run through an interpreter.\\n\\nAnything that can be executed or evaluated on the bash command line can be placed into a script.\\n\\nFrequently used to automate repetitive tasks:\\n\\n            * File handling\\\\, data backups\\n            * Schedule computing jobs\\\\, e\\\\.g\\\\. on UVAs Rivanna High\\\\- Performance Computing Cluster\\\\.\\n\\nHow to write a script\\n\\n1) Bash shell environment to execute scripts\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2) Needed: Text Editor to create and edit script files * - vi\\\\, vim\\\\, nano * - gedit through FastX * - avoid Windows Notepad\\\\, Microsoft Word\\n\\nOur Workspace Setup\\n\\nBasic Unix commands:\\n\\ncd \\\\\\n\\ncd ~/ changes to your home directory\\n\\npwd shows full path of current directory\\n\\nmkdir p \\\\\\n\\nls lists non-hidden files in current directory\\n\\nls *.sh lists non-hidden files that end in .sh\\n\\nmv\\n\\ncd ~/\\n\\npwd\\n\\nmkdir scripts\\n\\ncd scripts\\n\\npwd\\n\\nls\\n\\nBash Script Structure: A Simple Example\\n\\nCreate script hello.sh\\n\\n#!/bin/bash\\n\\n#This is a simple bash script\\n\\necho \"Hello world!\" #print greeting to screen\\n\\necho \"I am done now!\"\\n\\nThe first line tells the system to start the shell and execute the commands. It is sometimes called a shebang . An alternative is:\\n\\n#!/ usr /bin/ env _ bash_\\n\\nScripts can be annotated with comments\\\\, characters after the # character are ignored by the interpreter\\n\\nThe third and fourth line are commands.\\n\\nExecuting A Script\\n\\nSuppose the previous script was in a file hello.sh\\n\\nBy default it is just text. You must explicitly make it executable:\\n\\nchmod u+x hello.sh\\n\\nThen you can just invoke it by name at the command line:\\n\\n./hello.sh\\n\\nAlternative: Run via bash interpreter\\n\\nbash hello.sh\\n\\nComments and Line Continuations\\n\\nAll text from the # to the end of the line is ignored\\n\\nTo continue a statement on to the next line\\\\, type \\\\ \\\\\\n\\n#This is a comment\\n\\necho \"This line is too long I \\\\\\n\\nwant it to be on two lines\"\\n\\nMultiple statements can be placed on the same line when separated by the ;\\n\\na=20 ; b=3\\n\\nSourcing\\n\\nIf you execute the script as a standalone script\\\\, it starts a new shell -- that is what the shebang does -- if you do not use that you can type\\n\\nbash myscript.sh\\n\\nSometimes you just want to bundle up some commands that you repeat regularly and execute them within the current shell. To do this you should not include _ a _shebang \\\\, and you must source the script\\n\\n. \\\\')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1394 of 1477]\n",
      "Found 1393 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/notes/bash-scripting/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='type: docs toc: true date: \"2015-07-23T00:00:00\" draft: false weight: 1\\n\\nmenu: bash-scripting: name: Bash Scripting\\n\\nThe bash interpreter is the default shell on Linux. A shell is the intermediary between the user and the Linux operating system when working at the command line. Shells also can be programmed, much like other interpreted languages such as Python or R. A program for an interpreter is usually called a script.\\n\\nScripts are simple ways of bundling up a series of commands to run in order. They can be used to automate repetitive tasks, to run programs in the background, to handle conditions the program may encounter, and so forth.\\n\\nAnything a user can type on the command line can be part of a shell script.\\n\\nBefore')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1395 of 1477]\n",
      "Found 1394 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/kah/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Katherine Holcomb\\n\\nUsername (this should match the folder name)\\n\\nauthors: - kah\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Senior Research Computing Consultant\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Compilers - Parallel Computing')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1396 of 1477]\n",
      "Found 1395 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/kal/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Kathryn Linehan\\n\\nUsername (this should match the folder name)\\n\\nauthors: - kal\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Computational Research Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Machine Learning - HPC - Data Science')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1397 of 1477]\n",
      "Found 1396 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/uvarc/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: UVA Research Computing\\n\\nUsername (this should match the folder name)\\n\\nauthors: - uvarc\\n\\nIs this the primary user of the site?\\n\\nsuperuser: true\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\ninterests: - UVARC supports all facets of research computing at the University.\\n\\nThe University of Virginia Research Computing learning site is a repository for our online short courses, tutorials, and workshops.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1398 of 1477]\n",
      "Found 1397 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/mab/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Marcus Bobar\\n\\nUsername (this should match the folder name)\\n\\nauthors: - mab\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Computational Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Data Science - Image Analysis - Machine Learning - Research')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1399 of 1477]\n",
      "Found 1398 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/gka/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Gladys Andino\\n\\nUsername (this should match the folder name)\\n\\nauthors: - gka\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Senior Computational Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Bioinformatics')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1400 of 1477]\n",
      "Found 1399 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/abd/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Angela Boakye Danquah\\n\\nUsername (this should match the folder name)\\n\\nauthors: - abd\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Machine Learning/Deep Learning - Python - R')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1401 of 1477]\n",
      "Found 1400 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/teh/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Ed Hall\\n\\nUsername (this should match the folder name)\\n\\nauthors: - teh\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Consultant\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Matlab - Mathematica - Optimization')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1402 of 1477]\n",
      "Found 1401 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/jmh/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Jacalyn Huband\\n\\nUsername (this should match the folder name)\\n\\nauthors: - jmh\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Consultant\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - R - Data Analytics - Visualization')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1403 of 1477]\n",
      "Found 1402 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/rs/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Ruoshi Sun\\n\\nUsername (this should match the folder name)\\n\\nauthors: - rs\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Lead Scientist, Scientific Computing\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Computational Chemistry - Compilers - Containers - Parallelization')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1404 of 1477]\n",
      "Found 1403 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/cag/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Christina Gancayco\\n\\nUsername (this should match the folder name)\\n\\nauthors: - cag\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Consultant\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - R - Matlab - Python - Data Analytics')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1405 of 1477]\n",
      "Found 1404 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/as/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Ahmad Sheikhzada\\n\\nUsername (this should match the folder name)\\n\\nauthors: - as\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Consultant\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Parallel Computing - Machine Learning/Deep Learning - Containers - Matlab')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1406 of 1477]\n",
      "Found 1405 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/ab/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Angela Boakye Danquah\\n\\nUsername (this should match the folder name)\\n\\nauthors: - ab\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Computational Research Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Python - Data Analytics - ML/DL')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1407 of 1477]\n",
      "Found 1406 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/khs/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Karsten Siller\\n\\nUsername (this should match the folder name)\\n\\nauthors: - khs\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Research Computing Consultant, Manager of User Services\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - HPC - Biosciences - Image Analysis - Containers - Python')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1408 of 1477]\n",
      "Found 1407 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/wtr/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Will Rosenow\\n\\nUsername (this should match the folder name)\\n\\nauthors: - wtr\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Former Employee\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Bioinformatics - R - Python')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1409 of 1477]\n",
      "Found 1408 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/authors/pbo/_index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='Display name\\n\\ntitle: Paul Orndorff\\n\\nUsername (this should match the folder name)\\n\\nauthors: - pbo\\n\\nIs this the primary user of the site?\\n\\nsuperuser: false\\n\\nRole/position\\n\\nrole: Computational Scientist\\n\\nOrganizations/Affiliations\\n\\norganizations: - name: University of Virginia Research Computing url: \"https://www.rc.virginia.edu\"\\n\\nShort bio (displayed in user profile at end of posts)\\n\\nbio:\\n\\ninterests: - Computational Chemistry - Data Analysis - Python')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1410 of 1477]\n",
      "Found 1409 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/epihet.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"epihet\" description = \"\" author = \"RC Staff\" date = \"2018-05-03T14:33:50-05:00\" images = \"/images/projects/r-language.png\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"cphg\", \"r\", ] draft = false projecttype = [\"basic-science\", \"tools\"] +++\\n\\nRC is working with researchers in the Center for Public Health Genomics to write an R package to calculate Relative Proportion of Sites with Intermediate Methylation (RPIM) scores, which represent the epigenetic heterogeneity in a bisulfite sequencing sample.\\n\\nhttps://github.com/databio/epihet\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1411 of 1477]\n",
      "Found 1410 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/calcium-oscillations.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Quantifying Calcium Oscillations\" description = \"\" date = \"2020-10-05T09:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/cell-rosettes.png\" categories = [\"projects\"] tags = [ \"pharmacology\", \"matlab\", \"gui\" ] draft = false projecttype = [\"basic-science\", \"image-analysis\", \"tools\"] publications = [{authors = \"Guagliardo, N.A., Klein, P.M., Gancayco, C.A. et al.\", title = \"Angiotensin II induces coordinated calcium bursts in aldosterone-producing adrenal rosettes\", journal = \"Nature Communications\", year = \"2020\", doi = \"https://doi.org/10.1038/s41467-020-15408-4\"}] +++\\n\\nCalcium oscillations signify communication between zona glomerulosa cells of the mouse adrenal gland. Researchers in the Barrett Lab can capture these oscillatory events with calcium imaging, but they had difficulty analyzing the results. The Barrett Lab was in need of a comprehensive MATLAB program for quantitative analysis of the intracellular calcium signals from their cell imaging experiments. Prior to Research Computing\\'s involvement in the project, the Barrett Lab had been using fragments of code to analyze their data with little success. Research Computing developed a MATLAB application to create an efficient, centralized workflow that is also accessible to people who are new to MATLAB and programming.\\n\\nWith this application, the Barrett Lab was able to analyze the characteristics of calcium oscillatory events for the first time in two years. The app allows researchers to:\\n\\nChoose data and analysis parameters\\n\\nView full or partial fluorescent reading traces\\n\\nPerform quantitative analysis of individual events and bursts of events\\n\\n**PI: Paula Barrett')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1412 of 1477]\n",
      "Found 1411 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/age-mvc.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Predicting Injury Severity\" description = \"\" date = \"2020-10-05T09:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/age-mvc.jpg\" categories = [\"projects\"] tags = [ \"r\" ] draft = false projecttype = [\"basic-science\"] publications = [{authors = \"Hartka, T., Gancayco, C., McMurry, T., Robson, M., Weaver, A.\", title = \"Accuracy of algorithms to predict injury severity in older adults for trauma triage\", journal = \"Traffic Injury Prevention\", year = \"2019\", doi = \"https://doi.org/10.1080/15389588.2019.1688795\"}] +++\\n\\nPrevious research has shown that older adults are more susceptible to severe injury than their younger counterparts after being involved in a motor vehicle collision. Dr. Hartka was interested in determining whether there are age-related differences in the accuracy of severe injury prediction following a motor vehicle collision. Using R, Research Computing developed age-specific logistic regression models and assessed their accuracy, and generated unique graphs and animations to visualize the data more effectively.\\n\\nPI: Thomas Hartka')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1413 of 1477]\n",
      "Found 1412 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/johnson-steven.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Distribution and Discovery of Digital Information \" date = \"2025-03-30T00:00:00-05:00\" author = \"RC Staff\" images = \"/images/projects/johnson.png\" categories = [\"projects\"] tags = [ \"hpc\", \"cloud\", \"data-analysis\", \"data\", \"data-transfer\" ] draft = false projecttype = [\"social-science\",\"dac\"] +++ A team of UVA Commerce faculty partnered with the DAC to explore how information about personal health and finance propagates on online platforms and influences decisions. The DAC developed for them a process to merge and standardize data from CoreLogic and ComScore, two sources of consumer and real estate information. The DAC assisted by developing a method to map real estate data to Designated Market Areas (DMAs), which are geographic regions where the population receives similar types of information through the media. The DMA mapping allowed the researchers to link consumer behavior in the real estate market with demographic characteristics. To make the data analysis more efficient, the DAC automated the data ingestion and analysis processes using high-performance computing. This project demonstrates how the DAC can assist faculty in tackling complex and socially relevant research questions using big data.\\n\\nPI: Steven Johnson, PhD (UVA McIntire School of Commerce)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1414 of 1477]\n",
      "Found 1413 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/guagliardo.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Analysis of Calcium Activity in Ex Vivo Adrenal Slices\" date = \"2024-09-23T00:00:00-05:00\" author = \"RC Staff\" images = \"/images/projects/guagliardo.png\" categories = [\"projects\"] tags = [ \"hpc\", \"pharmacology\", \"image-processing\", \"rivanna\" ] draft = false projecttype = [\"hpc-computing\", \"dac\", \"image-analysis\"] +++\\n\\nThis proposal is to enhance the computational analysis of calcium imaging data from live adrenal tissue in the study of primary aldosteronism, a leading cause of hypertension. The significant computational challenges associated with large calcium imaging datasets and complex analyses are addressed by first improving the current workflow for greater efficiency and accessibility, and second, establishing a robust computaional workflow and data management strategy.\\n\\nPI: Nick Guagliardo, Dept. of Pharmacology')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1415 of 1477]\n",
      "Found 1414 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/simpleCache.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"simpleCache\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/r-language.png\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"r\", ] draft = false projecttype = [\"tools\"] publications = [{authors = \"Sheffield NS, Nagraj VP, Reuter V\", title = \"simpleCache: R caching for reproducible, distributed, large-scale projects\", journal = \"Journal of Open Source Software\", year = \"2018\", doi = \"10.21105/joss.00463\"}] +++\\n\\nIn partnership with researchers in the Center for Public Health Genomics, School of Medicine Research Computing has contributed to the development of a novel package for computationally efficient caching and loading of data in R. simpleCache provides an interface to a series of functions to store and retrieve cached objects, including in the context batch processing or HPC environments. The package further extends base R functionality of saving and loading external representations of objects by enabling caching to pre-defined directories and timed cache operations.\\n\\nRC helped document and develop new functions for the package ahead of its release to the Comprehensive R Archive Network (CRAN). An accompanying article was selected for publication in the Journal of Open Source Software in early 2018.\\n\\nhttps://CRAN.R-project.org/package=simpleCache\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1416 of 1477]\n",
      "Found 1415 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/cloud-migrations.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Cloud Migration for HIPAA Data\" description = \"\" date = \"2019-03-08T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/aws/aws-smile-logo.jpg\" categories = [\"projects\"] tags = [ \"cloud\", \"cbht\", \"aws\", \"hipaa\", ] draft = true projecttype = [\"tools\"] +++\\n\\nUVA Research Computing worked with researchers in the UVA Center for Behavioral Health and Technology to move many of its web-based research instruments to the cloud.\\n\\nCBHT \"has been involved in eHealth, specifically the development and testing of clinical interventions delivered via the Internet. We believe the Internet can be used to implement engaging, interactive, and comprehensive interventions. Our interventions are designed to improve outcome by tailoring the programs to the individual user. We were among the first to test the feasibility and effectiveness of delivering Internet interventions.\" Their research depends upon secure, data-driven websites that both enable participants to make regular submissions via web form, but also to safeguard private health data for researchers to learn from.\\n\\nWhen their previous generation of hardware was ready to be retired, CBHT developers contacted Research Computing to help redesign their platform and plan their migration into the Amazon public cloud. Their setup includes private, encrypted databases and web servers, and a strictly-controlled environment for highly sensitive data.\\n\\nLearn more about the Center for Behavioral Health & Technology.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1417 of 1477]\n",
      "Found 1416 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/dest.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Drosophila Evolution through Space and Time 2.0\" description = \"\" author = \"RC Staff\" date = \"2025-03-11\" images = \"/images/projects/dest.jpg\" caption = \"Artwork by Roberto Torres, CC BY\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"data\", \"hpc\", \"parallel-computing\" ] draft = false projecttype = [\"hpc-computing\", \"tools\", \"basic-science\", \"dac\"] publications = [{authors = \"Martin Kapun, Joaquin C B Nunez, Mara Bogaerts-Mrquez, Jess Murga-Moreno, Margot Paris, Joseph Outten, , Alan O Bergland\", title = \"Drosophila Evolution over Space and Time (DEST): A New Population Genomics Resource\", journal = \"Molecular Biology and Evolution\", volume = \"38\", issue = \"12\", month=\"December\", year = \"2021\", pages = \"57825805\", doi = \"10.1093/molbev/msab259\"}] +++\\n\\nEvolutionary biologists use population-based DNA sequencing to gain insight into the nature of adaptation, genetic diversity, and organismal form and function. When collecting DNA data, scientists are often sample limited because of the logistical challenges of collecting DNA from wild individuals across large portions of a species range. This can be mitigated when groups of scientists work together to create data and then share it with the larger community. The Bergland Lab has been a central participant in developing and maintaining DEST (Drosophila Evolution through Space and Time), a large (~10TB) repository of Drosophila melanogaster population genomic data which has been processed and standardized. The DEST dataset is a unique, spatially resolved, genomic time-series dataset for one of the premier model organisms in genetics.\\n\\nUVAs Research Computing has been the primary host for the DEST dataset and bioinformatics pipeline since 2020. Users access data through a combination of an http-passthrough, Globus, and a website. The website has been viewed nearly 5,000 times by over 2,500 unique visitors since its launch in 2020 and has been used by members of the broader research community in dozens of published research projects.\\n\\nThe Bergland Lab is working on a new version of the DEST dataset (DEST 2.0) that includes genomic data for over 50,000 flies from 500 population-based samples collected at ~100 localities throughout the world, with many localities sampled through time for upwards of a decade. Research Computings Data Analytics Center supported this work by debugging and streamlining one of the main parallel processes in the bioinformatics pipeline to efficiently use UVA HPC.\\n\\nPI: Alan Bergland, PhD (Department of Biology)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1418 of 1477]\n",
      "Found 1417 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/smooth-muscle-cells.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"PHACTR1 and Smooth Muscle Cell Behavior\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/smooth-muscle-cells.jpg\" categories = [\"projects\"] tags = [ \"basic-science\", \"r\", ] draft = false projecttype = [\"basic-science\"] +++\\n\\nCoronary artery disease (CAD) is the major cause of morbidity and mortality worldwide. Recent genome wide association studies (GWAS) have revealed more than 50 genomic loci that are associated with increased risk for CAD. However, the pathological mechanisms for the majority of the GWAS loci leading to increased susceptibility to this complex disorder are still unclear. RC is working with Redouane Aherrahrou (CPHG) who aims to study the impact of the CAD-associated genetic factors on the cellular and molecular SMC phenotypes. Support for this project has included preparation of scripts for programmatic data analyses, data visualization, statistical modeling, and assistance with use of the Rivanna high-performance computing cluster.\\n\\nPreliminary results were presented as a poster at the 2016 International Vascular Biology Meeting.\\n\\nPI: Redouane Aherrarou (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1419 of 1477]\n",
      "Found 1418 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/covid-saliva.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"COVID Saliva Testing\" description = \"\" author = \"RC Staff\" date = \"2022-03-01T14:33:50-05:00\" images = \"/images/projects/covid-saliva.jpg\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"covid-19\", \"data\", \"health\" ] draft = false projecttype = [\"basic-science\", \"tools\", \"clinical-research\", \"containers\"] +++\\n\\nIn cooperation with the UVA Saliva Testing Lab, the UVA Health System, and the Virginia Department of Health, the \"Be SAFE\" saliva testing program was launched in late 2020. Now a retired project, Be SAFE used saliva samples to detect the COVID-19 virus through a diagnostic PCR test.\\n\\nResearch Computing provided computational, storage, and data integration expertise to this project.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1420 of 1477]\n",
      "Found 1419 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/functional-connectome.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Functional Connectome Fingerprinting\" date = \"2018-05-03T14:33:50-05:00\" description = \"\" author = \"RC Staff\" images = \"/images/projects/functional-connectome-fingerprint.png\" categories = [\"projects\"] tags = [\"basic-science\"] draft = false projecttype = [\"basic-science\"] +++\\n\\nFunctional magnetic resonance imaging (fMRI) can be used to assess functional activity in the brain and connectivity between different regions of interest (ROIs), and a functional connectome is a map of the interactions between ROIs. Previous research has shown that a functional connectome contains enough unique characteristics, not unlike a fingerprint, that it can be used for accurate identification of an individual subject from a large group. RC is working with the UVA Functional Neuroradiology Lab to perform this fingerprinting analysis for a wide variety of populations and to develop innovative ways to visualize the results.\\n\\nPI: Jason Druzgal (Radiology and Medical Imaging)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1421 of 1477]\n",
      "Found 1420 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/esfarjani-aladyn.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Thermal properties of materials from first-principles\" date = \"2025-04-07T00:00:00-05:00\" author = \"RC Staff\" images = \"/images/projects/esfarjani.png\" categories = [\"projects\"] tags = [ \"hpc\", \"materials-science\", \"simulations\", \"rivanna\" ] draft = false projecttype = [\"hpc-computing\",\"engineering\"] publications = [{authors = \"Keivan Esfarjani, Harold Stokes, Safoura Nayeb Sadeghi, Yuan Liang, Bikash Timalsina, Han Meng, Junichiro Shiomi, Bolin Liao, Ruoshi Sun\", title = \"ALATDYN: A set of Anharmonic LATtice DYNamics codes to compute thermodynamic and thermal transport properties of crystalline solids\", journal = \"Computer Physics Communications\", volume = \"312\", year = \"2025\", pages = \"109575\", doi = \"10.1016/j.cpc.2025.109575\"}] +++\\n\\nProf. Esfarjani\\'s group is using the HPC cluster to develop the Anharmonic LAttice DYNamics (ALADYN) software suite to calculate thermal transport properties and phase transitions from first-principles. The codes can extract force constants, solve the Boltzmann transport equation, predict thermal equilibrium based on the self-consistent phonon theory, and run molecular dynamics simulations within an anharmonic force field. The figure shows the phonon density of states and dispersion curve of Ge obtained from ALADYN.\\n\\nPI: Keivan Esfarjani, PhD (Department of Materials Science & Engineering)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1422 of 1477]\n",
      "Found 1421 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/bii-covid.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"COVID-19 Surveillance Dashboard\" description = \"\" date = \"2020-07-23T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/covid-dashboard.png\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"covid-19\", \"web\" ] draft = false projecttype = [\"hpc-computing\", \"basic-science\", \"tools\"] +++\\n\\nThe Biocomplexity Institute at the University of Virginia has been at the forefront of epidemiological modeling to track the COVID-19 pandemic and has developed a suite of COVID-19 epidemic response resources including a series of dashboards to better help the public and the government better understand the pandemic. This is a static view of the Institutes interactive COVID-19 Surveillance Dashboard, which provides a visualization of COVID-19 cases, recoveries, and deaths across the globe. In an effort to support the planning and response efforts for the recent Coronavirus pandemic, researchers prepared this visualization tool that provides a unique way of examining data curated by different data sources.\\n\\nhttps://nssac.bii.virginia.edu/covid-19/dashboard/')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1423 of 1477]\n",
      "Found 1422 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/basic-science.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ author = \"RC Staff\" description = \"\" date = \"2018-04-23T17:17:35-04:00\" title = \"Basic Science Projects\" draft = true tags = [\"collaborations\"] categories = [\"projects\"] images = \"\" +++\\n\\nSchool of Medicine Research Computing is engaged in multiple collaborative projects in support of basic science research. Below is a list of some recent collaborations in this area.\\n\\nMicrobiome Analysis of Hospital Sink Drains\\n\\nSink drains are notoriously characterized as reservoirs of pathogens causing nosocomial transmissions in hospitals worldwide. Outbreaks where sinks have been implicated as source of antibiotic resistant bacteria have upsurged over the last few years. To understand transmission dynamics University of Virginia School of Medicine has established a unique \"Sink Lab\" for this research. This one-of-the kind laboratory establishes UVa as worldwide frontrunners in investigating sink related antibiotic resistant bacteria and how they spread. RC is working with the UVa Sink Lab for genomic analysis of the sink biomass.\\n\\nRC is contributing to:\\n\\nComparative genomic analysis of gram-negative bacterial isolates: The analysis aims at tracking the mobile genetic element blaKPC gene, which encodes for Klebsiella pneumoniae carbapenemase (KPC) enzyme that confers resistance to all beta lactam agents including penicillins, cephalosporins, monobactams and carbapenems. As a part of this project, whole-genome shotgun sequencing data for about 1500 bacterial isolates will be analyzed to assess the risk of acquisition of Carbapenemase producing Enterobacteriaceae from exposure to contaminated waste water premise plumbing.\\n\\nMetagenomic analysis: This project, under a contract for the Center for Disease Control and Prevention (CDC), aims at understanding the temporal dynamics of hospital sink microbiome. Taxonomic and functional analysis of whole metagenomic shotgun sequencing data from longitudinal sampling will shed light on the transfer and sustenance of high-risk antibiotic resistance genes in the hospital environments.\\n\\nPI: Amy Mathers (Infectious Diseases & UVa Sink Lab)\\n\\nGenomic Locus Overlap Enrichment Analysis (LOLAweb)\\n\\nThe past few years have seen an explosion of interest in understanding the role of regulatory DNA. This interest has driven large-scale production of functional genomics data resources and analytical methods. One popular analysis is to test for enrichment of overlaps between a query set of genomic regions and a database of region sets. In this way, annotations from external data sources can be easily connected to new genomic data.\\n\\nSOM Research Computing is working with faculty in the UVA Center for Public Health Genomics to implement LOLAweb, an online tool for performing genomic locus overlap annotations and analyses. This project, written in the statistical programming language R, allows users to specify region set data in BED format for automated enrichment analysis. LOLAweb provides interactive plots and annotated data based on specific reference genomes and region databases.\\n\\nhttp://lolaweb.databio.org/\\n\\nManuscript under review\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)\\n\\nPHACTR1 and Smooth Muscle Cell Behavior\\n\\nCoronary artery disease (CAD) is the major cause of morbidity and mortality worldwide. Recent genome wide association studies (GWAS) have revealed more than 50 genomic loci that are associated with increased risk for CAD. However, the pathological mechanisms for the majority of the GWAS loci leading to increased susceptibility to this complex disorder are still unclear. RC is working with Redouane Aherrahrou (CPHG) who aims to study the impact of the CAD-associated genetic factors on the cellular and molecular SMC phenotypes. Support for this project has included preparation of scripts for programmatic data analyses, data visualization, statistical modeling, and assistance with use of the Rivanna high-performance computing cluster.\\n\\nPreliminary results were presented as a poster at the 2016 International Vascular Biology Meeting.\\n\\nPI: Redouane Aherrarou (Center for Public Health Genomics)\\n\\nFunctional Connectome Fingerprinting\\n\\nFunctional magnetic resonance imaging (fMRI) can be used to assess functional activity in the brain and connectivity between different regions of interest (ROIs), and a functional connectome is a map of the interactions between ROIs. Previous research has shown that a functional connectome contains enough unique characteristics, not unlike a fingerprint, that it can be used for accurate identification of an individual subject from a large group. RC is working with the UVA Functional Neuroradiology Lab to perform this fingerprinting analysis for a wide variety of populations and to develop innovative ways to visualize the results.\\n\\nPI: Jason Druzgal (Radiology and Medical Imaging)\\n\\nSonomicrometry Signal Classification\\n\\nResearchers are using sonomicrometry to study the biomechanics of the human brain. While at times the signals collected do not require any preprocessing, more frequently they do require some denoising or are too noisy to analyze. Currently, researchers are manually categorizing the quality of thousands of these sonomicrometry signals and preprocessing them individually. RC is helping researchers develop a machine learning model to classify the signals and to determine the necessary preprocessing steps.\\n\\nPreliminary sonomicrometry data have been collected, and RC is working to classify, prepare, and normalize the data for use in a machine learning model. RC is currently developing preliminary models to classify the data by signal quality and preprocess automation techniques that will later be applied to noisy signals.\\n\\nPI: Matthew Panzer (Center for Applied Biomechanics)\\n\\nepihet\\n\\nRC is working with researchers in the Center for Public Health Genomics to write an R package to calculate Relative Proportion of Sites with Intermediate Methylation (RPIM) scores, which represent the epigenetic heterogeneity in a bisulfite sequencing sample.\\n\\nhttps://github.com/databio/epihet\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)\\n\\nTranscription factor-chromatin Binding Dynamics\\n\\nTwo important measures of the in vivo interaction of transcription factors with chromatin are the search time and the residence time. The former refers to the time it takes a factor to find its binding location, while the latter is the time the factor physically attaches to the chromatin. By quantifying the interaction dynamics of transcription factors, researchers hope to understand the role of these factors in basic cellular processes such as transcription and gene regulation. The RC team is working with collaborators from UVA and the NIH to understand the dynamics of the Gal4 protein in yeast. The project involves quantitatively analyzing ChIP-qPCR data, writing and running non-linear regression and statistical routines in Mathematica, and developing numerical simulations to determine the error bounds on the kinetic parameters.\\n\\nPI: Stefan Bekiranov (Biochemistry and Molecular Genetics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1424 of 1477]\n",
      "Found 1423 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/primed.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Center for Diabetes Technology PriMed\" description = \"Blah blah blah here we are with a placeholder.\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/dexcom.jpg\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"machine-learning\", ] draft = false projecttype = [\"tools\",\"clinical-research\",\"machine-learning\"] +++\\n\\nIn their research around constant glucose monitoring and the automated maintenance of insulin for patients, the CDT is exploring data drawn from external data sources such as DexCom and FitBit. RC has assisted the CDT by designing a secure computing footprint in Amazon Web Services to pull in these data, parse and process them, in order to perform deeper analytics through machine learning. In January 2018, CDT sponsored a ski camp at Wintergreen Resort for a group of youth diagnosed with Type I diabetes with the goal of importing glucose, insulin, and exercise metrics at the end of each day through remote web APIs. This proof of concept has enabled the CDT to move forward with further monitoring efforts that draw upon existing devices and providers, rather than re-inventing them in a singular system.\\n\\nPI: Marc Breton, PhD (Center for Diabetes Technology)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1425 of 1477]\n",
      "Found 1424 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/radiology-tustison-stone.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Quantifying Cerebral Cortex Regions\" description = \"Blah blah blah here we are with a placeholder.\" date = \"2019-05-10T14:33:50-05:00\" author = \"UVARC Staff\" images = \"/images/projects/tustison-stone-radiology.png\" categories = [\"projects\"] tags = [ \"hpc\", \"radiology\", \"rivanna\" ] audio = true draft = false projecttype = [\"image-analysis\",\"clinical-research\",\"tools\",\"hpc-computing\"] +++\\n\\nA powerful new technique for quantifying regions of the cerebral cortex was developed by Nick Tustison and James Stone at the University of Virginia along with collaborators from the University of Pennsylvania. It was evaluated using large data sets comprised of magnetic resonance imaging (MRI) of the human brain processed on a high-performance computing cluster at the University of Virginia. By making this technique available as open-source software, other neuroscientists are now able to investigate various hypotheses concerning the relationship between brain structure and development. Tustisons and Stones software has been widely disseminated and is being actively incorporated into a variety of clinical research studies, including a collaborative effort between the Department of Defense and Department of Veterans Affairs, exploring the long term effects of traumatic brain injury (TBI) among military service members.\\n\\nLearn more about the ITK Insight Toolkit on GitHub.\\n\\nPIs: Nick Tustison and James Stone (Department of Radiology)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1426 of 1477]\n",
      "Found 1425 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/refgenie.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Refgenie: A Reference Genome Resource Manager\" description = \"\" date = \"2020-02-23T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/refgenie-project.png\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"containers\", \"docker\", \"cphg\", \"python\" ] draft = false projecttype = [\"basic-science\", \"tools\", \"containers\"] publications = [{authors = \"Michal Stolarczyk, Vincent P. Reuter, Jason P. Smith, Neal E. Magee, Nathan C. Sheffield\", title = \"Refgenie: a reference genome resource manager\", journal = \"GigaScience\", year = \"2020\", doi = \"10.1093/gigascience/giz149\"}] +++\\n\\nReference genome assemblies are essential for high-throughput sequencing analysis projects. Typically, genome assemblies are stored on disk alongside related resources; e.g., many sequence aligners require the assembly to be indexed. The resulting indexes are broadly applicable for downstream analysis, so it makes sense to share them. However, there is no simple tool to do this.\\n\\nRefgenie is a reference genome assembly asset manager. Refgenie makes it easier to organize, retrieve, and share genome analysis resources. In addition to genome indexes, refgenie can manage any files related to reference genomes, including sequences and annotation files. Refgenie includes a command line interface and a server application that provides a RESTful API, so it is useful for both tool development and analysis.\\n\\nRC staff supported this project through its design phase, underlying infrastructure and final deployment of a Refgenie server within containers, which are attached to reference data in high performance storage.\\n\\nhttp://refgenie.databio.org/\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1427 of 1477]\n",
      "Found 1426 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/ncaa.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"In-Silico NCAA-Containing Peptide Design\" description = \"\" author = \"RC Staff\" date = \"2025-04-04\" images = \"/images/projects/ncaa.png\" categories = [\"projects\"] tags = [ \"data\", \"hpc\", \"parallel-computing\", \"drug-discovery\", \"data-science\" ] draft = false projecttype = [\"hpc-computing\", \"dac\", \"basic-science\", \"clinical-research\", \"engineering\", \"data-science\"] +++\\n\\nBacteria are an important type of human pathogen that can cause life-threatening infections. Increasingly, these microorganisms can survive the effects of antibiotics previously used to kill them. As bacteria become resistant to multiple kinds of antibiotics, the diseases they cause become ever more difficult to cure. Accordingly, infections caused by multidrug-resistant (MDR) pathogens are associated with frequent treatment failures, high hospitalization costs, and substantial mortality. New therapeutics are needed to treat infections caused by MDR bacteria. Towards developing these critical countermeasures, our group has discovered a unique peptide that efficiently kills many of the most challenging antibiotic-resistant pathogens and also demonstrates therapeutic efficacy in pre-clinical animal models of bacterial infection. Interested in investigating the effect of replacing the canonical-amino acids by non-canonical amino acids (NCAA) to increase the efficacy of the peptide, a DAC team member has created a computational strategy to perform the screening of multiple-peptide positions using a NCAA peptide library and the high-performance computing capabilities of Research Computing. With good agreement between computational predictions and bench-top experiments, our collaboration with the DAC led to the following key points: * Determination of NCAA-containing preferred peptides with better predicted binding (under experimental testing) * Construction of the first structural model of the peptide (both canonical and non-canonical variants) with the potential bacterial target * Structure-function insights in search of optimized antimicrobial peptides towards better therapeutics (by utilizing NCAAs)\\n\\nThese investigations have set the stage for our continued collaboration with the DAC team member in this area including multiple state and federal grants that we will be targeting in 2025.\\n\\nPIs: Matthew A Crawford, PhD (Department of Medicine, Division of Infectious Diseases & International Health) and Molly A Hughes, PhD (Department of Medicine, Division of Infectious Diseases & International Health)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1428 of 1477]\n",
      "Found 1427 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/political-sentiment.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Political Sentiment Analysis\" author = \"RC Staff\" categories = [\"projects\"] tags = [\"hpc\", \"R\", \"text analysis\",\"data-science\",\"hpc-computing\" ] images = \"/images/projects/political-sentiment.png\" description = \"\" date = \"2021-03-28T17:18:27-04:00\" draft = false audio = true projecttype = [\"social-science\", \"hpc-computing\", \"data-science\"] +++\\n\\nThe nature of political communication has been fundamentally altered by the emergence of social media. In earlier eras, social scientists, journalists, and citizens could focus on static statements by politicians and candidates in order to understand the nature of political discourse. Social scientists studying political communication would design surveys and focus groups to understand which messages were received by citizens, and with what effect. Today, as news moves to digital platforms and as political figures increasingly rely on social media, political communication is fundamentally dynamic. Studying patterns of communication among politicians, their supporters, and their critics requires scholarly focus on the content, sentiment, and framing of posts on various social media platforms. Similarly, making sense of the contours of an election campaign requires that scholars explore the interplay among online messages and real-world events such as endorsements, scandals, and standing in the polls. All of this means that the tools of political analysis must be combined with the tools of data science.\\n\\nOver the past several years a team of researchers from the Department of Politics, the School of Data Science, and Research Computing have collaborated to create a system to capture and store every Tweet to and from every major presidential candidate since the 2016 primaries, continuing with every Tweet to and from President Trump since Election Day. This collaboration has produced a unique database of approximately one billion tweets (currently 5 TB). While the analysis of tweets from candidates and office holders is commonplace, collecting, organizing, and analyzing tweets to these figures, both from supporters and opponents, requires significant effort and sustained collaboration.\\n\\nPI: Paul Freedman (Department of Politics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1429 of 1477]\n",
      "Found 1428 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/nicu-bpd.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Bradycardia and Desaturation Events in Infants\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/infant-rn.jpg\" categories = [\"projects\"] tags = [ \"NICU\", ] draft = false projecttype = [\"clinical-research\",\"machine-learning\"] publications = [{authors = \"Fairchild KD, Nagraj VP, Sullivan BA, Moorman JR, Lake DE\", title = \"Oxygen desaturations in the early neonatal period predict development of bronchopulmonary dysplasia\", journal = \"Pediatric Research\", year = \"2018\", doi = \"10.1038/s41390-018-0223-5\"}] +++\\n\\nEpisodes of bradycardia and oxygen desaturation (BD) are common among preterm very low birthweight (VLBW) infants and their association with adverse outcomes such as bronchopulmonary dysplasia (BPD) is unclear. A better understanding of this relationship could lead to improved clinical interventions.\\n\\nRC is helping neonatologists describe BD events in a large single-NICU VLBW cohort and test the hypothesis that measures of BD in the neonatal period add to clinical variables to predict BPD or death and other adverse outcomes. RC has implemented statistical modeling and machine learning techniques to assess the primary outcome of BPD in the context of a combination of clinical characteristics (like birthweight and gestational age) and bedside monitor features.\\n\\nPI: Karen Fairchild (Department of PediatricsNeonatology) & Doug Lake (Center for Advanced Medical Analytics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1430 of 1477]\n",
      "Found 1429 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/nicu-vital-signs.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Heart Rate Ranges in Neonates\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/heart-rate.jpg\" categories = [\"projects\"] tags = [ \"NICU\" ] draft = false projecttype = [\"clinical-research\"] publications = [{authors = \"Alonzo CJ, Nagraj VP, Zschaebitz JV, Lake DE, Moorman JR, Spaeder MC\", title = \"Heart rate ranges in premature neonates using high resolution physiologic data\", journal = \"Journal of Perinatology\", year = \"2018\", doi = \"10.1038/s41372-018-0156-1\"}] +++\\n\\nThere are limited evidence-based published heart rate ranges for premature neonates. However, knowing heart rate reference ranges in the premature neonatal population can be beneficial for bedside assessment in the Neonatal Intensive Care Unit (NICU).\\n\\nRC is collaborating with clinical researchers in the Department of Pediatrics to establish baseline ranges for heart rate data in premature infants. These results are summarized from more than two billion data points collected via bedside monitoring in the NICU. RC staff has contributed data analysis and visualization expertise to aggregate the data, generate interactive heatmaps and produce tables of these ranges by gestational age.\\n\\nPI: Corrie Alonzo (Department of PediatricsNeonatology) & Mike Spaeder (Department of Pediatrics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1431 of 1477]\n",
      "Found 1430 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/lolaweb.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"LOLAweb\" author = \"RC Staff\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"containers\", \"docker\", \"r\", \"cphg\", \"shiny\"] images = \"/images/projects/LOLAweb-logo-square.png\" description = \"\" date = \"2020-02-23T14:33:50-05:00\" draft = false audio = true projecttype = [\"basic-science\", \"tools\", \"containers\"] publications = [{authors = \"Nagraj VP, Magee NE, Sheffield NC\", title = \"LOLAweb: a containerized web server for interactive genomic locus overlap enrichment analysis\", journal = \"Nucleic Acids Research\", year = \"2018\", doi = \"10.1093/nar/gky464\"}]\\n\\n+++\\n\\nThe past few years have seen an explosion of interest in understanding the role of regulatory DNA. This interest has driven large-scale production of functional genomics data resources and analytical methods. One popular analysis is to test for enrichment of overlaps between a query set of genomic regions and a database of region sets. In this way, annotations from external data sources can be easily connected to new genomic data.\\n\\nSOM Research Computing is working with faculty in the UVA Center for Public Health Genomics to implement LOLAweb, an online tool for performing genomic locus overlap annotations and analyses. This project, written in the statistical programming language R, allows users to specify region set data in BED format for automated enrichment analysis. LOLAweb provides interactive plots and annotated data based on specific reference genomes and region databases.\\n\\nhttps://github.com/databio/LOLAweb/\\n\\nPI: Nathan Sheffield (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1432 of 1477]\n",
      "Found 1431 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/brodie-biology.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Tracking Bug Movements\" description = \"\" date = \"2019-06-13T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/bug-tracking.png\" categories = [\"projects\"] tags = [ \"hpc\", \"biology\", \"rivanna\", \"parallel-computing\" ] draft = false projecttype = [\"hpc-computing\"] +++\\n\\nEd Hall worked with the Brodie Lab in the Biology department, to set up a workflow to analyze videos of bug tracking experiments on the Rivanna Linux cluster. They wanted to use the community Matlab software (idTracker) for beetle movement tracking. Their two goals were to shorten the software runtime and to automate the process. There was a large backlog of videos to go through. Ed installed the idTracker software on Rivanna and modified the code to parallelize the bug tracking process. He wrote and documented shell scripts to automate their workflow on the cluster.\\n\\nPI: Edmund Brodie, PhD (Department of Biology)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1433 of 1477]\n",
      "Found 1432 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/ercp.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Outcomes of Dexmedetomidine During ERCP on Post-ERCP Pancreatitis\" description = \"\" author = \"RC Staff\" date = \"2025-03-18\" images = \"/images/projects/ercp.png\" caption = \"Image by Davee T, et al. CC BY-NC-SA\" categories = [\"projects\"] tags = [ \"health\", \"data\", \"machine-learning\" ] draft = false projecttype = [\"clinical-research\", \"machine-learning\", \"dac\"] +++\\n\\nEndoscopic retrograde cholangiopancreatography (ERCP) is a procedure in which an endoscope is guided into the first part of the small bowel for various instruments to be passed into the biliary and pancreatic ducts to remove obstructions, drain infectious collections or diagnose diseases of the bile ducts. ERCP is associated with higher rates of complications than other endoscopic procedures, one of the most severe being post-ERCP pancreatitis which is thought to take place in up to 10% of patients.\\n\\nDr. Podboy and Internal Medicine Resident Physician Dr. Jason Erno are interested in factors that may contribute to reduced outcomes of post-ERCP pancreatitis, such as the use of dexmedetomidine as an anesthetic agent. Research Computings Data Analytics Center investigated this by performing statistical and machine learning analyses of data from a retrospective cohort study who underwent ERCP at UVA in the last five years. These analyses examined associations between post-ERCP pancreatitis and factors such as dexmedetomidine use, patient demographics, pre-procedural medications, and specific intra-operative stent placements and procedures.\\n\\nFull image attribution: Davee T, Garcia JA, Baron TH. Precut sphincterotomy for selective biliary duct cannulation during endoscopic retrograde cholangiopancreatography. Annals of Gastroenterology (2012). PMCID: PMC3959408\\n\\nPI: Alexander Podboy, MD (Division of Gastroenterology and Hepatology)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1434 of 1477]\n",
      "Found 1433 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/bartweb.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"BART Web\" author = \"RC Staff\" categories = [\"projects\"] tags = [\"tools\",\"containers\",\"hpc\",\"scripts\",\"architecture\",\"code\",\"cphg\",\"docker\"] images = \"/images/projects/bart-web.png\" description = \"\" date = \"2021-10-22T17:18:27-04:00\" draft = false audio = true projecttype = [\"basic-science\", \"tools\", \"containers\"] publications = [{authors = \"Wenjing Ma, Zhenjia Wang, Yifan Zhang, Neal E Magee, Yayi Feng, Ruoyao Shi, Yang Chen, Chongzhi Zang\", title = \"BARTweb: a web server for transcriptional regulator association analysis\", journal = \"NAR Genomics and Bioinformatics\", year = \"2021\", volume = 3, issue = 2, month = \"June\", doi = \"10.1093/nargab/lqab022\"}] +++\\n\\nBART (Binding Analysis for Regulation of Transcription) Web\\n\\nWorking with researchers in the Zang Lab in the Center for Public Health Genomics (CPHG), RC helped launch BARTweb, an interactive web-based tool for users to analyze their Genelist or ChIP-seq datasets. BARTweb is a containerized Flask front-end (written in Python) that ingests files and submits them to a more robust Python-based genomics pipeline running on Rivanna, UVA\\'s high performance computing cluster (HPC). This architecture -- of a public web application that uses a supercomputer to process data -- is a new model for UVA, and one that eases the learning curve for researchers who may not have access to an HPC system or the expertise to run a BART pipeline in the command-line.\\n\\nhttp://bartweb.org/\\n\\nPI: Chongzhi Zang (Center for Public Health Genomics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1435 of 1477]\n",
      "Found 1434 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/sink-microbiome.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Microbiome Analysis of Hospital Sink Drains\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/klebsiella_pneumoniae.jpg\" categories = [\"projects\"] tags = [ \"bioinformatics\", \"sink-lab\" ] draft = false projecttype = [\"basic-science\"] +++\\n\\nSink drains are notoriously characterized as reservoirs of pathogens causing nosocomial transmissions in hospitals worldwide. Outbreaks where sinks have been implicated as source of antibiotic resistant bacteria have upsurged over the last few years. To understand transmission dynamics University of Virginia School of Medicine has established a unique \"Sink Lab\" for this research. This one-of-the kind laboratory establishes UVa as worldwide frontrunners in investigating sink related antibiotic resistant bacteria and how they spread. RC is working with the UVa Sink Lab for genomic analysis of the sink biomass.\\n\\nRC is contributing to:\\n\\nComparative genomic analysis of gram-negative bacterial isolates: The analysis aims at tracking the mobile genetic element blaKPC gene, which encodes for Klebsiella pneumoniae carbapenemase (KPC) enzyme that confers resistance to all beta lactam agents including penicillins, cephalosporins, monobactams and carbapenems. As a part of this project, whole-genome shotgun sequencing data for about 1500 bacterial isolates will be analyzed to assess the risk of acquisition of Carbapenemase producing Enterobacteriaceae from exposure to contaminated waste water premise plumbing.\\n\\nMetagenomic analysis: This project, under a contract for the Center for Disease Control and Prevention (CDC), aims at understanding the temporal dynamics of hospital sink microbiome. Taxonomic and functional analysis of whole metagenomic shotgun sequencing data from longitudinal sampling will shed light on the transfer and sustenance of high-risk antibiotic resistance genes in the hospital environments.\\n\\nPI: Amy Mathers (Infectious Diseases & UVa Sink Lab)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1436 of 1477]\n",
      "Found 1435 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/ciliberto-economics.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Economic Market Behavior\" description = \"Blah blah blah here we are with a placeholder.\" date = \"2019-06-13T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/market-trends.jpg\" categories = [\"projects\"] tags = [ \"hpc\", \"economics\", \"rivanna\", \"parallel-computing\" ] draft = false projecttype = [\"hpc-computing\",\"social-science\"] +++\\n\\nWhile conducting research for a highly-technical study of market behavior, Dr. Ciliberto realized that he needed to parallelize an integration over a sample distribution. RC staff member Ed Hall successfully parallelized Cilibertos Matlab code and taught him how to do production runs on the Universitys high-performance clusters. The second stage estimator was computationally intensive, Ciliberto recalls. We needed to compute the distribution of the residuals and unobservables for multiple parameter values and at many different points of the distribution, which requires parallelizing the computation. Ed Halls expertise in this area was crucial. In fact, without Eds contribution, this project could not have been completed.\\n\\nPI: Federico Ciliberto, PhD (Department of Economics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1437 of 1477]\n",
      "Found 1436 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/sonomicrometry-signal.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Sonomicrometry Signal Classification\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/sonomicrometry.jpg\" categories = [\"projects\"] tags = [\"basic-science\"] draft = false projecttype = [\"basic-science\",\"machine-learning\"] +++\\n\\nResearchers are using sonomicrometry to study the biomechanics of the human brain. While at times the signals collected do not require any preprocessing, more frequently they do require some denoising or are too noisy to analyze. Currently, researchers are manually categorizing the quality of thousands of these sonomicrometry signals and preprocessing them individually. RC is helping researchers develop a machine learning model to classify the signals and to determine the necessary preprocessing steps.\\n\\nPreliminary sonomicrometry data have been collected, and RC is working to classify, prepare, and normalize the data for use in a machine learning model. RC is currently developing preliminary models to classify the data by signal quality and preprocess automation techniques that will later be applied to noisy signals.\\n\\nPI: Matthew Panzer (Center for Applied Biomechanics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1438 of 1477]\n",
      "Found 1437 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/shukla-nikhil.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"OmegaSync\" date = \"2025-03-20T00:00:00-05:00\" author = \"RC Staff\" images = \"/images/projects/shukla.png\" categories = [\"projects\"] tags = [ \"hpc\", \"parallel-computing\", \"kubernetes\", \"rivanna\", \"shiny\" ] draft = false projecttype = [\"hpc-computing\",\"engineering\",\"dac\",\"tools\",\"containers\"] +++ The Computing Hardware Research Lab (CHRL) worked with the DAC to develop a pipeline connecting a web app to HPC resources for solving computationally hard combinatorial optimization problems such as computing the MaxCut in complex graphs using OmegaSync. The DAC created an RShiny app running on Kubernetes that collects user information and graph files. The app formats data, saves it to the HPC filesystem, and automates job submissions. It also triggers email notifications to users upon job start and completion, providing the results they need. This project highlights the DAC\\'s role in supporting faculty with complex research workflows.\\n\\nPI: Nikhil Shukla, PhD (Department of Electrical and Computer Engineering)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1439 of 1477]\n",
      "Found 1438 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/cardiovascular-genomics.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ description = \"\" title = \"Cardiovascular Genomics\" draft = false date = \"2018-05-03T14:33:50-05:00\" tags = [\"genomics\",\"cphg\"] categories = [\"projects\"] images = \"/images/projects/cphg.png\" author = \"RC Staff\" +++\\n\\nCoronary artery disease (CAD) is the major cause of morbidity and mortality worldwide. Recent genome wide association studies (GWAS) have revealed more than 50 genomic loci that are associated with increased risk for CAD. However, the pathological mechanisms for the majority of the GWAS loci leading to increased susceptibility to this complex disorder are still unclear. Many of the CAD loci appear to act through the vessel wall, presumably affecting smooth muscle cell (SMC) function.\\n\\nUVA Research Computing (RC) is working with Redouane Aherrahrou from the Center for Public Health Genomics who aims to study the impact of the CAD-associated genetic factors on the cellular and molecular SMC phenotypes, as well as the underlying biological pathways that are perturbed by these genetic factors.\\n\\nWhile providing scientific programming and data analysis support for this project, Research Computing has:\\n\\nDeveloped a series of scripts to programmatically normalize and summarize experimental data\\n\\nCreated interactive and static data visualizations\\n\\nPerformed statistical hypothesis tests\\n\\nProvided guidance on the use of the local high-performance computing cluster (Rivanna)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1440 of 1477]\n",
      "Found 1439 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/periasamy-flim.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Fluorescence Lifetime Imaging Microscopy in Cancer Research\" description = \"\" date = \"2020-07-22T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/periasamy-flim.png\" categories = [\"projects\"] tags = [ \"image analysis\", \"biology\", \"cancer\" ] draft = false projecttype = [\"basic-science\", \"image-analysis\", \"tools\"] publications = [{authors = \"Wallrabe H, Svindrych Z, Alam SR, Siller KH, Wang T, Kashatus D, Hu S, Periasamy A\", title = \"Segmented cell analyses to measure redox states of autofluorescent NAD(P)H, FAD & Trp in cancer cells by FLIM\", journal = \"Scientific Reports\", year = \"2018\", doi = \"https://doi.org/10.1038/s41598-017-18634-x\"}] +++\\n\\nMultiphoton FLIM microscopy offers many opportunities to investigate processes in live cells, tissue and animal model systems. For redox measurements, FLIM data is mostly published by cell mean values and intensity-based redox ratios. Our method is based entirely on FLIM parameters generated by 3-detector time domain microscopy capturing autofluorescent signals of NAD(P)H, FAD and novel FLIM-FRET application of Tryptophan and NAD(P)H-a2%/FAD-a1% redox ratio. Furthermore, image data is analyzed in segmented cells thresholded by 2  2 pixel Regions of Interest (ROIs) to separate mitochondrial oxidative phosphorylation from cytosolic glycolysis in a prostate cancer cell line. Hundreds of data points allow demonstration of heterogeneity in response to intervention, identity of cell responders to treatment, creating thereby different subpopulations. Histograms and bar charts visualize differences between cells, analyzing whole cell versus mitochondrial morphology data, all based on discrete ROIs. This assay method allows to detect subtle differences in cellular and tissue responses, suggesting an advancement over means-based analyses. RC staff supported this project with development of custom image analysis tools.\\n\\nPI: Ammasi Periasamy (Keck Center for Cellular Imaging)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1441 of 1477]\n",
      "Found 1440 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/transcription-factor.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Transcription factor-chromatin Binding Dynamics\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/chromatin-unwinding.jpg\" categories = [\"projects\"] tags = [\"basic-science\"] draft = false projecttype = [\"basic-science\"] +++\\n\\nTwo important measures of the in vivo interaction of transcription factors with chromatin are the search time and the residence time. The former refers to the time it takes a factor to find its binding location, while the latter is the time the factor physically attaches to the chromatin. By quantifying the interaction dynamics of transcription factors, researchers hope to understand the role of these factors in basic cellular processes such as transcription and gene regulation. The RC team is working with collaborators from UVA and the NIH to understand the dynamics of the Gal4 protein in yeast. The project involves quantitatively analyzing ChIP-qPCR data, writing and running non-linear regression and statistical routines in Mathematica, and developing numerical simulations to determine the error bounds on the kinetic parameters.\\n\\nPI: Stefan Bekiranov (Biochemistry and Molecular Genetics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1442 of 1477]\n",
      "Found 1441 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/surgical-research.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Secure Computing for Surgical Research\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/secure-surgery.png\" categories = [\"projects\"] tags = [ \"secure-computing\", \"ivy\", \"hipaa\" ] draft = false projecttype = [\"clinical-research\"] +++\\n\\nRC is working with Dr. Eric Schneider to create a secure computing environment for the research of the Healthcare Surgical Outcome team. Data from this project will contain HIPAA identifiers, as well as Medicare information, and requires more security and control of data ingress/egress than projects previously hosted on the Ivy platform. After successful implementation of this project, RC will create a similar computing environment for DoD blast and traumatic brain injury data collected by Dr. Schneider before he joined UVA.\\n\\nPI: Eric Schneider (Department of Surgery)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1443 of 1477]\n",
      "Found 1442 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/clinical-research.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Clinical Research Projects\" draft = true tags = [\"collaborations\"] categories = [\"projects\"] images = \"\" author = \"RC Staff\" description = \"\" date = \"2018-05-03T14:33:50-05:00\" +++\\n\\nBringing expertise in data analysis and large scale computation, School of Medicine Research Computing is supporting clinical research at UVa. Several recent collaborations are listed below.\\n\\nBradycardia and oxygen desaturation events in VLBW infants\\n\\nEpisodes of bradycardia and oxygen desaturation (BD) are common among preterm very low birthweight (VLBW) infants and their association with adverse outcomes such as bronchopulmonary dysplasia (BPD) is unclear. A better understanding of this relationship could lead to improved clinical interventions.\\n\\nRC is helping neonatologists describe BD events in a large single-NICU VLBW cohort and test the hypothesis that measures of BD in the neonatal period add to clinical variables to predict BPD or death and other adverse outcomes. RC has implemented statistical modeling and machine learning techniques to assess the primary outcome of BPD in the context of a combination of clinical characteristics (like birthweight and gestational age) and bedside monitor features.\\n\\nManuscript under review\\n\\nKaren Fairchild (Department of PediatricsNeonatology) & Doug Lake (Center for Advanced Medical Analytics)\\n\\nPredicting Triage Level in the Emergency Department with Machine Learning\\n\\nBefore patients are admitted to the emergency room, they are assigned a triage level based on the severity of their health problems. This is accomplished using the Emergency Severity Index (ESI), an emergency department triage algorithm that classifies patient cases into five different levels of urgency. Researchers are interested in using machine learning to develop a model to predict patient triage level. This model would not only analyze the typical vital signs that are used in the ESI, but also demographic data and patients history of health.\\n\\nDemographic and health data have been collected. RC is helping to prepare and normalize the data for use in a machine learning model. RC is currently developing preliminary machine learning models for predicting triage level.\\n\\nPI: Thomas Hartka (Department of Emergency Medicine)\\n\\nCustomized Secure Computing Environment for Surgical Research\\n\\nRC is working with Dr. Eric Schneider to create a secure computing environment for the research of the Healthcare Surgical Outcome team. Data from this project will contain HIPAA identifiers, as well as Medicare information, and requires more security and control of data ingress/egress than projects previously hosted on the Ivy platform. After successful implementation of this project, RC will create a similar computing environment for DoD blast and traumatic brain injury data collected by Dr. Schneider before he joined UVA.\\n\\nPI: Eric Schneider (Department of Surgery)\\n\\nHeart Rate Ranges in Premature Neonates Using High Resolution Physiologic Data\\n\\nThere are limited evidence-based published heart rate ranges for premature neonates. However, knowing heart rate reference ranges in the premature neonatal population can be beneficial for bedside assessment in the Neonatal Intensive Care Unit (NICU).\\n\\nRC is collaborating with clinical researchers in the Department of Pediatrics to establish baseline ranges for heart rate data in premature infants. These results are summarized from more than two billion data points collected via bedside monitoring in the NICU. RC staff has contributed data analysis and visualization expertise to aggregate the data, generate interactive heatmaps and produce tables of these ranges by gestational age.\\n\\nManuscript under review\\n\\nPI: Corrie Alonzo (Department of PediatricsNeonatology) & Mike Spaeder (Department of Pediatrics)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1444 of 1477]\n",
      "Found 1443 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/arctic.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Integrated Sensor Networks in Arctic Alaska\" description = \"\" date = \"2022-03-04T09:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/weather-station.png\" categories = [\"projects\"] tags = [ \"storage\", \"microservices\", \"data\", \"nsf\" ] audio = true draft = false projecttype = [\"basic-science\", \"containers\", \"engineering\",\"tools\"]\\n\\npublications = [{authors = \"Hartka, T., Gancayco, C., McMurry, T., Robson, M., Weaver, A.\", title = \"Accuracy of algorithms to predict injury severity in older adults for trauma triage\", journal = \"Traffic Injury Prevention\", year = \"2019\", doi = \"https://doi.org/10.1080/15389588.2019.1688795\"}]\\n\\n+++\\n\\nUnderstanding the Changing Natural-Built Landscape in an Arctic Community\\n\\nNavigating the New Arctic (NNA) is one of The National Science Foundation\\'s 10 Big Ideas. NNA projects address convergence scientific challenges in the rapidly changing Arctic. Arctic research is needed to inform the economy, security and resilience of the Nation, the larger region and the globe. NNA empowers new research partnerships from local to international scales, diversifies the next generation of Arctic researchers, enhances efforts in formal and informal education, and integrates the co-production of knowledge where appropriate. This award fulfills part of that aim by addressing interactions among social systems, natural environment, and built environment in the following NNA focus areas: Arctic Residents, Data and Observation, Education, and Resilient Infrastructure.\\n\\nArctic communities face many challenges as they grow and develop in the context of a rapidly changing environment. These challenges include coastal erosion, permafrost thaw, and ecosystem change. This project is developing and deploying a network of environmental sensors collecting continuous information over a five-year period in terrestrial and aquatic locations within the community of Utqiagvik. The sensor network yields an unprecedented dataset for examining the interactive effects of the natural and built environments. This project is improving the health and economic well-being of Utqiagvik and potentially other North Slope Borough villages in Alaska.\\n\\nThis research investigates two essential challenges for the Arctic city of Utqiagvik, Alaska: i) the impacts of existing community infrastructure practices on the surrounding tundra, coastal, and lagoon landscapes within and around the city, and ii) the impacts of a changing environment on the design and future planning of community infrastructure and buildings. The ultimate goal of the project is to understand how the natural and built environments interact with social systems in an Arctic city.\\n\\nUVA Research Computing is supporting this research by hosting computational services to ingest, process, transform, store, and serve sensor data over the life of the project. A scalable data service named HSDS runs within a containerized environment in the HPC networks to aggregate the collected sensor data. This service is backed by object storage, and is then served internally for research using a variety of data analysis tools.\\n\\nData: https://arcticdata.io/\\n\\nAward: https://www.nsf.gov/awardsearch/showAward?AWD_ID=2022639\\n\\nPI: Howard Epstein, Chair, Dept. of Environmental Sciences.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1445 of 1477]\n",
      "Found 1444 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/ed-triage.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Predicting ER Triage Levels with Machine Learning\" description = \"\" author = \"RC Staff\" images = \"/images/projects/uva-er.jpg\" categories = [\"projects\"] tags = [\"clinical-research\",\"machine-learning\"] draft = false projecttype = [\"clinical-research\",\"machine-learning\"] date = \"2018-05-03T14:33:50-05:00\" +++\\n\\nBefore patients are admitted to the emergency room, they are assigned a triage level based on the severity of their health problems. This is accomplished using the Emergency Severity Index (ESI), an emergency department triage algorithm that classifies patient cases into five different levels of urgency. Researchers are interested in using machine learning to develop a model to predict patient triage level. This model would not only analyze the typical vital signs that are used in the ESI, but also demographic data and patients history of health.\\n\\nDemographic and health data have been collected. RC is helping to prepare and normalize the data for use in a machine learning model. RC is currently developing preliminary machine learning models for predicting triage level.\\n\\nPI: Thomas Hartka (Department of Emergency Medicine)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1446 of 1477]\n",
      "Found 1445 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/zhigilei-materialsci.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Pulse Laser Irradiation and Surface Morphology\" description = \"Blah blah blah here we are with a placeholder.\" date = \"2019-06-24T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/zhigilei.png\" categories = [\"projects\"] tags = [ \"hpc\", \"materials-science\", \"simulations\", \"rivanna\" ] draft = false projecttype = [\"hpc-computing\",\"engineering\"] +++\\n\\nDr. Zhigilei and his team are using Rivanna to perform large-scale atomistic simulations aimed at revealing fundamental processes responsible for the modification of surface morphology and microstructure of metal targets treated by short pulse laser irradiation. The simulations are performed with a highly-optimized parallel computer code capable of reproducing collective dynamics in systems consisting of up to billions of atoms. As a result, the simulations naturally account for the complexity of the material response to the rapid laser energy deposition and provide clear visual representations, or atomic movies, of laser-induced dynamic processes. The mechanistic insights revealed in the simulations have an immediate impact on the development of the theoretical understanding of laser-induced processes and assist in optimization of laser processing parameters in current applications based on laser surface modification and nanoparticle generation in laser ablation.\\n\\nPI: Leonid V. Zhigilei, PhD (Department of Materials Science & Engineering)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1447 of 1477]\n",
      "Found 1446 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/project/reidenbach-envirosci.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ title = \"Fluid Dynamics and Reef Health\" description = \"Blah blah blah here we are with a placeholder.\" date = \"2019-06-20T14:33:50-05:00\" author = \"RC Staff\" images = \"/images/projects/fluid-dynamics.jpg\" categories = [\"projects\"] tags = [ \"hpc\", \"fluid-dynamics\", \"rivanna\", \"science\" ] draft = false projecttype = [\"hpc-computing\"] +++\\n\\nProfessor Reidenbach and his team are using Rivanna to run computational fluid dynamics simulations of wave and tide driven flows over coral reefs in order to determine how storms, nutrient inputs, and sediments impact reef health. This is an image of dye fluxing from the surface of the Hawaiian coral Porites compressa utilizing a technique known as planar laser induced fluorescence (PLIF). Reefs such as this one have been severely impacted by human alteration, both locally through additional inputs of sediments and nutrients, and globally through increased sea surface temperatures caused by climate change. Reidenbach is hopeful that his computational models will allow scientists to better predict the future health of reefs based on human activity and improve global reef restoration efforts.\\n\\nPI: Matthew Reidenbach, PhD (Department of Environmental Sciences)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1448 of 1477]\n",
      "Found 1447 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/education/courses.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ draft = false date = \"2022-02-02T10:55:28-05:00\" title = \"Courses\" description = \"\" author = \"RC Staff\" categories = [\"education\"] tags = [\"R\",\"cloud\",\"DSI\",\"CS\",\"SDS\",\"UVA\",\"BIMS\"]\\n\\n+++\\n\\nIn addition to providing free, in-person workshop training, UVA Research Computing staff teach for-credit courses. Below is a selection of courses that members of our group have taught, co-taught or provided guest lectures:\\n\\nBIMS 8382: Introduction to Biomedical Data Science\\n\\nSpring 2017, Spring 2018\\n\\nThis course introduces methods, tools, and software for reproducibly managing, manipulating, analyzing, and visualizing large-scale biomedical data. Specifically, the course introduces the R statistical computing environment and packages for manipulating and visualizing high-dimensional data, covers strategies for reproducible research, and culminates with analysis of data from a real RNA-seq experiment using R and Bioconductor packages.\\n\\nCS 6501: Distributed & Cloud Computing\\n\\nSpring 2017, Spring 2018\\n\\nThis graduate course introduces a basic grounding in designing and implementing distributed and cloud systems. It aims to acquaint students with principles and technologies of server clusters, virtualized datacenters, Grids/P2P, Internet clouds, social networks, Internet of Things (IoT), and applications. Students will have the opportunity to gain hands-on experience on public cloud such as Amazon EC2. Selected scientific applications will also be used as case studies to gain hands-on experiences.\\n\\nCS 4740: Cloud Computing\\n\\nSpring 2018, Fall 2020, Fall 2021\\n\\nInvestigates the architectural foundations of the various cloud platforms, as well as examining both current cloud computing platforms and modern cloud research. Student assignments utilize the major cloud platforms.\\n\\nDS 3002: Data Science Systems\\n\\nSpring 2021\\n\\nExposes students to contemporary platforms, tools, and pipelines for data analysis through a series of steadily escalating use cases. The course will begin with simple local database construction and evolve to cloud based providers such as AWS or Google Cloud. Attention is given to data lakes and NoSQL as appropriate.\\n\\nData Science Bootcamp: Computing, Storage & Data Analysis in the Cloud\\n\\nSummer 2017\\n\\nThis 1.5-day course introduces MSDS students to the basics of cloud computing in AWS, and the independent management of code, data, and computing resources in a research environment. Particular concern is given to the concepts of programmable, reusable, scalable resources in the AWS cloud, through hands-on labs in EC2 and S3.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1449 of 1477]\n",
      "Found 1448 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/education/rivanna-instructional.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ draft = false date = \"2023-09-13T10:55:28-05:00\" title = \"Instructional Use of High Performance Computing\" description = \"\" author = \"RC Staff\" categories = [\"education\",\"workshops\"] tags = [\"Rivanna\",\"instructional\",\"courses\"]\\n\\n+++\\n\\nInstructors can request instructional allocations on Rivanna and Afton for classes and extended workshops. These allocations are time-limited and generally allow access to a restricted set of nodes and only one special Slurm partition, but are otherwise equivalent to any allocation.\\n\\nResource Availability\\n\\nHardware and Partition\\n\\nInstructional allocations may use interactive partition. The instructional allocation is 100,000 SUs for the semester during which the course is conducted. For workshops, the allocation will persist during the workshop and for two days afterwards. RC offers several low-cost storage options to researchers, including 10TB of Research Standard storage for each eligible PI at no charge. Instructors are encouraged to utilize this 10TB of storage for both research and teaching activities. For more detailed descriptions of our storage options, visit https://www.rc.virginia.edu/userinfo/storage/.\\n\\nSoftware & Storage Environment\\n\\nResearch Computing\\'s primary focus is supporting the direct research mission of the University. Instructional allocations are provided in recognition of the many areas where the educational and research missions of the University meet, and in recognition that there is value in providing UVA\\'s diverse communities with experience in an HPC environment. However, staff time is a highly limited resource and instructional use of RC systems as a largely \\'as-is\\' service with standardized software and storage environments. We are unable to provide customization of the environment for specific classes.\\n\\nInterface\\n\\nFor most classes, we recommend the Open OnDemand interface if it suits the expected usage. This does not require knowledge of Unix and greatly reduces the training burden. The Open OnDemand interface requires only Netbadge credentials and can be accessed without a VPN from off Grounds.\\n\\nIf Open OnDemand is not adequate, the other recommended interface is FastX Web. This is a remote desktop application and requires the students to be able to navigate a Unix desktop system. Access from off Grounds via FastX requires a VPN connection.\\n\\nFastX connects only to a frontend. We significantly restrict the time, memory, and cores available to frontend jobs. If students are running anything but very short jobs, the Open OnDemand applications should be utilized. These access the compute nodes and are far less limited. Open OnDemand provides a remote desktop on compute nodes as well as direct access to JupyterLab, the Matlab Desktop, and Rstudio Server.\\n\\nHow to Submit a Request\\n\\nInstructors planning to use HPC should fill out the form. You will need to create the Grouper (requires VPN connection) allocation group. We suggest a generic group name related to the course rubric, e.g. cs5014. Once the group is created, the instructor or a designated group administrator will need to add the student IDs. The instructor should empty the membership of the group after the class or workshop has terminated. Instructors will need to submit an instructional allocation renewal request at the start of each semester.\\n\\nUsing the Allocation\\n\\nPrior to the first class use, instructors should test the allocation and the software applications required during class. Please do not wait until multiple students are attempting to use it.\\n\\nPasswords\\n\\nStudents, particularly undergraduates, frequently experience password difficulties. Rivanna and Afton use the Eservices password to authenticate, but few students know this password. Instructors are urged to communicate to students that they should go to the ITS password page at least several hours in advance and change their Netbadge password before using the system. Changing the Netbadge password will sync the Eservices password with it.\\n\\nPartition and Reservations\\n\\nThe allocation will have access to the interactive partition. Students can enter this with the -p or --partition options to Slurm. ```\\n\\nSBATCH -p interactive\\n\\nor\\n\\nSBATCH --partition=interactive\\n\\n``` If students use the Open OnDemand interface, they will enter this into the appropriate textbox when starting their interactive job application.\\n\\nInstructors are urged to request reservations for their classes. The reservation will be created to coincide with the class meeting time. Students must add an option --reservation=your-reservation in order to access the reserved resources. Students may still use the instructional partition outside the reservation, but those jobs will wait like any other queued job. Outside the dedicated reservation window jobs should be submitted without the --reservation flag for immediate queueing; otherwise the job will be pending until the next reservation window opens.\\n\\nFor batch jobs, the reservation can be entered on the command line sbatch --reservation=your-reservation myscript.slurm or it can be added to the job script preamble ```\\n\\nSBATCH --reservation=your-reservation\\n\\n``` For Open OnDemand interactive applications, it should be entered as an additional Slurm option.\\n\\nTraining\\n\\nResearch Computing staff are available to come to a class session to provide training to the students. This can be done in-person, when possible, or virtually through Zoom.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1450 of 1477]\n",
      "Found 1449 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/education/workshops.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ author = \"RC Staff\" description = \"\" title = \"Workshops\" date = \"2023-02-23T10:55:28-05:00\" draft = false tags = [\"R\",\"Python\",\"Matlab\",\"Shiny\",\"HPC\",\"Rivanna\",\"Ivy\",\"image processing\",\"bioinformatics\",\"containers\",\"programming\"] categories = [\"education\", \"workshops\"] images = [\"\"]\\n\\n+++\\n\\nUVA Research Computing provides training opportunities covering a variety of data analysis, basic programming and computational topics. All of the classes listed below are taught by experts and are freely available to UVa faculty, staff and students.\\n\\nNew to High-Performance Computing?\\n\\nWe offer orientation sessions to introduce you to the Afton & Rivanna HPC systems on Wednesdays (appointment required).\\n\\nWednesdays 3:00-4:00pm\\n\\nUpcoming Workshops\\n\\n{{% upcoming-workshops-smart %}}\\n\\nResearch Computing is partnering with the Research Library and the Health Sciences Library to deliver workshops covering a variety of research computing topics.\\n\\nAll Upcoming Workshops from UVA Library Research Data Services\\n\\nAll Upcoming Workshops from UVA Health Sciences Library\\n\\nWorkshop Material\\n\\nCourse material and exercises are available through a companion site. Feel free to browse classes, tutorials and workshop material and learn at your own pace.\\n\\nhttps://learning.rc.virginia.edu\\n\\nNew Tutorials\\n\\nSpecifically, check out these new tutorials!\\n\\n{{% new-tutorials %}}\\n\\nPrevious Workshops\\n\\nAdvanced Computing in the Cloud\\n\\nAdvanced Data Manipulation with R\\n\\nAdvanced Data Visualization with R\\n\\nAnalyzing 16s RNA Amplicons\\n\\nBuilding Shiny Web Applications in R\\n\\nConditionals and Iteration in R\\n\\nData Analysis & Visualization with Python\\n\\nData Visualization with Matlab\\n\\nDatabases and How to Use Them\\n\\nDocker Containers for Scientific Research\\n\\nHow to Work With Databases\\n\\nImage Processing with Matlab\\n\\nIntroduction to Cloud Computing\\n\\nIntroduction to Docker Containers\\n\\nIntroduction to Git and GitHub\\n\\nIntroduction to High Performance Computing (Rivanna)\\n\\nIntroduction to Highly-Sensitive Data Analysis (Ivy)\\n\\nIntroduction to Matlab\\n\\nIntroduction to Python\\n\\nIntroduction to R\\n\\nIntroduction to Rivanna\\n\\nIntroduction to the Command Line\\n\\nIntroduction to UVA Research Computing Resources\\n\\nMachine Learning in the Cloud\\n\\nMachine Learning with MatLab\\n\\nNext Generation Sequence Alignment\\n\\nOptimizing R\\n\\nParallel Computing with Matlab\\n\\nR For Beginners\\n\\nR Package Development Tools\\n\\nWriting in Functions in R\\n\\n{{% callout %}} Do you need a specific workshop and have a group of people to attend? Let us know.{{% /callout %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1451 of 1477]\n",
      "Found 1450 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/accord.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2021-06-10T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"ACCORD Support Request\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}\\n\\n{{< getstatus keyword=\"jira\" >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1452 of 1477]\n",
      "Found 1451 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/dedicated-computing.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2024-01-4T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Dedicated Computing Request\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1453 of 1477]\n",
      "Found 1452 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/sns-test.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2021-04-10T23:59:16-05:00\" tags = [\"database\"]\\n\\ncategories = [\"forms\"]\\n\\nimages = [\"\"] author = \"Staff\" description = \"\" title = \"Database Service Request\" draft = true type = \"form\" private = true +++\\n\\nhere is a response\\n\\n{{% form-userinfo %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1454 of 1477]\n",
      "Found 1453 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/support-request-attachments.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2022-08-16T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Support Request WITH ATTACHMENTS\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1455 of 1477]\n",
      "Found 1454 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/combined-request-form.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-09-18T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Combined Request Form\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1456 of 1477]\n",
      "Found 1455 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/allocation-purchase.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-04-22T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Purchase Service Units\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1457 of 1477]\n",
      "Found 1456 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/support-request-orig.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2022-08-16T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Support Request\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1458 of 1477]\n",
      "Found 1457 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/allocation-instructional.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-09-12T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Request an Instructional Allocation\" draft = false type = \"form\" private = true\\n\\n+++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1459 of 1477]\n",
      "Found 1458 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/skyline.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2020-09-11\" tags = [\"skyline\",\"virtual machine\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Skyline Virtual Machine Request\" draft = true type = \"form\" private = true +++\\n\\n{{% jira-msg %}}\\n\\n{{< form-cookies >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1460 of 1477]\n",
      "Found 1459 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/support-request.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-04-27T23:59:16-05:00\" tags = [] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Support Request\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}\\n\\n{{< form-cookies >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1461 of 1477]\n",
      "Found 1460 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/containers.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-05-11T23:59:16-05:00\" tags = [] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Container Service Request\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1462 of 1477]\n",
      "Found 1461 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/README.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content=' Combined Request Form - Research Computing\\n\\n Overview\\n\\nThe Combined Request Form is a dynamic web-based UI for Service Unit (SU) Requests and Storage Requests. The form handles new allocations and renewals, validates user inputs, generates API payloads, and submits requests using POST (New) and PUT (Renewal) methods.\\n\\n Table of Contents\\n\\nForm Structure\\n\\nJavaScript Architecture\\n\\nEvent Handling & Interactivity\\n\\nFetching and Processing User Data\\n\\nPayload Construction (New & Renewal Requests)\\n\\nForm Submission & API Communication\\n\\nValidation & Error Handling\\n\\nUI Behaviors & Additional Features\\n\\n 1. Form Structure\\n\\nThe form dynamically adjusts based on the selected request type.\\n\\nService Unit (SU) Requests\\n\\nNew Request: Users select a Group, Tier, and input billing details.\\n\\nRenewal: Users select from an Existing SU Table, and only the update_date is changed.\\n\\nStorage Requests\\n\\nNew Storage: Users pick a storage tier and specify allocation details.\\n\\nModify Storage: Users choose an existing project from the Existing Storage Table.\\n\\nBilling Information\\n\\nDisplayed dynamically if a selected request requires billing.\\n\\n 2. JavaScript Architecture\\n\\nThe core JavaScript file combined-request-form.js manages: - Dynamic form updates based on user selections. - Fetching and displaying user resources. - Validating inputs and preventing invalid submissions. - Building and submitting API payloads.\\n\\nKey JavaScript Functions\\n\\nFunction Description fetchMetadata() Fetches storage tier limits and billing rules from API. fetchAndPopulateGroups() Retrieves user groups and resources dynamically. updatePayloadPreview() Shows real-time request preview before submission. validatePayload(payload) Ensures API payload structure is correct. submitForm(formData, payload) Sends request via POST (New) or PUT (Renewal). processUserResources(apiResponse) Populates users Existing SU Table .\\n\\n 3. Event Handling & Interactivity\\n\\nJavaScript dynamically updates the UI based on user actions.\\n\\nKey Event Listeners\\n\\nEvent Function Triggered Description Change on request-type toggleRequestFields() Toggles between Service Unit and Storage Requests . Change on new-or-renewal toggleAllocationFields() Shows correct fields for New vs Renewal . Change on existing-project-allocation updatePayloadPreview() Updates the API payload preview. Change on any form input updateBillingVisibility() Shows/hides Billing Information . Form Submit handleFormSubmit(event) Collects data, validates, and submits the request.\\n\\n 4. Fetching and Processing User Data\\n\\nAt page load, fetchAndPopulateGroups() retrieves: - User Groups - Existing Service Unit Allocations - Storage Requests\\n\\nFetched data is stored in consoleData and updates: 1. Existing SU Table (populateExistingServiceUnitsTable()) 2. Existing Storage Requests Table (if applicable)\\n\\n 5. Payload Construction (New & Renewal Requests)\\n\\nNew SU Requests (POST)\\n\\nUser selects Group and Tier.\\n\\nBilling details are included if applicable.\\n\\nRequest count defaults to 1000 unless specified.\\n\\nPayload structure: json [ { \"group_name\": \"RC_Staff\", \"project_name\": \"Test Project\", \"project_desc\": \"This is free text\", \"data_agreement_signed\": true, \"pi_uid\": \"UVAComputingID\", \"resources\": { \"hpc_service_units\": { \"CACS_Staff\": { \"tier\": \"ssz_project\", \"request_count\": \"1000\", \"billing_details\": { \"fdm_billing_info\": [ { \"financial_contact\": \"First Name Last Name\", \"company\": \"234324\", \"business_unit\": \"3\", \"cost_center\": \"224\", \"fund\": \"a Fund\", \"gift\": \"\", \"grant\": \"\", \"designated\": \"\", \"project\": \"\", \"program_code\": \"a program\", \"function\": \"A Function\", \"activity\": \"an activity\", \"assignee\": \"an assignee\" } ] } } } }, \"user_resources\": [] } ]\\n\\nRenewal Requests (PUT)\\n\\nThe user selects an existing SU instead of filling in a new group.\\n\\nThe only change allowed is updating the update_date.\\n\\nThe API payload includes the existing group, tier, and updated timestamp. json [ { \"group_name\": \"RC_Staff\", \"project_name\": \"Existing Project\", \"resources\": { \"hpc_service_units\": { \"CACS_Staff-ssz_standard\": { \"tier\": \"ssz_standard\", \"request_count\": \"50000\", \"update_date\": \"2025-02-12T10:30:00Z\" \"billing_details\": { \"fdm_billing_info\": [ { \"financial_contact\": \"First Name Last Name\", \"company\": \"234324\", \"business_unit\": \"3\", \"cost_center\": \"224\", \"fund\": \"a Fund\", \"gift\": \"\", \"grant\": \"\", \"designated\": \"\", \"project\": \"\", \"program_code\": \"a program\", \"function\": \"A Function\", \"activity\": \"an activity\", \"assignee\": \"an assignee\" } ] } } } } } ]\\n\\n6. Form Submission & API Communication\\n\\nThe submitForm() function determines whether to POST or PUT based on the selected New vs Renewal option.\\n\\nNew Requests  POST to: https://uvarc-unified-service.pods.uvarc.io/uvarc/api/resource/rcwebform/user/{userId}\\n\\nRenewal Requests  PUT to: https://uvarc-unified-service.pods.uvarc.io/uvarc/api/resource/rcwebform/user/{userId}/{resource_id}\\n\\n7. Validation & Error Handling\\n\\nBefore submission, validatePayload(payload) checks for:\\n\\nMissing required fields (group, tier, request count).\\n\\nDuplicate group/tier combinations.\\n\\nCorrect formatting of billing details (when required).\\n\\nErrors trigger showErrorMessage(), and invalid fields are marked red.\\n\\n8. UI Behaviors & Additional Features\\n\\n Real-Time Payload Preview\\n\\nThe function updatePayloadPreview() shows the request payload before submission.\\n\\n Billing Visibility\\n\\nThe form automatically hides/shows billing details based on the selected SU or Storage option.\\n\\n Sorting of Existing SU Table\\n\\nNewest allocations appear first in the Existing SU table.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1463 of 1477]\n",
      "Found 1462 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/storage.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-04-24T23:59:16-05:00\" tags = [] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Storage Request\" draft = false type = \"form\" private = true +++\\n\\n{{% jira-msg %}}\\n\\n{{< form-cookies >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1464 of 1477]\n",
      "Found 1463 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/test-form.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2019-06-30T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Test FDM Form\" draft = true type = \"form\" private = true +++\\n\\n{{% form-userinfo %}}\\n\\n(Non-UVA personnel are charged $0.07/SU)\\n\\n{{% billing-fdm %}}\\n\\nPlease submit the form only once. If you receive an error message after submitting this request, please check your email to confirm that the submission completed.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1465 of 1477]\n",
      "Found 1464 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/allocation-standard.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2023-04-24T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Request or Renew a Standard Allocation\" draft = false type = \"form\" private = true\\n\\n+++\\n\\n{{% jira-msg %}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1466 of 1477]\n",
      "Found 1465 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/support-request-vRedesign.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2020-12-10T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Support Request\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1467 of 1477]\n",
      "Found 1466 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/storage-ptao.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2022-05-04T23:59:16-05:00\" tags = [\"storage\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Storage Request\" draft = true type = \"form\" private = true +++\\n\\n{{< form-cookies >}}')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1468 of 1477]\n",
      "Found 1467 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/fdm.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2019-06-30T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"FDM Field Testing\" draft = true type = \"form\" private = true +++\\n\\nAlternate forms with FDM implemented:\\n\\nSU Allocation Purchase\\n\\nStorage Purchase\\n\\nIvy FDM needs to be implemented in the SERVICES application:\\n\\nhttps://services.rc.virginia.edu/')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1469 of 1477]\n",
      "Found 1468 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/omero-ptao.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2019-07-22T23:59:16-05:00\" tags = [\"omero\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Omero Image Database Service\" draft = true type = \"form\" private = true +++\\n\\nFrom the microscope to publication, OMERO handles all your images in a secure central repository. You can view, organize, analyze and share your data from anywhere you have internet access. Work with your images from a desktop app (Windows, Mac or Linux), from the web or from 3rd party software. Over 140 image file formats supported, including all major microscope formats.\\n\\nUse the form below to request access for your group or lab to manage and analyze data in our OMERO database service.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1470 of 1477]\n",
      "Found 1469 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/database.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2021-04-10T23:59:16-05:00\" tags = [\"mysql\",\"database\"]\\n\\ncategories = [\"forms\"]\\n\\nimages = [\"\"] author = \"Staff\" description = \"\" title = \"Database Service Request\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1471 of 1477]\n",
      "Found 1470 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/containers-ptao.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2021-04-10T23:59:16-05:00\" tags = [\"microservices\",\"containers\",\"docker\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Container Service Request\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1472 of 1477]\n",
      "Found 1471 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/omero.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2019-07-22T23:59:16-05:00\" tags = [\"omero\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Omero Image Database Service\" draft = true type = \"form\" private = true +++\\n\\nFrom the microscope to publication, OMERO handles all your images in a secure central repository. You can view, organize, analyze and share your data from anywhere you have internet access. Work with your images from a desktop app (Windows, Mac or Linux), from the web or from 3rd party software. Over 140 image file formats supported, including all major microscope formats.\\n\\nUse the form below to request access for your group or lab to manage and analyze data in our OMERO database service.')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1473 of 1477]\n",
      "Found 1472 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/form/retired/allocation-purchase-ptao.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='+++ date = \"2019-06-30T23:59:16-05:00\" tags = [\"search\"] categories = [\"forms\"] images = [\"\"] author = \"Staff\" description = \"\" title = \"Purchase Service Units\" draft = true type = \"form\" private = true +++')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1474 of 1477]\n",
      "Found 1473 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/slides/example/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: Slides summary: An introduction to using Academic\\'s Slides feature. authors: [] tags: [] categories: [] date: \"2019-02-05T00:00:00Z\" slides: # Choose a theme from https://github.com/hakimel/reveal.js#theming theme: white # Choose a code highlighting style (if highlighting enabled in params.toml) # Light style: github. Dark style: dracula (default). highlight_style: github\\n\\nCreate slides in Markdown with Academic\\n\\nAcademic | Documentation\\n\\nFeatures\\n\\nEfficiently write slides in Markdown\\n\\n3-in-1: Create, Present, and Publish your slides\\n\\nSupports speaker notes\\n\\nMobile friendly slides\\n\\nControls\\n\\nNext: Right Arrow or Space\\n\\nPrevious: Left Arrow\\n\\nStart: Home\\n\\nFinish: End\\n\\nOverview: Esc\\n\\nSpeaker notes: S\\n\\nFullscreen: F\\n\\nZoom: Alt + Click\\n\\nCode Highlighting\\n\\nInline code: variable\\n\\nCode block: python porridge = \"blueberry\" if porridge == \"blueberry\": print(\"Eating...\")\\n\\nMath\\n\\nIn-line math: $x + y = z$\\n\\nBlock math:\\n\\n$$ f\\\\left( x \\\\right) = \\\\;\\\\frac{{2\\\\left( {x + 4} \\\\right)\\\\left( {x - 4} \\\\right)}}{{\\\\left( {x + 4} \\\\right)\\\\left( {x + 1} \\\\right)}} $$\\n\\nFragments\\n\\nMake content appear incrementally\\n\\n{{%/* fragment */%}} One {{%/* /fragment */%}} {{%/* fragment */%}} **Two** {{%/* /fragment */%}} {{%/* fragment */%}} Three {{%/* /fragment */%}}\\n\\nPress Space to play!\\n\\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} Two {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}\\n\\nA fragment can accept two optional parameters:\\n\\nclass: use a custom style (requires definition in custom CSS)\\n\\nweight: sets the order in which a fragment appears\\n\\nSpeaker Notes\\n\\nAdd speaker notes to your presentation\\n\\nmarkdown {{%/* speaker_note */%}} - Only the speaker can read these notes - Press `S` key to view {{%/* /speaker_note */%}}\\n\\nPress the S key to view the speaker notes!\\n\\n{{< speaker_note >}} - Only the speaker can read these notes - Press S key to view {{< /speaker_note >}}\\n\\nThemes\\n\\nblack: Black background, white text, blue links (default)\\n\\nwhite: White background, black text, blue links\\n\\nleague: Gray background, white text, blue links\\n\\nbeige: Beige background, dark text, brown links\\n\\nsky: Blue background, thin dark text, blue links\\n\\nnight: Black background, thick white text, orange links\\n\\nserif: Cappuccino background, gray text, brown links\\n\\nsimple: White background, black text, blue links\\n\\nsolarized: Cream-colored background, dark green text, blue links\\n\\n{{< slide background-image=\"/img/boards.jpg\" >}}\\n\\nCustom Slide\\n\\nCustomize the slide style and background\\n\\nmarkdown {{</* slide background-image=\"/img/boards.jpg\" */>}} {{</* slide background-color=\"#0000FF\" */>}} {{</* slide class=\"my-style\" */>}}\\n\\nCustom CSS Example\\n\\nLet\\'s make headers navy colored.\\n\\nCreate assets/css/reveal_custom.css with:\\n\\ncss .reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }\\n\\nTwo Columns\\n\\nThis is a local addition to the features.\\n\\nThis is how you make a slide with two columns. You can put an image on the other side.\\n\\n\\n\\n--- # Questions? [Ask](https://spectrum.chat/academic) [Documentation](https://sourcethemes.com/academic/docs/managing-content/#create-slides)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1475 of 1477]\n",
      "Found 1474 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/slides/accord-intro/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: ACCORD Intro summary: An introduction to ACCORD. authors: [] tags: [] categories: [] date: \"2021-10-25T00:11:14Z\" slides: # Choose a theme from https://github.com/hakimel/reveal.js#theming theme: white # Choose a code highlighting style (if highlighting enabled in params.toml) # Light style: github. Dark style: dracula (default). highlight_style: github\\n\\n\\n\\nIntro to ACCORD\\n\\n\\n\\nOverview\\n\\nACCORD is a web-accessible secure platform which allows researchers from Virginia public universities to analyze their sensitive data in a central location\\n\\n\\n\\nACCORD projects\\n\\nACCORD is project-based:\\n\\nInvestigators can have multiple projects\\n\\nExample: kidney research and an RNA-seq study\\n\\nProjects are isolated, you cannot transfer or access data between them\\n\\nInvite co-investigators\\n\\nTo add researchers to your project, submit a request here: Add a researcher\\n\\n\\n\\n--- ### Storage on ACCORD\\n\\nACCORD projects come with:\\n\\nHome directory of 50GB\\n\\nProject directory of 1TB\\n\\nAdditional storage can be purchased. Please submit a request here\\n\\n\\n\\n--- ### Data on ACCORD\\n\\nACCORD supports:\\n\\nDe-identified PII\\n\\nFERPA\\n\\nBusiness Confidential\\n\\nOther types of sensitive data\\n\\nACCORD does not support:\\n\\nIdentifiable HIPAA\\n\\nCUI\\n\\nFISMA\\n\\nPCI\\n\\n\\n\\nQuestions about whether your data is suitable for ACCORD? Submit a support ticket here\\n\\n--- ### Data retention\\n\\n\\n\\nData is stored on the system for 6 months. - To extend your project, please fill out a request --- ### Globus data transfer\\n\\n\\n\\nData transfer is processed through Research Computing staff for the time being. - Please fill out a request here for data transfer --- ### Requirements to access ACCORD - To access ACCORD, you need: - A modern web browser such as Chrome, Firefox, Safari, or Edge - You must be logged into your institutions VPN - If you have a sponsored account or are a UVA researcher, you will need the HSVPN - Install and register OPSWAT, a posture-checking client ![](img/ACCORD_Intro_2021102211.png) --- ### ACCORD Portal * ACCORD can be accessed via:[https://accord.uvarc.io/](https://accord.uvarc.io/) * The ACCORD website has a User Guide, FAQ, and additional documentation:[https://www.rc.virginia.edu/userinfo/accord/overview/](https://www.rc.virginia.edu/userinfo/accord/overview) ![](img/ACCORD_Intro_202110222.jpg) --- ### Logging into ACCORD\\n\\n\\n\\nTo access ACCORD, you need to log in through InCommon\\n\\nSelect your home institution from the dropdown menu (or UVA if you have a sponsored account)\\n\\n--- ### Logging into ACCORD\\n\\n\\n\\nLogin using your home institutions credentials\\n\\nIn this example, UVA will ask you to login using NetBadge. If you\\'re from another institution, this will be different\\n\\n--- ### ACCORD dashboard * Once you log in, you will see the ACCORD dashboard * Your name will appear in the top right corner, along with any recent or currently running sessions ![](img/ACCORD_Intro_2021102215.png) --- ### Start a new session * A session is an individual instance running one of the available containers (RStudio, JupyterLab, etc.) * To create a new session, click on the \"*Start A New Session*\" button in the top right ![](img/ACCORD_Intro_2021102216.png) --- ### Select a project ![](img/ACCORD_Intro_2021102217.png) * To create a new session, you need to select a project * Projects are isolated. You can only access data youve uploaded to the project youve selected --- ### Select an environment ![](img/ACCORD_Intro_2021102218.png) * After selecting a project, select the environment you want to use * To start your new environment, click on the *Start* button --- ### Connecting to a session ![](img/ACCORD_Intro_2021102219.png) * Your new session will be in the *Current Sessions* section * __Note:__ Your session may show pending as the system waits for resources to become available * Once your session is ready, click the *Connect* button to launch your session --- ### Stopping a session ![](img/ACCORD_Intro_2021102221.png) * When youre finished working in a session, __always__ click on the **Stop** button to delete it. This will free up resources for the system * Failing to delete sessions will slow down the system and create long wait times for researchers --- ### Recent sessions ![](img/ACCORD_Intro_2021102222.png) * After stopping a session, it will be moved to the *Recent Sessions* section * You can re-launch any session by clicking the *Launch* button --- ### Want to learn more? * The ACCORD website has additional documentation, FAQs, and a user guide: * [https://www.rc.virginia.edu/userinfo/accord/overview/](https://www.rc.virginia.edu/userinfo/accord/overview/) * Have issues or questions? Fill out a support ticket here ![](img/ACCORD_Intro_2021102223.jpg)')]\n",
      "Added 1 documents to the vector store\n",
      "\n",
      "[Batch 1476 of 1477]\n",
      "Found 1475 existing document IDs in the vector store.\n",
      "Filtered 1 documents to add to the vector store.\n",
      "Documents to add: [Document(metadata={'source': './md_content/learning_content/slides/site-info/index.md', 'source_type': 'markdown', 'chunk_number': 1}, page_content='title: The rc-learning site summary: An introduction maintaining the site. authors: [] tags: [] categories: [] date: \"2022-11-03T00:00:00Z\" slides: # Choose a theme from https://github.com/hakimel/reveal.js#theming theme: white # Choose a code highlighting style (if highlighting enabled in params.toml) # Light style: github. Dark style: dracula (default). highlight_style: github\\n\\nBasic Info\\n\\nREADME\\n\\nWorkflow\\n\\nSame as for the main rc.virginia.edu site\\n\\nAlways check out and modify staging\\n\\nClone into an appropriate directory, then cd to it and run /wherever/hugo server. Example\\n\\n(I don\\'t know how to do this on Windows)\\n\\nwebsite\\n\\nrc-learning\\n\\nrc-website\\n\\nhugo (copy of hugo-extended)\\n\\nTheme\\n\\nFormerly called Academic, now called Wowchemy\\n\\nDo not modify anything under the themes subdirectory\\n\\nMake changes into the corresponding folder under the top level\\n\\ne.g. layouts/partials/page-footer.html modified from themes/academic/layout/partials/page_footer.html\\n\\nHugo looks in top level first, then goes to theme\\n\\nCode Highlighting\\n\\nCode block python porridge = \"blueberry\" if porridge == \"blueberry\": print(\"Eating...\")\\n\\nMath\\n\\nIn-line math: $x + y = z$\\n\\nBlock math:\\n\\n$$ f\\\\left( x \\\\right) = \\\\;\\\\frac{{2\\\\left( {x + 4} \\\\right)\\\\left( {x - 4} \\\\right)}}{{\\\\left( {x + 4} \\\\right)\\\\left( {x + 1} \\\\right)}} $$\\n\\nDiagrams\\n\\nMermaid (https://mermaid-js.github.io/mermaid/#/)\\n\\nExample\\n\\nmarkdown {{< diagram >}} flowchart LR subgraph Users A(User) --> F((Internet)) B(User) --> F C(User) --> F end subgraph Cluster F --> G(Frontend) G --> H{{Interconnection Network}} H --> K(Node) H --> L(Node) H --> M(Node) H --> N(Node) H --> S[(Storage)] end {{< /diagram >}}\\n\\nMermaid\\n\\nView example here\\n\\nShortcodes\\n\\ncode.html\\n\\nshows code from a file\\n\\ncode-snippet.html\\n\\ncopies a bit of code to user\\'s clipboard\\n\\ncode-download\\n\\nallows user to download a file containing code\\n\\nSite Design\\n\\nThree categories\\n\\nshort courses\\n\\ntutorials\\n\\nworkshops\\n\\nprobably should reorganize but we\\'ll deal with that later\\n\\nTutorials and Workshops\\n\\nBasically the same thing (hence the need to reorganize)\\n\\nHave a \"landing page\"\\n\\nLanding page has options for links/downloads (in ovals)\\n\\nnotes\\n\\nslides\\n\\npdf\\n\\nFront Matter for Tutorials and Workshops \"Landings\"\\n\\nnotes\\n\\ndirects to content/notes/samename\\n\\nslides\\n\\ndirects to content/slides/samename\\n\\nexpects Reveal.js slides\\n\\nurl_slides\\n\\nfull (relative to Hugo paths or full URL) URL must be provided, e.g.\\n\\nurl_slides: /slides/r-intro-r-intro-slides.pdf\\n\\npdf\\n\\nexpects to find a pdf in the same directory\\n\\nurl_pdf\\n\\nsimilar to url_slides\\n\\nurl_dataset\\n\\ndata/whatever\\n\\nor longer URL\\n\\nurl_code\\n\\nlike url_dataset\\n\\nShort courses\\n\\nFor longer material\\n\\nNo \"landing page\"\\n\\nBe sure to include tags and categories\\n\\nImages\\n\\nCan be in /static/images if used more than once\\n\\nCan be local within course directory\\n\\nReference like\\n\\n{{< figure src=\"/courses/parallel_computing_introduction/img/SMP.png\" caption=\"Schematic of an SMP system.\" >}}\\n\\nfigure shortcode is a Hugo built-in\\n\\nDocument Types\\n\\narticle\\n\\nCan have a menu layout with \"subchapters\"\\n\\nChapter parent menus must be a file that isn\\'t empty (a Hugo thing)\\n\\nbook\\n\\nno subchapters\\n\\nAesthetics\\n\\nThe title in the frontmatter will be Header 1\\n\\nI tend to prefer to avoid Header 1 subsequently unless you have only one file')]\n",
      "Added 1 documents to the vector store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of Documents:', len(markdown_documents))\n",
    "\n",
    "def doc_to_id(doc):\n",
    "    return f\"{doc.metadata['source_type']}_{doc.metadata['source']}_{doc.metadata['chunk_number']}\"\n",
    "\n",
    "def add_documents_to_vector_store(documents):\n",
    "    existing_ids = vector_store.get()[\"ids\"]\n",
    "    existing_ids_set = set(existing_ids)\n",
    "    print(f\"Found {len(existing_ids_set)} existing document IDs in the vector store.\")\n",
    "    documents = [doc for doc in documents if doc_to_id(doc) not in existing_ids_set]\n",
    "    print(f\"Filtered {len(documents)} documents to add to the vector store.\")\n",
    "    if not documents:\n",
    "        print(\"No new documents to add.\")\n",
    "        return\n",
    "    print(\"Documents to add:\", documents)\n",
    "    vector_store.add_documents(\n",
    "        documents=documents,\n",
    "        ids=[doc_to_id(doc) for doc in documents],\n",
    "    )\n",
    "    print(f\"Added {len(documents)} documents to the vector store\")\n",
    "\n",
    "# Add documents to the vector store in batches\n",
    "BATCH_SIZE = 1\n",
    "for i in range(0, len(markdown_documents), BATCH_SIZE):\n",
    "    print(f\"[Batch {i // BATCH_SIZE + 1} of {len(markdown_documents) // BATCH_SIZE + 1}]\")\n",
    "    batch = markdown_documents[i:i + BATCH_SIZE]\n",
    "    add_documents_to_vector_store(batch)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
